{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53758456-2c13-4822-bf89-42be1a8f464b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "67d3cb62c956904e515960567c430672",
     "grade": false,
     "grade_id": "ads",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class='heading'>\n",
    "    <div style='float:left;'><h1>CPSC 4300/6300: Applied Data Science</h1></div>\n",
    "    <img style=\"float: right; padding-right: 10px; width: 65px\" src=\"https://raw.githubusercontent.com/bsethwalker/clemson-cs4300/main/images/clemson_paw.png\"> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec88fb0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0bcbef2685eb6a94f169c24b68cab7d6",
     "grade": false,
     "grade_id": "week-9-lab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Week 9| Lab: Supervised Classification\n",
    "\n",
    "**Clemson University** </br>\n",
    "**Instructor(s):** Tim Ransom </br>\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "## Learning objectives\n",
    "\n",
    "- Differentiate between supervised and unsupervised classification methods.\n",
    "- Implement a logistic regression model for classification.\n",
    "- Evaluate the performance of a classification model using metrics like accuracy.\n",
    "- Compare the performance of different classification algorithms.\n",
    "- Preprocess data for classification tasks, including normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab03e65",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9ca8221b1f4242dc04a39989a909956",
     "grade": false,
     "grade_id": "formatting",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" RUN THIS CELL TO GET THE RIGHT FORMATTING \"\"\"\n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "css_file = 'https://raw.githubusercontent.com/bsethwalker/clemson-cs4300/main/css/cpsc6300.css'\n",
    "styles = requests.get(css_file).text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03104480-9d7e-4293-b069-1ef8bf53a47f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dda4c4a91136e7bbf3aef0d767e3cfb3",
     "grade": false,
     "grade_id": "required-libs",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from matplotcheck.base import PlotTester\n",
    "from matplotlib.patches import PathPatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f50f064-2b18-4918-880d-7a590ebb3f79",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0bc5e0bb1821675dba239558cbe8a702",
     "grade": false,
     "grade_id": "part-1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 1: The AirBnB NYC 2019 Dataset + EDA\n",
    "\n",
    "The dataset contains information about AirBnB hosts in NYC from 2019.\n",
    "There are 49k unique hosts and 16 features for each:\n",
    "\n",
    "-   **id:** listing ID\n",
    "-   **name:** name of the listing\n",
    "-   **host<sub>id</sub>:** host ID\n",
    "-   **host<sub>name</sub>:** name of the host\n",
    "-   **neighbourhood<sub>group</sub>:** NYC borough\n",
    "-   **neighbourhood:** neighborhood\n",
    "-   **latitude:** latitude coordinates\n",
    "-   **longitude:** longitude coordinates\n",
    "-   **room<sub>type</sub>:** listing space type (e.g., private room,\n",
    "    entire home)\n",
    "-   **price:** price in dollars per night\n",
    "-   **minimum<sub>nights</sub>:** number of min. nights required for\n",
    "    booking\n",
    "-   **number<sub>ofreviews</sub>:** number of reviews\n",
    "-   **last<sub>review</sub>:** date of the last review\n",
    "-   **reviews<sub>permonth</sub>:** number of reviews per month\n",
    "-   **calculated<sub>hostlistingscount</sub>:** number of listings the\n",
    "    host has\n",
    "-   **availability<sub>365</sub>:** number of days the listing is\n",
    "    available for booking\n",
    "\n",
    "Our goal is to predict the price of unseen housing units as being\n",
    "'affordable' or 'unaffordable', by using their features. We will assume\n",
    "that this task is for a particular client who has a specific budget and\n",
    "would like to simplify the problem by classifying any unit that costs \\<\n",
    "\\\\150 per night as 'affordable' and any unit that costs \\\\150 or great\n",
    "as 'unaffordable'.\n",
    "\n",
    "For this task, we will exercise our normal data science pipeline – from\n",
    "EDA to modelling and visualization. In particular, we will show the\n",
    "performance of two different classifiers:\n",
    "\n",
    "-   `Linear Regression`\n",
    "-   `Logistic Regression`\n",
    "\n",
    "### Read-in and checking\n",
    "\n",
    "We do the usual read-in and verification of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce91413-93c7-499a-913b-5e0aad26f996",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53f268e11eea00e3e78fb6a145447247",
     "grade": false,
     "grade_id": "read-df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/nyc_airbnb.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dfe2d1-f1b3-4c2d-bcf7-6c4e1e6f2f04",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5a7faa6e1ca67886a5131fc06d02f78e",
     "grade": false,
     "grade_id": "train-test-dev",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Building the training/ dev/ testing data\n",
    "\n",
    "As usual, we split the data before we begin our analysis. It would be\n",
    "unfair to cheat by looking at the testing data. Let's divide the data\n",
    "into 60% training, 20% development (aka validation), 20% testing.\n",
    "However, before we split the data, let's make the simple transformation\n",
    "and converting the prices into a categories of being *affordable* or\n",
    "not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e96cf-a3c0-44c6-920d-94aa7027a8a0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "adc653da35c830c1499bd615842a9697",
     "grade": false,
     "grade_id": "cell-0ab7cdb8f8afe094",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df['affordable'] = np.where(df['price'] < 150, 1, 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda7272f-6ec8-4b73-8df5-ae258dc83462",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c5f12ea7555fa846109a3e9db22a9f6",
     "grade": false,
     "grade_id": "note-1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**NOTE:** The `affordable` column now has a value of 1 whenever the\n",
    "price is \\< 150, and 0 otherwise.\n",
    "\n",
    "Also, the feature named `neighbourhood_group` can be easily confused\n",
    "with `neighbourhood`, so let's go ahead and rename it to `borough`, as\n",
    "that is more distinct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d657603-6d57-40db-92c3-9f63b1374adc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cbafbd869299a605a7ce22f32b371eee",
     "grade": false,
     "grade_id": "cell-fad1764cb4c7620b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df.rename(columns={\"neighbourhood_group\": \"borough\"}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82bd398-7252-408c-aed6-14356e48ce97",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a7794684e1ac5e02d3ba1b3b43d2d2f",
     "grade": false,
     "grade_id": "cell-986662ec755ac7f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Without looking at the full data yet, let's just ensure our prices are\n",
    "within valid ranges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702f6306-cde9-4412-b55a-4d60a07803aa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b63d1ed25a3c94c2b60c9219ae96feeb",
     "grade": false,
     "grade_id": "cell-aaac659f7630178b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df['price'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71c2d91-c668-4107-9cb3-a30c426614a6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5a40fddda2f1a5b688133746aa8a5827",
     "grade": false,
     "grade_id": "cell-c8464e45267a862b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Uh-oh. We see that `price` has a minimum value of \\\\0. I highly doubt\n",
    "any unit in NYC is free. These data instances are garbage, so let's go\n",
    "ahead and remove any instance that has a price of \\\\0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d520c70-a071-471a-bf5b-bb5b3d468c35",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "04670e6417729bb49bdd0a92ab44cd4d",
     "grade": false,
     "grade_id": "cell-090dae1c08f6f2c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"original training size:\", df.shape)\n",
    "df = df.loc[df['price'] != 0]\n",
    "print(\"new training size:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa601905-4b39-47e7-9334-065efe850f8f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea025b22a87c4112c4713595cacfc77d",
     "grade": false,
     "grade_id": "cell-2b637571f28b0b65",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, let's split the data while ensuring that our test set has a fair\n",
    "distribution of affordable units, then further split our training set so\n",
    "as to create the development set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43842ed8-12c2-4d47-99e4-0b45a995e2ad",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2746cc0236af1e18b2a6bf549637912c",
     "grade": false,
     "grade_id": "cell-3c08c1021aaa02e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42, stratify=df['affordable'])\n",
    "df_train, df_dev = train_test_split(df_train, test_size=0.25, random_state=99)\n",
    "\n",
    "# ensure our dataset splits are of the % sizes we want\n",
    "total_size = len(df_train) + len(df_dev) + len(df_test)\n",
    "print(\"train:\", len(df_train), \"=>\", len(df_train) / total_size)\n",
    "print(\"dev:\", len(df_dev), \" =>\", len(df_dev) / total_size)\n",
    "print(\"test:\", len(df_test), \"=>\", len(df_test) / total_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3253563a-073e-43da-8b94-bec6f18fa1ad",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "37c69cdd47dd29777017f642e09a69ab",
     "grade": false,
     "grade_id": "cell-b24843952dd07f30",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's remove the target value (i.e., **affordable**) from our current\n",
    "dataframes and create it as separate prediction dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dde2e1-03ce-4fcf-bb5e-584809a4fb26",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19bdedf9621a392f640f8280db83e81c",
     "grade": false,
     "grade_id": "cell-16bdee4aaf45fc59",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# training\n",
    "x_train = df_train.drop(['price', 'affordable'], axis=1)\n",
    "y_train = pd.DataFrame(data=df_train['affordable'], columns=[\"affordable\"])\n",
    "\n",
    "# dev\n",
    "x_dev = df_dev.drop(['price', 'affordable'], axis=1)\n",
    "y_dev = pd.DataFrame(data=df_dev['affordable'], columns=[\"affordable\"])\n",
    "\n",
    "# test\n",
    "x_test = df_test.drop(['price', 'affordable'], axis=1)\n",
    "y_test = pd.DataFrame(data=df_test['affordable'], columns=[\"affordable\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7df8639-f5c0-4fbd-a41c-384cb81b7700",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7fcf14b64fb2acac510eed98135fb72a",
     "grade": false,
     "grade_id": "cell-5b2579c23099796d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "From now onwards, we will do EDA and cleaning based on the training set,\n",
    "`x_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8631c563-8a3a-484e-ba64-487a0fa6381f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c3f275fd39e252683504f7dc16247f90",
     "grade": false,
     "grade_id": "cell-4bc5966c5ab16de4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for col in x_train.columns:\n",
    "    print(col, \":\", np.sum([x_train[col].isnull()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b63786-a081-467f-b326-69cc3629b945",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "68693fb37088b62bfb303040cdd18835",
     "grade": false,
     "grade_id": "cell-3347d1d514b640de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "It appears ~6k of the rows have missing values concerning the reviews.\n",
    "It seems impossible to impute the `last_review` feature with reasonable\n",
    "values, as this is very specific to each unit. At best, we could guess\n",
    "the date based on the `reviews_per_month`, but that feature is missing\n",
    "for the same rows. Further, it might be difficult to replace\n",
    "`reviews_per_month` with reasonable values – sure, we could fill in\n",
    "values to be the median value, but that seems wrong to generalize so\n",
    "heavily, especially for over 20% of our data. Consequently, let's just\n",
    "ignore these two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0663fab-83a0-41f3-b9cc-7720cccd073d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5124347982ff70611dc49069970ec903",
     "grade": false,
     "grade_id": "cell-b698c751cc4882b6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x_train = x_train.drop(['last_review', 'reviews_per_month'], axis=1)\n",
    "x_dev = x_dev.drop(['last_review', 'reviews_per_month'], axis=1)\n",
    "x_test = x_test.drop(['last_review', 'reviews_per_month'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4e7977-f7f3-4e78-ad69-09a2f6808032",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6058232fce0ff08a78107d06e868f791",
     "grade": false,
     "grade_id": "cell-51273ea1cb9a1516",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's look at the summary statistics of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b978ae-d755-4762-a02e-bac3b616c2ae",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3fcf734c2a9f5fa205905e901544c7ab",
     "grade": false,
     "grade_id": "cell-0d03259582e3676e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c282ea-3e52-4a1c-9bb2-55eaaffd62f4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c3566777631c71592a81197008223e65",
     "grade": false,
     "grade_id": "cell-9752630b95282eab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next, we see that the `minimum_nights` feature has a maximum value of\n",
    "1,250. That's almost 3.5 years, which is probably longer than the\n",
    "duration that most people rent an apartment. This seems anomalous and\n",
    "wrong. Let's discard it and other units that are outrageous. Well, what\n",
    "constitutes 'outrageous'? We see that the standard deviation for\n",
    "`minimum_nights` is 21.24. If we assume our distribution of values are\n",
    "normally distributed, then only using values that are within 2 standard\n",
    "deviations of the mean would yield us with ~95% of the original data.\n",
    "However, we have no reason to believe our data is actually normally\n",
    "distributed, especially since our mean is 7. To have a better idea of\n",
    "our actual values, let's plot it as a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa013a0-cb06-4b3d-aee0-8b3b95359d67",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d171912802903bb46508ef1dfabdb84",
     "grade": false,
     "grade_id": "cell-36ef0ce839f4f39d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.hist(x_train['minimum_nights'], 25, log=True)\n",
    "plt.xlabel('minimum_nights')\n",
    "plt.ylabel('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8ef05e-6310-4bf6-8f4b-05cd3d267570",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "101b172c4058fed122e92dfa50a3bab8",
     "grade": false,
     "grade_id": "cell-9d8d0dbcdf0221d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Yea, that instance was a strong outlier, and the host was being\n",
    "ridiculously greedy. That's a clever way to get out a multi-year lease.\n",
    "Notice that we are using log-scale. Clearly, a lot of our mass is from\n",
    "units less than 365 days. To get a better sense of that subset, let's\n",
    "re-plot only units with minumum<sub>nights</sub> \\< 365 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97591d7-1190-44a1-bef8-5489d384bdaa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ea39844fa1288c20e07f88f7b9423b7",
     "grade": false,
     "grade_id": "cell-ebd442975e689fc8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "subset = x_train['minimum_nights']<365\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.hist(x_train['minimum_nights'][subset], 30, log=True)\n",
    "plt.xlabel('minimum_nights')\n",
    "plt.ylabel('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23663cf-240e-414e-88e9-76412b0ef1fb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e827cfba463833f1340b61cd3f34696b",
     "grade": false,
     "grade_id": "cell-dc94b8feede31012",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Ok, that doesn't look too bad, as most units require \\< 30 nights. It's\n",
    "surprising that some hosts list an unreasonable requirement for the\n",
    "minimum number of nights. There is a risk that any host that lists such\n",
    "an unreasonable value might also have other incorrect information.\n",
    "Personally, I think anything beyond 30 days could be suspicious. If we\n",
    "were to exclude any unit that requires more than 30 days, how many\n",
    "instances would we be ignoring?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e2d07c-85a3-467c-aa12-c5610c647ba9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e41dbf63392544abd033abc227e6bdc2",
     "grade": false,
     "grade_id": "cell-a0a3f4ebb6b33991",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "len(x_train.loc[x_train['minimum_nights']>30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366d8c22-c4d1-4bc5-b5b5-ae184c9707cf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d3b9127ebea66d514d48a44ecc866dd5",
     "grade": false,
     "grade_id": "cell-84a9238fb7c655d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Alright, we'd be throwing away 436 out of our ~30k entries. That's\n",
    "roughly 1.5% of our data. While we generally want to keep and use as\n",
    "much data as we can, I think this is an okay amount to discard,\n",
    "especially considering (1) we have a decently large amount of data\n",
    "remaining, and (2) the entries beyond a 30-day-min could be unrealiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6545dfba-05bc-439b-8aa2-859c70438349",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad2e9cd5a12d224de059be1809aea4a3",
     "grade": false,
     "grade_id": "cell-f38f39117e90c2c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "good_subset = x_train['minimum_nights'] <= 30\n",
    "x_train = x_train.loc[good_subset]\n",
    "y_train = y_train.loc[good_subset]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d278ea-3194-45e2-8dc2-bb03be856af2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b85fc261c0be490bd941958eb941cda4",
     "grade": false,
     "grade_id": "cell-a9fc1ae7e59e37d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Notice that we only trimmed our training data, not our development or\n",
    "testing data. I am making this choice because in real scenarios, we\n",
    "would not know the nature of the testing data values. We pre-processed\n",
    "our data to ignore all data that has a price of \\$0, and to ignore\n",
    "certain columns (even if it's in the testing set), but that was fair\n",
    "because those columns proved to be obvious, bogus element of the\n",
    "dataset. However, it would be unfair to inspect the values of the\n",
    "training set and then to further trim the development and testing set\n",
    "accordingly, conditioned on certain data values.\n",
    "\n",
    "The remaining columns of our training data all have reasonable summary\n",
    "statistics. None of the min's or max's are cause for concern, and we\n",
    "have no reason to assert a certain distribution of values. Since all the\n",
    "feature values are within reasonable ranges, and there are no missing\n",
    "values (NaNs) remaining, we can confidently move foward. To recap, our\n",
    "remaining columns are now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57d1a9e-7f0f-457f-af8b-132f01c73dfb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d858e2ce7dd213f096c823f10df0a02",
     "grade": false,
     "grade_id": "cell-22c149cd93e899dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "[col for col in x_train.columns] # easier to read vertically than horizontally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af26db1-b9a4-4c0f-b02d-bebb6a7fc4ac",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bbfd76f3bb50a66845c6d7d515a64262",
     "grade": false,
     "grade_id": "cell-afcdb646dfb7ecc5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We don't have a terribly large number of features. This allows us to\n",
    "inspect every pairwise interaction. A scatterplot is great for this, as\n",
    "it provides us with a high-level picture of how every pair of features\n",
    "correlates. If any subplot of features depicts a linear relationship\n",
    "(i.e., a clear, concise path with mass concentrated together), then we\n",
    "can assume there exists some collinearity – that the two features\n",
    "overlap in what they are capturing and that they are not independent\n",
    "from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628514d3-11d1-47ec-b172-b08e91f824e2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7224b96ce8f01be49e99a9e6599e83e3",
     "grade": false,
     "grade_id": "cell-57688c718165af39",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "scatter_matrix(x_train, figsize=(30,20));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6793df-c5e9-45e1-96c2-f9744ff7dfef",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c7ecf22d7c45e0b4dbb4ca9d2d279222",
     "grade": false,
     "grade_id": "part-2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "------------------------------------------------------------------------\n",
    "\n",
    "## Part 2: Predicting with Linear Regression\n",
    "\n",
    "Now, let's actually use our features to make more informed predictions.\n",
    "Since our model needs to use numeric values, not textual ones, let's use\n",
    "**ONLY** the following features for our linear model:\n",
    "\n",
    "-   `borough`, using 1-hot encodings. There are 5 distinct boroughs, so\n",
    "    represent them via 4 unique columns.\n",
    "-   `latitude`\n",
    "-   `longitude`\n",
    "-   `room_type`, using 1-hot encodings. There are 3 distinct\n",
    "    room<sub>types</sub>, so represent them via 2 unique columns.\n",
    "-   `minimum_nights`\n",
    "-   `number_of_reviews`\n",
    "-   `calculated_host_listings_count`\n",
    "-   `availability_365`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55edd5ac",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a436455e2d32f70369b092a9128773b4",
     "grade": false,
     "grade_id": "exercise-1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"exercise\"><b>Exercise 1:</b> </div>  \n",
    "\n",
    "Prepare the dataset for **classification** by selecting relevant features and applying one-hot encoding.\n",
    "\n",
    "### **Instructions:**  \n",
    "1. **Modify `x_train`, `x_dev`, and `x_test`** to contain only the following features:  \n",
    "   - **Categorical Features** (to be one-hot encoded):  \n",
    "     - `borough` (NYC borough)  \n",
    "     - `room_type` (Type of listing: entire home, private room, shared room)  \n",
    "   - **Numeric Features**:  \n",
    "     - `latitude`  \n",
    "     - `longitude`  \n",
    "     - `minimum_nights`  \n",
    "     - `number_of_reviews`  \n",
    "     - `calculated_host_listings_count`  \n",
    "     - `availability_365`  \n",
    "\n",
    "2. **Apply one-hot encoding**:  \n",
    "   - Convert `borough` and `room_type` into one-hot encoded variables.  \n",
    "   - Drop the **first category** for each (`drop_first=True`) to avoid dummy variable traps.  \n",
    "\n",
    "3. **Ensure final dataset structure**:  \n",
    "   - Remove unnecessary columns: `id`, `name`, `host_id`, `host_name`, and `neighbourhood`.  \n",
    "   - Ensure the final shape of `x_train` is **(28,894, 12)**.  \n",
    "\n",
    "**Hint:**  \n",
    "- Use `pd.get_dummies()` for **one-hot encoding**.  \n",
    "- Use `.drop()` to **remove unnecessary columns**.  \n",
    "- Refer to [`pandas.get_dummies()` documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2255d9-31c2-4c45-9d4a-66f4facdc994",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e16f8ec2391fe54962cf5dbee46f5a3f",
     "grade": false,
     "grade_id": "exercise-1-implementation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Write your code for exercise-1 here:\"\"\"\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9f1a59",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c86f1185f79cc549fdb537a0bdcf762",
     "grade": true,
     "grade_id": "exercise-1-tests",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33c9f6be-a722-4109-847b-d0fc4cd2509f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd46eeb7df38c70142151346ccfd7280",
     "grade": false,
     "grade_id": "exercise-2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"exercise\"><b>Exercise 2:</b> </div>\n",
    "\n",
    "Perform **multi-linear regression** and evaluate its performance on the **development set**.\n",
    "\n",
    "1. **Create and train a Linear Regression model**:  \n",
    "   - Instantiate a `LinearRegression` model named **`model`**.  \n",
    "   - Train the model using the **training set** (`x_train`, `y_train`).  \n",
    "\n",
    "2. **Compute the R² scores**:  \n",
    "   - Store the **R² score** for the **training set** (`x_train`, `y_train`) in a variable named **`train_r2`**.  \n",
    "   - Store the **R² score** for the **development set** (`x_dev`, `y_dev`) in a variable named **`dev_r2`**.  \n",
    "\n",
    "3. **Make predictions and evaluate accuracy**:  \n",
    "   - Use `.predict()` on `x_dev` and store the predictions in `y_pred_dev`.  \n",
    "   - Convert predictions into binary classifications using **0.5 as the threshold**:\n",
    "     - **Predictions ≥ 0.5 → Affordable (1)**\n",
    "     - **Predictions < 0.5 → Unaffordable (0)**\n",
    "   - Compute the **accuracy score** and store it in **`accuracy`**.  \n",
    "\n",
    "4. **Print the results**:\n",
    "   - Print **R² scores** (`train_r2` and `dev_r2`).  \n",
    "   - Print the **accuracy percentage**.  \n",
    "\n",
    "**Hint:**  \n",
    "- Use `.score()` to calculate the R² value.  \n",
    "- Use `accuracy_score()` from `sklearn.metrics` to compute accuracy.  \n",
    "- Refer to [`LinearRegression()` documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) and [`accuracy_score()` documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7dd1ec-e54e-4eb4-a57f-62890e80316a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed4cf0d9e1f452510162220f1c728f6c",
     "grade": false,
     "grade_id": "exercise-2-implementation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Write your code for exercise-2 here:\"\"\"\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72980d65",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c686dc7799d02a085143b5b4dc08b65",
     "grade": true,
     "grade_id": "exercise-2-tests",
     "locked": true,
     "points": 12,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b718976c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cda2386e872ebce6a8a872e825bd74f3",
     "grade": false,
     "grade_id": "exercise-3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"theme\"> <b>Question 1:</b> </div>  \n",
    "\n",
    "After evaluating the **Linear Regression model**, the **accuracy on the development set** was approximately **77%**. What does this accuracy indicate about the model's performance? (Select the most appropriate answer.)\n",
    "\n",
    "- 1. The accuracy is **very high**, meaning the model is excellent and needs no improvement.  \n",
    "- 2. The accuracy is **reasonable**, but **Linear Regression may not be ideal** for classification problems.  \n",
    "- 3. The accuracy is **too low**, suggesting there is **no relationship** between features and affordability.  \n",
    "- 4. The accuracy is **irrelevant**, as Linear Regression is always the best model for classification tasks.  \n",
    "\n",
    "**Store your answer in an integer variable named `answer` in the below code cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6713571",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b94edbca33717a3ab5a6d0f019eea6d1",
     "grade": false,
     "grade_id": "exercise-3-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab827724",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f13f0a9fa985c11e2c027b39421fcf3",
     "grade": true,
     "grade_id": "cell-ee0c68d6b3ade774",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb8586da-e251-4011-aaf8-837d7066cd33",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a4b17a5a63a7b1579ae62a9adc80828",
     "grade": false,
     "grade_id": "exercise-4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"exercise\"><b>Exercise 3:</b> </div> \n",
    "\n",
    "Analyze and visualize the **residuals** for both the **training** and **development** sets.\n",
    "\n",
    "1. **Compute residuals**:  \n",
    "   - Residuals are calculated as the difference between actual and predicted values:  \n",
    "     $$\n",
    "     \\text{Residual} = \\text{Actual Value} - \\text{Predicted Value}\n",
    "     $$\n",
    "   - Use the trained **Linear Regression model** (`model`) to generate predictions:  \n",
    "     - Compute **training residuals** and store them in `training_residuals`.  \n",
    "     - Compute **development residuals** and store them in `dev_residuals`.  \n",
    "\n",
    "2. **Create a figure with two histograms**:  \n",
    "   - Use `plt.subplots(1, 2, figsize=(15, 5))` to create a **single figure** with **two subplots**:\n",
    "     - **Left plot** → Histogram of **training residuals**.  \n",
    "     - **Right plot** → Histogram of **development residuals**.  \n",
    "\n",
    "3. **Customize the plots**:  \n",
    "   - Set **titles** for each subplot (`\"Histogram of Training Residuals\"` and `\"Histogram of Development Residuals\"`).  \n",
    "   - Label the **x-axis** as `\"Residuals\"` and the **y-axis** as `\"Frequency\"`.  \n",
    "   - Use **bins=20** for better visualization.  \n",
    "   - Add a **horizontal reference line at zero** (`axhline(0)`) for comparison.  \n",
    "\n",
    "4. **Display the figure** using `plt.show()`.  \n",
    "\n",
    "5. **Print the minimum residual value** in the development set.  \n",
    "\n",
    "**Hint:**  \n",
    "- Use `ax.hist()` to create **histograms** in each subplot.  \n",
    "- Use `ax.axhline(0, color='black', linewidth=2)` to **add a reference line at zero**.  \n",
    "- Refer to [`matplotlib.pyplot.subplots()` documentation](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3a7ab4-f4c3-4b69-b5ef-02090df6ebaa",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd14a555604d0cb0c345b9d9cc7c3fe1",
     "grade": false,
     "grade_id": "exercise-4-implementation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Write your code for exercise-3 here:\"\"\"\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a3678f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ae4e82149b2b6a4c41b6759895a3f17",
     "grade": true,
     "grade_id": "exercise-4-tests",
     "locked": true,
     "points": 16,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "699c8a07",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5b5cba59a2d9b5de15e446dcb56cd2cf",
     "grade": false,
     "grade_id": "exercise-5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"theme\"> <b>Question 2:</b> </div> \n",
    "\n",
    "Based on the residual plots from **Exercise 3**, does this adhere to the assumptions of a **linear model**? (Select the most appropriate answer.)\n",
    "\n",
    "1. **Yes, the residuals are randomly distributed, supporting the linear model assumption.**  \n",
    "2. **No, the residuals show patterns, suggesting the linear model may not be the best choice.**  \n",
    "\n",
    "**Store your answer in an integer variable named `answer` in the below code cell.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afccdb1a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a588f1c5e313ef2c67c833396b258cf0",
     "grade": false,
     "grade_id": "exercise-5-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df374e2a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "74b69461b6363f366a0d9b08fe908e1d",
     "grade": true,
     "grade_id": "cell-aac1f26348a144d6",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8490acb-18e6-4040-a9ab-afdd13f64777",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6058cb2daf627ec6ead26b2e27495b75",
     "grade": false,
     "grade_id": "part-3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Part 3: Binary Logistic Regression**\n",
    "\n",
    "Linear regression is a useful **baseline model**, but since our target variable is **binary** (0 or 1), we need to use **Binary Logistic Regression** instead.  \n",
    "\n",
    "### **Why Logistic Regression?**  \n",
    "- **Handles binary classification problems effectively.**  \n",
    "- **Outputs probabilities** that can be converted into class labels (0 or 1).  \n",
    "- **Applies the logistic (sigmoid) function** to model the relationship between input features and the probability of a class.  \n",
    "\n",
    "### **Implementing Logistic Regression with `sklearn`**  \n",
    "In this section, we will:  \n",
    "1. **Import the necessary classes** from `sklearn`.  \n",
    "2. **Instantiate and fit a Logistic Regression model** using our training data.  \n",
    "3. **Evaluate the model** using accuracy metrics.  \n",
    "4. **Analyze feature importance** using model coefficients.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Step 1: Import Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38f4e85-488c-4903-be89-dd4189d4b159",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8fe6c52f9e4952c50c1d8bfce4239421",
     "grade": false,
     "grade_id": "cell-d6a63704aa435e39",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71c3610-7e8c-4a55-8225-2fddd2f0ec6f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c6b71a32396e2ab28cf429682979b4c",
     "grade": false,
     "grade_id": "cell-e69a6b728fe1072f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 2: Instantiate and Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f6ac13-bb44-4d42-a346-3bcb03e94095",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a66517995224bde61dbb712d8d4e55d8",
     "grade": false,
     "grade_id": "cell-146b428c8bbbb60d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create an instance of Logistic Regression\n",
    "lr = LogisticRegression(solver=\"lbfgs\", max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd94ade-8597-4d98-961f-065b8547ca32",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8b6891934a1ff896c708773eba58716",
     "grade": false,
     "grade_id": "cell-64cca7c7da35b57b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Train the model using the training set\n",
    "lr.fit(x_train, y_train['affordable'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670e0348-5587-4f99-a977-741dd9884f83",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1b6c4a0e5de4eaee8d0107c510e976e9",
     "grade": false,
     "grade_id": "exercise-6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"exercise\"><b>Exercise 4:</b> </div>  \n",
    "\n",
    "Train a **binary logistic regression model**, make predictions, and evaluate its accuracy.\n",
    " \n",
    "1. **Use the above trained `LogisticRegression` model (`lr`)** to make predictions on **x_dev**.  \n",
    "   - Store the predictions in a variable named **`y_dev_pred`**.  \n",
    "\n",
    "2. **Compute the accuracy of the model**:  \n",
    "   - Use `accuracy_score()` from `sklearn.metrics` to calculate accuracy.  \n",
    "   - Store the accuracy in a variable named **`lr_accuracy`**.  \n",
    "\n",
    "3. **Print the model’s performance details**:  \n",
    "   - Print the **accuracy score**.  \n",
    "   - Print the **number of coefficients** in the model.  \n",
    "   - Print all **coefficient values** along with their corresponding feature names.  \n",
    "\n",
    "4. **Experiment with different model parameters**:  \n",
    "   - Try different values for **C penalty** (e.g., from `0` to `100 million`).  \n",
    "   - Test different **max iterations** (`5 to 5000`).  \n",
    "   - Compare the effects of **L1 (Lasso) vs. L2 (Ridge) regularization**.  \n",
    "\n",
    "5. **Analyze and interpret the results**:  \n",
    "   - How does the **accuracy compare** to the linear regression model?  \n",
    "   - What happens when you change **regularization strength (`C`)**?  \n",
    "   - Does increasing **max iterations** always improve performance?  \n",
    "\n",
    "**Hint:**  \n",
    "- Use `.predict()` to generate predictions.  \n",
    "- Use `.coef_` to examine feature importance.  \n",
    "- Refer to [`LogisticRegression()` documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) and [`accuracy_score()` documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fb4a52-f501-4886-abf4-c88ba91b680c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29ad0da282b452d6014132de18d8746b",
     "grade": false,
     "grade_id": "exercise-6-implementation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Write your code for exercise-4 here:\"\"\"\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fdeb92",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32c0a9bffb2f91eb974d779c856f088f",
     "grade": true,
     "grade_id": "exercise-6-tests",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a02fa7b2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c0f7c5fc6a3dd9298b365896e6866405",
     "grade": false,
     "grade_id": "cell-c5f55b818ce77fe8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The results here should show that for this dataset, logistic regression\n",
    "offered effectively identical performance as linear regression. There\n",
    "are two main takeaways from this:\n",
    "\n",
    "-   logistic regression should not be viewed as being *superior* to\n",
    "    linear regression; it should be viewed as a solution to a different\n",
    "    type of problem – **classification** (predicting categorical\n",
    "    outputs), not **regression** (predicting continuous-valued outputs).\n",
    "-   In our situation, our two categories/classes (affordable or not) had\n",
    "    an ordinal nature. That is, the continuum of prices directly aligned\n",
    "    with the structure of our two classes. Alternatively, you could\n",
    "    imagine other scenarios where our two categories are nominal and\n",
    "    thus un-rankable (e.g., predicting cancer or not, or predicting\n",
    "    which NYC borough an AirBnB is in based on its property features).\n",
    "    \n",
    "### **Key Takeaways**  \n",
    "\n",
    "The **Logistic Regression model** achieved an accuracy of **77.39%**, using **12 features**.  \n",
    "\n",
    "#### **Key Observations:**  \n",
    "1. **Logistic Regression vs. Linear Regression**  \n",
    "   - The results indicate that **Logistic Regression** performed **similarly** to **Linear Regression** in this dataset.  \n",
    "   - This suggests that **linear regression** can still be an effective baseline, even for binary classification problems.  \n",
    "\n",
    "2. **When to Use Logistic Regression?**  \n",
    "   - **Logistic Regression is not necessarily superior to Linear Regression**. Instead, it is suited for **classification problems** where the output is categorical.  \n",
    "   - In contrast, **Linear Regression** is best used when predicting **continuous numerical values**.  \n",
    "\n",
    "3. **Nature of Our Classification Task**  \n",
    "   - In this case, the **two classes (affordable vs. unaffordable)** were **ordinal** (ordered by price).  \n",
    "   - If the classification task involved **nominal categories** (e.g., **predicting boroughs** or **disease presence**), then **Logistic Regression would be the more appropriate choice** over Linear Regression.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e266c2-5b30-4987-99f3-f1f3e7c7616d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87e3f6878cc62c191f3dec8bb844b9c6",
     "grade": false,
     "grade_id": "part-4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 4 (The Real Challenge): Multiclass Classification\n",
    "\n",
    "Before we move on, let's consider a more common use case of logistic\n",
    "regression: predicting not just a binary variable, but what level a\n",
    "categorical variable will take. Instead of breaking the price variable\n",
    "into two classes (affordable being true or false), we may care for more\n",
    "fine-level granularity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2b8458",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f64a5f3f5ed70976e216b040a4519a07",
     "grade": false,
     "grade_id": "exercise-7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"exercise\"><b>Exercise 5:</b> </div> \n",
    "\n",
    "Prepare the dataset for **multi-class classification** by creating **categorical price levels**.\n",
    "\n",
    "1. **Create copies** of the original dataset (`x_train`, `x_dev`) for multi-class classification:  \n",
    "   - `x_train_multiclass`, `y_train_multiclass` (for training set)  \n",
    "   - `x_dev_multiclass`, `y_dev_multiclass` (for development set)  \n",
    "\n",
    "2. **Create a new categorical column `price_level`** based on the `price` column using the following 5 categories:\n",
    "   - **0 → Budget** (`price < 80`)\n",
    "   - **1 → Affordable** (`80 ≤ price < 120`)\n",
    "   - **2 → Average** (`120 ≤ price < 180`)\n",
    "   - **3 → Expensive** (`180 ≤ price < 240`)\n",
    "   - **4 → Very Expensive** (`price ≥ 240`)\n",
    "\n",
    "3. **Use `pd.cut()`** to bin the `price` values into these **5 categories**.\n",
    "\n",
    "4. **Ensure that**:\n",
    "   - `x_train_multiclass` and `x_dev_multiclass` contain **all original features** (excluding `price_level`).  \n",
    "   - `y_train_multiclass` and `y_dev_multiclass` contain **only the `price_level` column**.\n",
    "\n",
    "### **Why Multi-Class Classification?**  \n",
    "- Instead of predicting whether a property is simply **affordable (0 or 1)**, this new approach **categorizes prices into multiple levels**.  \n",
    "- This allows for **a more granular analysis** of property pricing and could improve predictive power.\n",
    "\n",
    "**Hint:**  \n",
    "- Use `pd.cut()` to **efficiently bin continuous variables** into categories.  \n",
    "- Refer to [`pandas.cut()` documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c895c2ca-5397-4169-a16a-b5be77e914b2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93ec5f71272babfec1feb1853caaf21c",
     "grade": false,
     "grade_id": "exercise-7-implementation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Write your code for exercise-5 here:\"\"\"\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422556e7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d77b40a61ae54cb8401b8836a195013",
     "grade": true,
     "grade_id": "exercise-7-tests",
     "locked": true,
     "points": 12,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a26af0e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b41fd7138a2a15db5ee1a748e23f2c81",
     "grade": false,
     "grade_id": "exercise-8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"exercise\"><b>Exercise 6:</b> </div>\n",
    "\n",
    "**Multi-Class Logistic Regression**  \n",
    "\n",
    "In this exercise, you will perform **logistic regression** on the newly created **multi-class price categories** and evaluate the model’s performance. Unlike binary classification, this task involves multiple class labels, making it a **multi-class classification problem**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Steps to Complete the Exercise**\n",
    "#### **1. Train a Multi-Class Logistic Regression Model**\n",
    "- Instantiate a **Logistic Regression** model named **`lr_8`**.\n",
    "- Use **`x_train_multiclass`** (features) and **`y_train_multiclass`** (multi-class labels) to train the model.\n",
    "\n",
    "#### **2. Make Predictions**\n",
    "- Use the trained model to predict the multi-class labels for **`x_dev_multiclass`**.\n",
    "- Store the predictions in **`y_dev_pred_multiclass`**.\n",
    "\n",
    "#### **3. Compute Accuracy**\n",
    "- Calculate the **accuracy score** between **predicted labels** and **true labels** (`y_dev_multiclass`).\n",
    "- Store the result in **`lr_accuracy_multiclass`**.\n",
    "- Print the accuracy score.\n",
    "\n",
    "---\n",
    "\n",
    "### **References**\n",
    "**LogisticRegression() documentation** - [Scikit-learn Docs](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)  \n",
    "**accuracy_score() documentation** - [Scikit-learn Docs](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95beb1a8-42ba-489c-890e-a3f265a4bf7e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f7652cc2f96084bcefaa5c089b4a484",
     "grade": false,
     "grade_id": "exercise-8-answers",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Write your code for exercise-6 here:\"\"\"\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba35d07",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "acb2103e233163784e1f7dead54fd650",
     "grade": true,
     "grade_id": "exercise-8-tests",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966655ca-d7bf-4823-bb80-25289c55b5d2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "482aca9bb11355083ac1601f177ef9da",
     "grade": false,
     "grade_id": "cell-f42beabe6e27ae70",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy score: {:.3f}\".format(lr_accuracy_multiclass))\n",
    "print(\"Coefficient Count: {}\".format(len(lr_8.coef_[0])))\n",
    "print(\"Feature Count: {}\".format(x_dev.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd2b75b-54af-4f3a-a5ae-79a133902bcd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5391faf0b014b6120695b4711eed331a",
     "grade": false,
     "grade_id": "cell-f122c6f617f8976b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(x_dev.columns)):\n",
    "    print(\"Feature: {}\".format(x_dev.columns[i]))\n",
    "    print(\"Coef: {:.5f}\\n\".format(lr.coef_[0][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081a2483-345b-4df2-bf05-46307c8b48a2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "217a32f8e7fdc2feee82ec36507e1b39",
     "grade": false,
     "grade_id": "cell-e3421eed85d9b154",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### **Conclusion and Next Steps**  \n",
    "\n",
    "Despite having **five distinct price categories**, our **multi-class classification model** performs reasonably well! However, there are several ways we could **further improve performance**:  \n",
    "\n",
    "1. **Cross-validation**:  \n",
    "   - Instead of relying on a single train-test split, we could apply **k-fold cross-validation** to evaluate model performance more robustly.  \n",
    "\n",
    "2. **Feature Engineering**:  \n",
    "   - **One-hot encoding** for the `neighbourhood` feature could help capture **fine-level location granularity**, as neighborhoods likely correlate strongly with price.  \n",
    "   - However, we should ensure we have **enough representative data** for each neighborhood before introducing it as a feature.  \n",
    "\n",
    "3. **Feature Scaling**:  \n",
    "   - **Longitude and latitude** contain valuable **spatial information**, but their range is quite small.  \n",
    "   - Scaling these features **between 0 and 1** might improve the model's ability to distinguish fine-grained location-based pricing trends.  \n",
    "\n",
    "4. **Handling Imbalanced Importance of Classes**:  \n",
    "   - In **some classification problems**, **certain classes may be more critical** than others.  \n",
    "   - Example: In medical diagnoses, **false negatives** (missing a disease) are more dangerous than **false positives** (false alarms).  \n",
    "   - We could **adjust class weights** during training to **prioritize more important categories** and **balance misclassification penalties**.  \n",
    "\n",
    "5. **Threshold Tuning for Decision Making**:  \n",
    "   - Instead of treating a predicted class as the highest probability category, we can **analyze model performance across different thresholds**.  \n",
    "   - By **plotting precision-recall curves** and adjusting the decision threshold, we could better control **false positives vs. false negatives** depending on the application.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Final Takeaway**  \n",
    "In this lab, we explored:\n",
    "- **Binary classification** using **Logistic Regression**.  \n",
    "- **Multi-class classification** and performance evaluation.  \n",
    "- **Feature engineering, scaling, and class weight adjustments** for improvement.  \n",
    "- **Real-world considerations** in classification models, including cost-sensitive learning.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd79fcc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da4df2e0c66343cd4cf2e9d24c45ceb1",
     "grade": false,
     "grade_id": "cell-e572aaff520b21b9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
