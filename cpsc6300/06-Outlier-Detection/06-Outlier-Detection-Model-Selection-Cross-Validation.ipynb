{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "78E15aLOsyPX",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "436bfd68c3e08da118c27fa50d265d07",
     "grade": false,
     "grade_id": "ads",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class='heading'>\n",
    "    <div style='float:left;'><h1>CPSC 4300/6300: Applied Data Science</h1></div>\n",
    "    <img style=\"float: right; padding-right: 10px; width: 65px\" src=\"https://bsethwalker.github.io/assets/img/clemson_paw.png\"> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "634e10975698d8eaad0ef97bc5eb4d69",
     "grade": false,
     "grade_id": "week-6-lab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Week 6 | Lab: Outlier Detection, Model Selection and Cross Validation\n",
    "\n",
    "**Clemson University**<br>\n",
    "**Instructor(s):** Tim Ransom<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this lab, you should be able to:\n",
    "* Feel comfortable with splitting the training and validation sets\n",
    "* Feel comfortable with model selection\n",
    "* Feel comfortable with selecting the best model out of selected ones\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9ca8221b1f4242dc04a39989a909956",
     "grade": false,
     "grade_id": "formatting",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" RUN THIS CELL TO GET THE RIGHT FORMATTING \"\"\"\n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "css_file = 'https://raw.githubusercontent.com/bsethwalker/clemson-cs4300/main/css/cpsc6300.css'\n",
    "styles = requests.get(css_file).text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1Hw0YTAPsyPa",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0560e66a145fca5e22b8669c07876767",
     "grade": false,
     "grade_id": "required-libs",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.inspection import permutation_importance\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "YVi9_Ox9Arny",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "06e255912bc843833ac9772568cf5dd8",
     "grade": false,
     "grade_id": "outlier-detection",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 1. Outlier Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "SaXnxAtUKZci",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3b651416db29802e55ad189f4d7f9848",
     "grade": false,
     "grade_id": "about-outlier-detection",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "`Outiler`: Outliers are values at the extreme ends of a dataset.\n",
    "\n",
    "- Some outliers represent true values from natural variation in the population. Other outliers may result from incorrect data entry, equipment malfunctions, or other measurement errors.\n",
    "\n",
    "- An outlier isn’t always a form of dirty or incorrect data, so you have to be careful with them in data cleansing. What you should do with an outlier depends on its most likely cause.\n",
    "\n",
    "- There are different ways to detect Outliers. One of the common technique is `Interquartile Range`.\n",
    "\n",
    "    - Each dataset can be divided into quartiles. \n",
    "    - The first quartile point indicates that 25% of the data points are below that value whereas second quartile is considered as median point of the dataset. \n",
    "    - The inter quartile method finds the outliers on numerical datasets by following the procedure below\n",
    "\n",
    "         - Find the first quartile, Q1.\n",
    "         - Find the third quartile, Q3.\n",
    "         - Calculate the IQR. IQR= Q3-Q1.\n",
    "\n",
    "- Define the normal data range with lower limit as Q1 – 1.5 * IQR and upper limit as Q3 + 1.5 * IQR.\n",
    "\n",
    "- Any data point outside this range is considered as outlier and should be removed for further analysis.\n",
    "\n",
    "- The concept of quartiles and IQR can best be visualized from the boxplot. It has the minimum and maximum point defined as Q1 – 1.5 * IQR and Q3 + 1.5 * IQR respectively. Any point outside this range is outlier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 939
    },
    "deletable": false,
    "editable": false,
    "id": "2OgPSGZLKZci",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be0944833569dace1e691994dce37ceb",
     "grade": false,
     "grade_id": "import-housing-data",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "f231aee1-d486-42d3-9dfb-9f7a7d751e1c"
   },
   "outputs": [],
   "source": [
    "# reading the dataset \n",
    "df=pd.read_csv('data/housing.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "gyi4BHKsKZci",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb08056a285b7101734cac55130294b3",
     "grade": false,
     "grade_id": "housing-data-desc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "0a12635a-0eef-41f7-a312-9fd7a18cd778"
   },
   "outputs": [],
   "source": [
    "# Description of the dataset\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "IrAZv6fpKZci",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57d9aed6fdb18d93ddebb61bc4b88ad7",
     "grade": false,
     "grade_id": "remove",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is the function to remove special characters.\n",
    "def remove_sign(x,sign):\n",
    "    if type(x) is str:\n",
    "        x = float(x.replace(sign,'').replace(',',''))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "deletable": false,
    "editable": false,
    "id": "dNNPnqG1KZcj",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18a5ac8ece5b125cfaa6a8f7572b92b4",
     "grade": false,
     "grade_id": "initial-box-plot",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "ab76d458-ea58-4127-fa4a-bef77cbda6c3"
   },
   "outputs": [],
   "source": [
    "# See the initial distribution in boxplots.\n",
    "df=df[['price','type']]\n",
    "df=pd.DataFrame(df)\n",
    "\n",
    "df.price = df.price.apply(remove_sign,sign='$')\n",
    "sns.boxplot(y='price', x='type',data=df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Price ($)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "g2ZoKatzKZcj",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9b7d8042a33078b04532e4be0131cb0",
     "grade": false,
     "grade_id": "iqr-implementation",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create function to implement IQR method.\n",
    "#Inter Quartile Range\n",
    "\n",
    "def remove_outlier_IQR(df):\n",
    "    Q1=df.quantile(0.25)\n",
    "    Q3=df.quantile(0.75)\n",
    "    IQR=Q3-Q1\n",
    "    df_final=df[~((df<(Q1-1.5*IQR)) | (df>(Q3+1.5*IQR)))]\n",
    "    return df_final\n",
    "\n",
    "def remove_outlier_ZScore(df):\n",
    "    df_final=df[(np.abs(stats.zscore(df)) < 3)]\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "EW3RPPfMktwn",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c885bddb0a2ad67da9eb71b3e654dda3",
     "grade": false,
     "grade_id": "cell-da269e6460d2c361",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "![IQR](https://editor.analyticsvidhya.com/uploads/15066IQR-Boxplot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "uCDMp5ONivzt",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8cd869069c758febacb335d8ac5a6e7",
     "grade": false,
     "grade_id": "cell-8f874fd290715140",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "e44d87f5-69fb-4834-b1b4-545202c778d5"
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "UNB9XeSWi02L",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0566efbc910dd77df6d8cd33207580fc",
     "grade": false,
     "grade_id": "remove-outliers",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "5604c30e-62af-4211-bdbc-0ee8446e17a7"
   },
   "outputs": [],
   "source": [
    "len(remove_outlier_ZScore(df.price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "ViXuxrKXid5v",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfd806332f71fdc3cd788c791835e640",
     "grade": false,
     "grade_id": "cell-851ac08a9fafcae5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "853357c8-c4bc-4aa9-e2c9-23eaec669908"
   },
   "outputs": [],
   "source": [
    "len(remove_outlier_IQR(df.price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "deletable": false,
    "editable": false,
    "id": "GYcSLZjsKZcj",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51a47d218ee77a0f5d22c46a725e74f9",
     "grade": false,
     "grade_id": "updated-boxplot",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "33d21318-204f-40c7-cde5-81dd4c1eab2e"
   },
   "outputs": [],
   "source": [
    "# Revisit the boxplot after outlier removal. The indices of the bad data points are determined and those are removed from the initial dataset.\n",
    "# Creating the box plot \n",
    "df_outlier_removed=remove_outlier_IQR(df.price)\n",
    "df_outlier_removed=pd.DataFrame(df_outlier_removed)\n",
    "ind_diff=df.index.difference(df_outlier_removed.index)\n",
    "\n",
    "for i in range(0, len(ind_diff),1):\n",
    "    df_final=df.drop([ind_diff[i]])\n",
    "    df=df_final\n",
    "# Creating the box plot   \n",
    "sns.boxplot(y='price', x='type',data=df_final)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Price ($)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "r_hXACbcKZcj",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c4ac5d8a57d96fbeadacbc7e33528227",
     "grade": false,
     "grade_id": "cell-68d3f1ab10984515",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As seen in the boxplot, the majority of the outliers are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_O5p7y9-KZcj",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "918bd52e565346d0f2dff4f43b2f3edc",
     "grade": false,
     "grade_id": "cell-f98bbded339a780f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Check number of outliers removed. The total number of outliers determined by this process is 18722."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "89_n7XVKKZcj",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95b0ad1741d41b1e49ee4fe0a99679fb",
     "grade": false,
     "grade_id": "cell-226eb9ab44f687fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "3f3e2c7f-8424-4b59-ae2c-548aa3ba98cd"
   },
   "outputs": [],
   "source": [
    "len(ind_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "cHmxVREcKZcj",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6450d50d43ccc3dd698fa57a3024ba31",
     "grade": false,
     "grade_id": "note-1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Notes:\n",
    "IQR or Hampel method are very successful for extreme outliers with a single pattern whereas DBSCAN is a better choice if we have data of different patterns. Let’s say if we have a linear data as well as a circular data, DBSCAN will be able to differentiate the samples into different groups. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e04ad93d27ef430be390665ae241c2ca",
     "grade": false,
     "grade_id": "model-selection",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 2. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "kij7oaf6syPb",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "82b2232e3611c458cd662326b81f7333",
     "grade": false,
     "grade_id": "model-selection-w-winedata",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"third-bullet\"></a>\n",
    "Model selection is the task of selecting a model from among various candidates on the basis of performance criterion to choose the best one. In the context of learning, this may be the selection a statistical model from a set of candidate models, given data. The goal of model selection is to find a model that can accurately predict new, unseen data while avoiding overfitting, which occurs when a model is too complex and fits the training data too closely.\n",
    "\n",
    "\n",
    "## 2.1 Model Selection with Wine Dataset\n",
    "We first examine on Wine dataset which is a common one in Machine learning datsets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "CDD2X_3YsyPc",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72067d57a9d84c28ccf32d3efd166b9f",
     "grade": false,
     "grade_id": "read-wine-data",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "8e33c662-2158-4340-b01d-ca06cb618b13"
   },
   "outputs": [],
   "source": [
    "# Load the wine dataset and below function will print the description of the dataset\n",
    "wine = load_wine()\n",
    "print(wine.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "wR-2xLIKsyPc",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d9cb3c9012b1b40588718dbcbb40b23",
     "grade": false,
     "grade_id": "model-selection-steps",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "#### Steps for Model Selection\n",
    "The wine dataset is a multiclass classification problem that involves predicting the type of wine (one of three possible classes) based on 13 numerical features. Here is a general outline of how you might approach model selection for this problem:\n",
    "\n",
    "1. Define the problem: In this case, the problem is to classify the type of wine based on 13 numerical features. The performance metric we want to optimize is classification accuracy.\n",
    "\n",
    "2. Select a set of candidate models: Choose a set of models that are appropriate for the problem and the data. For example, we might consider logistic regression, decision trees, random forests, support vector machines, and neural networks.\n",
    "\n",
    "3. Split the data: Split the wine dataset into training, validation, and test sets. We might use a 60/20/20 split, for example.\n",
    "\n",
    "4. Train and evaluate each model: Train each candidate model on the training set and evaluate its performance on the validation set using the chosen performance metric (classification accuracy). For example, we might use grid search to explore different hyperparameters for each model, such as the regularization strength for logistic regression or the number of trees in a random forest. We would then evaluate the performance of each model using k-fold cross-validation on the training set and choose the best hyperparameters based on the average validation accuracy.\n",
    "\n",
    "5. Select the best model: Compare the performance of each model on the validation set and choose the model with the best performance. In this case, we might choose the random forest model with the best validation accuracy. The final model is then evaluated on the test set to estimate its generalization performance.\n",
    "\n",
    "By following this process, we can ensure that we select the best model for the wine dataset and avoid overfitting to the training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "xqfXxOuasyPc",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a059cb2578fc45374eb9413bc7e44c19",
     "grade": false,
     "grade_id": "building-model",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.2 Building models\n",
    "In this part, we will select the models and build them.\n",
    "\n",
    "The snippets of code below implement the above steps for the Model Selection.  Let's walk through the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "X0ykFHTnsyPd",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "80520d7afb9d4f2f3bbfdd7563fcda57",
     "grade": false,
     "grade_id": "train-test-prep",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Lets split the data as Training set and Valitadion set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "7MEBaTuPVgsW",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0ae55e3df508c8c1a764c009b941829",
     "grade": false,
     "grade_id": "wine-features",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "063fa1c6-1904-4eac-e43e-13da7fd0e90d"
   },
   "outputs": [],
   "source": [
    "wine.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "6TRtbMNAsyPd",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "469a44e91891b2628fa8cf2e559725aa",
     "grade": false,
     "grade_id": "train-test-split",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(wine.data, wine.target, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "B1xzR-k1syPe",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5a7de6d8ce0f5f80407b492bc8f26435",
     "grade": false,
     "grade_id": "cell-8c5d407b61786f78",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Lets choose the candidate models for evaluation. Here we are going with Logistic Regression,\n",
    "Decision Tree, Support Vector classification and Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "iFAh4rrBsyPe",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61dc51610ce4bb577785bee1124e1076",
     "grade": false,
     "grade_id": "list-model-candidates",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define a list of candidate models\n",
    "models = [\n",
    "    ('logistic', LogisticRegression()),\n",
    "    ('decision_tree', DecisionTreeClassifier()),\n",
    "    ('random_forest', RandomForestClassifier()),\n",
    "    ('svm', SVC())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "lcIkF3kwsyPe",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f543f60686b5f12e3c2292cf3eabc95",
     "grade": false,
     "grade_id": "params-dict",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define a dictionary of hyperparameters for each model\n",
    "params = {\n",
    "    'logistic': {'C': [0.1, 1.0, 10.0]},\n",
    "    'decision_tree': {'max_depth': [None, 3, 5]},\n",
    "    'random_forest': {'n_estimators': [10, 50, 100], 'max_depth': [None, 3, 5]},\n",
    "    'svm': {'C': [0.1, 1.0, 10.0], 'kernel': ['linear', 'rbf']},\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "imdhtbwFsyPe",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "efdae997b4066e701016159c195824df",
     "grade": false,
     "grade_id": "cell-018aab106ddf3394",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "404c9558-ff9b-4345-bd70-c1bf11dc4390"
   },
   "outputs": [],
   "source": [
    "# Iterate over each model and perform grid search to find the best hyperparameters\n",
    "best_model = None\n",
    "best_accuracy = 0.0\n",
    "for name, model in models:\n",
    "    grid_search = GridSearchCV(model, params[name], cv=5)\n",
    "    grid_search.fit(X_trainval, y_trainval)\n",
    "    accuracy = grid_search.score(X_val, y_val)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_accuracy = accuracy\n",
    "    print(f\"{name}: validation accuracy = {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "SJSMJ5kxsyPf",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f38715ab3f743c5300fdc231ef9c7f51",
     "grade": false,
     "grade_id": "evaluate-models",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "0231570d-83cf-411d-e24a-1151bf080d2e"
   },
   "outputs": [],
   "source": [
    "# Evaluate the best model on the test set\n",
    "test_accuracy = accuracy_score(y_test, best_model.predict(X_test))\n",
    "print(f\"Best model ({type(best_model).__name__}): test accuracy = {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "KAXWSJ_esyPf",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "01b2fa40be74b0388b6f46a6f8f457c3",
     "grade": false,
     "grade_id": "cell-083a0fe4028fb46d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This code defines a list of candidate models (logistic regression, decision tree, random forest, SVM, and neural network), as well as a dictionary of hyperparameters for each model. It then iterates over each model, performs grid search to find the best hyperparameters, and evaluates the performance of each model on the validation set. The best model is selected based on the highest validation accuracy, and the final model is evaluated on the test set to estimate its generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "GW_QPtf5syPf",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b8d7310f8dae98e462d5458c340f314e",
     "grade": false,
     "grade_id": "cell-320469097f6417dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"Histogram\"></div>\n",
    "These histograms show the distribution of feature values for the first two features of the Wine dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "deletable": false,
    "editable": false,
    "id": "XKiPruR8syPf",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68295d854e011b85430a754eb3209f95",
     "grade": false,
     "grade_id": "cell-b6a2db3303e0fe52",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "82ffd2d7-be54-44d6-c6d4-015668c655b4"
   },
   "outputs": [],
   "source": [
    "# Plot histograms of feature values for the first two features\n",
    "plt.hist(wine.data[:, 0], bins=20)\n",
    "plt.xlabel('Feature 0')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(wine.data[:, 1], bins=20)\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "aM6Zx_gqsyPf",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e5f732e3831c2847f8471c38fc83a381",
     "grade": false,
     "grade_id": "cell-3b88d1ea87ba1f77",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This scatter plot shows the relationship between two features of the Wine dataset, with different colors indicating the target classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4a4dbabb0238b3238cf79c194362097d",
     "grade": false,
     "grade_id": "question-1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"exercise\"><b>Question 1: Interpreting Feature Distributions</b> \n",
    "    The histograms above show the distribution of two features from the Wine dataset. One of the distributions appears approximately normal, while the other is skewed. What could be the reason for this skewness?</div>\n",
    "\n",
    "1. The skewed distribution suggests that the feature has a natural asymmetry, possibly due to physical or chemical properties of the wine.\n",
    "2. The skewness is caused by an error in data collection, and the dataset should be cleaned before further analysis.\n",
    "3. The skewness occurs because the feature represents a categorical variable incorrectly encoded as numerical values.\n",
    "4. The skewness is irrelevant and does not affect model selection or data preprocessing.\n",
    "\n",
    "\n",
    "**Store your answer to a variable called `answer` in below code cell:**\n",
    "\n",
    "Example code:\n",
    "```python\n",
    "answer = 4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4cf51939c1a8e1864eea5f400aa09821",
     "grade": false,
     "grade_id": "question-1-implementation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a58f3ac2ce157cd4b2bf9c4f0c2bc073",
     "grade": true,
     "grade_id": "cell-13f4ef784a95d26f",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "deletable": false,
    "editable": false,
    "id": "SaM-_FoVsyPf",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d3ffc83f5434e78fb5267da14589a518",
     "grade": false,
     "grade_id": "cell-d89faf2cf3a7ae71",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "1a0c2871-c4c9-4637-dd7e-290f5288ff74"
   },
   "outputs": [],
   "source": [
    "# Plot a scatter plot of two features\n",
    "plt.scatter(wine.data[:, 0], wine.data[:, 1], c=wine.target)\n",
    "plt.xlabel('Feature 0')\n",
    "plt.ylabel('Feature 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Ad0DjSIMKZck",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a22aad328301d296ced7f3a6247b72a4",
     "grade": false,
     "grade_id": "cell-59520b658fa12842",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Below code uses the pairplot function from the seaborn library to create a scatter plot matrix of all pairwise combinations of features in the Wine dataset. The hue parameter is set to the target variable, which is used to color-code the points based on their target class. The diag_kind parameter is set to 'hist', which plots histograms of each feature on the diagonal instead of scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "deletable": false,
    "editable": false,
    "id": "kgLPr8gmKZck",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "634fcbc5bb05bfdd99cb913deb75131e",
     "grade": false,
     "grade_id": "cell-637a90e32b015d83",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "05e0736f-00d3-45cc-bc8c-f047a250edef"
   },
   "outputs": [],
   "source": [
    "# Pair wise scatter plot\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine = load_wine()\n",
    "\n",
    "# Create a DataFrame from the Wine dataset\n",
    "df = pd.DataFrame(data=wine.data, columns=wine.feature_names)\n",
    "df['target'] = wine.target\n",
    "\n",
    "# Create a pairwise scatter plot\n",
    "sns.pairplot(data=df, hue='target', diag_kind='hist')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "qKjoNvbXsyPg",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "66a1a6f16dc4227c4ebfddde7f0778ba",
     "grade": false,
     "grade_id": "cell-5cd8b49fa5ba889e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This confusion matrix shows the number of true positives, true negatives, false positives, and false negatives for each class of the Wine dataset, based on the predictions of the best model on the validation set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f2e54faec9e0a5dcd2364c806737fbba",
     "grade": false,
     "grade_id": "question-2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"exercise\"><b>Question 2: Understanding the Pairwise Scatter Plot</b> The pairwise scatter plot above visualizes relationships between all numerical features in the Wine dataset, with color coding based on wine type (target variable).\n",
    "\n",
    "Which of the following statements best describes insights that can be gained from this plot?</div>\n",
    "\n",
    "1. The scatter plots suggest that all features are independent and uncorrelated, making feature selection unnecessary.\n",
    "2. Some features show clear separation between different wine classes, indicating that classification models can achieve good accuracy.\n",
    "3. The histograms on the diagonal confirm that all features follow a perfect normal distribution.\n",
    "4. The scatter plots indicate that the dataset has a significant number of missing values, which may impact model performance.\n",
    "\n",
    "**Store your answer to a variable called `answer` in below code cell:**\n",
    "\n",
    "Example code:\n",
    "```python\n",
    "answer = 4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b504676900e3d9c8bd08a6a755d5ed6",
     "grade": false,
     "grade_id": "question-2-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c30f3c23a301910c90cd00ddc516ba2",
     "grade": true,
     "grade_id": "question-2-tests",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "deletable": false,
    "editable": false,
    "id": "c2ovXK7msyPg",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c6af137523515b2baf665ce9351e4c76",
     "grade": false,
     "grade_id": "cell-e1a56151ae2b79e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "a56d0707-195a-4fdf-d303-a1cbfec1cb3e"
   },
   "outputs": [],
   "source": [
    "\"\"\"from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# Plot a confusion matrix for the best model\n",
    "plot_confusion_matrix(best_model, X_val, y_val)\n",
    "plt.show()\"\"\"\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Plot a confusion matrix for the best model\n",
    "ConfusionMatrixDisplay.from_estimator(best_model, X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "0VBU-rhjsyPg",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f3a17e5b6cb63e82614ecd3c35413b57",
     "grade": false,
     "grade_id": "question-3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"exercise\"><b>Question 3: Interpreting the Confusion Matrix</b> The confusion matrix above represents the classification performance of the best model on the validation set of the Wine dataset.\n",
    "\n",
    "Which of the following statements best describes the model's performance based on this confusion matrix?</div>\n",
    "\n",
    "1. The model has a perfect classification accuracy, as there are no misclassified instances.\n",
    "2. The model correctly classifies most samples, but some misclassifications exist, which can be reduced with further hyperparameter tuning.\n",
    "3. The model struggles with classifying at least one class, as evident from a high number of misclassifications.\n",
    "4. The model performs poorly overall, as indicated by the presence of many false positives and false negatives.\n",
    "\n",
    "**Store your answer to a variable called `answer` in below code cell:**\n",
    "\n",
    "Example code:\n",
    "```python\n",
    "answer = 4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49afd4c07949ea7cea4738fa1ed4b3ce",
     "grade": false,
     "grade_id": "question-3-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e68dfe956e7fa52f6436b899dee4281",
     "grade": true,
     "grade_id": "question-3-tests",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "deletable": false,
    "editable": false,
    "id": "jCLKaKlfsyPg",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d2e0e89363c65b2c0e3a82024d2e543",
     "grade": false,
     "grade_id": "corr-matrix-compute",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "994b38bd-fde1-46c7-be25-86b1b5434796"
   },
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = np.corrcoef(wine.data.T)\n",
    "\n",
    "# Plot a heatmap of the correlation matrix\n",
    "sns.heatmap(corr, cmap='coolwarm', xticklabels=wine.feature_names,\n",
    "            yticklabels=wine.feature_names, annot=True, fmt='.2f')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "db7126a56bfd6779cc64753f579385dd",
     "grade": false,
     "grade_id": "question-4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"exercise\"><b>Question 4: Interpreting the Correlation Heatmap</b> The heatmap above displays the correlation between numerical features in the Wine dataset. A correlation value close to 1.0 indicates a strong positive correlation, while a value close to -1.0 indicates a strong negative correlation.\n",
    "\n",
    "Which of the following conclusions can be drawn from the correlation heatmap?</div>\n",
    "\n",
    "1. Some features are highly correlated, which suggests that dimensionality reduction techniques like PCA could be beneficial.\n",
    "2. All features have very weak correlations with each other, meaning each contributes independently to the classification task.\n",
    "3. The heatmap suggests that the dataset has missing values, as indicated by empty or zero correlation values.\n",
    "4. There is no relationship between any of the features, so feature selection is unnecessary.\n",
    "\n",
    "**Store your answer to a variable called `answer` in below code cell:**\n",
    "\n",
    "Example code:\n",
    "```python\n",
    "answer = 4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed72fd6aafa3c8d4a448f15c63d9814b",
     "grade": false,
     "grade_id": "question-4-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93815033493413b17003d5bd8351c2fe",
     "grade": true,
     "grade_id": "question-4-tests",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ouyJYrJnsyPg",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a859746f6907a62dec3920ef4c34e31",
     "grade": false,
     "grade_id": "cell-1d004cbf4e6192c0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Below learning curve shows how the accuracy of the best model improves as the size of the training set increases, based on cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "deletable": false,
    "editable": false,
    "id": "tzDC-jH8syPg",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9520e9d014c861d982ac99b08539234",
     "grade": false,
     "grade_id": "cell-8458aaaf16c9b4f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "4f8fcacc-4f26-428a-df03-c016d789abb1"
   },
   "outputs": [],
   "source": [
    "# Plot a learning curve for the best model\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(best_model, X_train, y_train,\n",
    "                                                        train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "                                                        cv=5, scoring='accuracy')\n",
    "\n",
    "plt.plot(train_sizes, np.mean(train_scores, axis=1), label='Training score')\n",
    "plt.plot(train_sizes, np.mean(val_scores, axis=1), label='Validation score')\n",
    "plt.xlabel('Training set size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Ue6p-LgAsyPg",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "90b1758e2f8a68f81987f7fdbbba5966",
     "grade": false,
     "grade_id": "cell-c668e2ff9169a580",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Below scatter plot shows the projection of the Wine dataset onto the first two principal components, with different colors indicating the target classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "deletable": false,
    "editable": false,
    "id": "BQPe8EVfsyPg",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7453b7e9ee33ddea2ddd8546a36a94eb",
     "grade": false,
     "grade_id": "cell-0d83a8a56acb7e20",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "569029d6-34bd-480f-f920-8bbd214b2314"
   },
   "outputs": [],
   "source": [
    "# Fit PCA to the Wine dataset\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(wine.data)\n",
    "\n",
    "# Plot a scatter plot of the first two principal components\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=wine.target)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "MU0rC3hrsyPg",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f5af3295a7fe425658aaaa346390f13",
     "grade": false,
     "grade_id": "cell-1c61bb912ebdedee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Below bar chart shows the feature importances of the best model based on permutation importance, which measures the decrease in accuracy when a feature is randomly permuted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "deletable": false,
    "editable": false,
    "id": "AAcYuPiZsyPg",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "92620909bb61e929d510c34c0b88fc55",
     "grade": false,
     "grade_id": "cell-a1b1c1ebe3c0636c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "3724f735-cf0c-4c6b-d5b7-2b74b2e5d875"
   },
   "outputs": [],
   "source": [
    "# Compute the feature importances using permutation importance\n",
    "result = permutation_importance(best_model, X_val, y_val, n_repeats=10, random_state=0)\n",
    "importances = result.importances_mean\n",
    "\n",
    "# Plot a bar chart of the feature importances\n",
    "plt.bar(wine.feature_names, importances)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "W0QNPrPn-Mmv",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "14b2b7e34d0dcd8d96572211420a33d0",
     "grade": false,
     "grade_id": "cell-5992bb51d388a4a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We loaded the wine dataset and then extracted the features (X) and target (y) from the dataset. Next, we use scikit-learn's SelectKBest class to select the 5 best features using the chi-squared statistical test (chi2). Finally, we transform the original feature matrix X into the K-best feature matrix X_kbest using the fit_transform method of the SelectKBest object.\n",
    "\n",
    "Note that in this example, we set k=5, which means we're selecting the 5 best features. You can adjust this value to select a different number of features depending on your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "VMd-r9I_KZcl",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb527f40471de8ab9c3a9ad71b73fdf7",
     "grade": false,
     "grade_id": "cell-4188100540748532",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "309d1512-97e6-4f49-e9d9-6c1de4e673b8"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Load the wine dataset\n",
    "wine = load_wine()\n",
    "\n",
    "# Extract the features and target\n",
    "X, y = wine.data, wine.target\n",
    "\n",
    "# Use chi-squared statistical test to select the K-best features\n",
    "selector = SelectKBest(chi2, k=5)\n",
    "X_kbest = selector.fit_transform(X, y)\n",
    "\n",
    "# Print the indices of the selected features\n",
    "print(selector.get_support(indices=True))\n",
    "wine.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "afMdtzWysyPh",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3b7a81146d10d9850387eda4fdf6a9ab",
     "grade": false,
     "grade_id": "cross-validation",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 3. Cross Validation\n",
    "Now lets see some problems in cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "tFrHE3FPsyPh",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf89523ae38391df7b03f5e458c3e23b",
     "grade": false,
     "grade_id": "about-cross-validation",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- `Cross-validation` is a technique used in machine learning to evaluate the performance of a model on an independent dataset.\n",
    "- It involves partitioning the original dataset into multiple subsets, called folds, and training the model on a subset of the data while using the remaining data for validation. \n",
    "- This process is repeated multiple times, with each fold used once for validation and the other folds used for training.\n",
    "- `Cross-validation` is a useful technique because it provides a more robust estimate of the model's performance than a single train-test split. \n",
    "- By using multiple splits of the data, cross-validation reduces the risk of overfitting or underfitting to a particular dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "Xm1n2ni7ochM",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63b12bdfabec3e5f3e1a656b0715fd49",
     "grade": false,
     "grade_id": "cell-43f6585b2a22cae1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "2631362e-32de-4a08-9838-3db2171b3c0a"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Set X and y variables\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Initialize Logistic Regression object\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "\n",
    "# Fit the model on the training set\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of validation set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy score:\", acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Cl6Io7u3syPh",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b92fd1df314f02ef3e58694a47a6b19a",
     "grade": false,
     "grade_id": "iris-data",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Lets Play with Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "xeRR0lZcKZcl",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9e9d3155909cd4a20a4d0ae29357ddd",
     "grade": false,
     "grade_id": "cell-ecafef753faf0271",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "4a80508a-09dc-4a58-c6d0-acb74e8b337c"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Set X and y variables\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Define number of folds for cross-validation\n",
    "n_folds = 5\n",
    "\n",
    "# Initialize KFold object\n",
    "kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "# Initialize Logistic Regression object\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Initialize empty list to store accuracy scores\n",
    "scores = []\n",
    "\n",
    "# Loop through each fold and train the model\n",
    "for train_idx, val_idx in kf.split(X):\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_val, y_val = X[val_idx], y[val_idx]\n",
    "\n",
    "    # Fit the model on the training set\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels of validation set\n",
    "    y_pred = logreg.predict(X_val)\n",
    "\n",
    "    # Calculate the accuracy score and append to scores list\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    scores.append(acc)\n",
    "    \n",
    "# Calculate the average accuracy score\n",
    "avg_score = sum(scores) / len(scores)\n",
    "\n",
    "print(\"Cross-validation average accuracy score:\", avg_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Yd9MBg-HKZcl",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "deb634ae2b0b48dc7cdfa7511b1de3e0",
     "grade": false,
     "grade_id": "note-2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Notes:\n",
    "In this example, we load the iris dataset and split it into X and y variables. We then define the number of folds for cross-validation and initialize a KFold object. We also initialize a Logistic Regression object and an empty list to store accuracy scores.\n",
    "We loop through each fold, split the data into training and validation sets, fit the logistic regression model on the training set, and predict the labels of the validation set. We then calculate the accuracy score and append it to the scores list.\n",
    "\n",
    "After all the folds are processed, we calculate the average accuracy score by summing the scores and dividing by the number of folds. Finally, we print the average accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "byh4zWr_XuqR",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "032a31d3edcfe56f334512638e1ccc4b",
     "grade": false,
     "grade_id": "cell-37b03e90e879321d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "c4eedbf2-ad32-4e0d-fe79-20d478341cb9"
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "deletable": false,
    "editable": false,
    "id": "-fzeomnqKZcl",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0b2afea8c917f57053048f353e57ad6",
     "grade": false,
     "grade_id": "cell-df73a44a6ae36cf0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "585a115a-d750-4d01-b9e9-ed142eec7090"
   },
   "outputs": [],
   "source": [
    "# Create a histogram of accuracy scores\n",
    "plt.hist(scores, bins=10)\n",
    "plt.title('Accuracy Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "SRVmLdYXKZcm",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f65a88d2ed60131a8f04e58512b3ba1f",
     "grade": false,
     "grade_id": "cell-4c2c470f50be29d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The below code will create a line plot that shows how the cross-validation average accuracy score changes as the number of folds increases. The line plot will show if increasing the number of folds improves or decreases the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "deletable": false,
    "editable": false,
    "id": "1gHu4-pFKZcm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17bbca77f4ed4f32c80c72d8e711d1bf",
     "grade": false,
     "grade_id": "cell-124e3baf73f1e95f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "c7821b7e-3c15-4aa8-fde2-630049424ebf"
   },
   "outputs": [],
   "source": [
    "# Initialize empty list to store average scores\n",
    "avg_scores = []\n",
    "\n",
    "lower_fold_range = 2\n",
    "upper_fold_range = 11\n",
    "\n",
    "# Loop through different values of n_folds\n",
    "for n_folds in range(lower_fold_range, upper_fold_range):\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "    scores = []\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_val, y_val = X[val_idx], y[val_idx]\n",
    "        logreg.fit(X_train, y_train)\n",
    "        y_pred = logreg.predict(X_val)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        scores.append(acc)\n",
    "    avg_score = sum(scores) / len(scores)\n",
    "    avg_scores.append(avg_score)\n",
    "\n",
    "# Create a line plot of average scores\n",
    "plt.plot(range(lower_fold_range, upper_fold_range), avg_scores)\n",
    "plt.title('Cross-Validation Average Accuracy Scores')\n",
    "plt.xlabel('Number of Folds')\n",
    "plt.ylabel('Average Accuracy Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "pQyXfoltKZcm",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3574d2d2b99a85c9b809dca669b1affc",
     "grade": false,
     "grade_id": "k-fold-cross-validation",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.1 K Fold Cross Validation\n",
    "\n",
    "k-Fold cross-validation is a technique that minimizes the disadvantages of the hold-out method. k-Fold introduces a new way of splitting the dataset which helps to overcome the “test only once bottleneck”.\n",
    "\n",
    "The algorithm of the k-Fold technique:\n",
    "\n",
    "1. Pick a number of folds – k. Usually, k is 5 or 10 but you can choose any number which is less than the dataset’s length.\n",
    "2. Split the dataset into k equal (if possible) parts (they are called folds)\n",
    "3. Choose k – 1 folds as the training set. The remaining fold will be the test set\n",
    "4. Train the model on the training set. On each iteration of cross-validation, you must train a new model independently of the model trained on the previous iteration\n",
    "5. Validate on the test set\n",
    "6. Save the result of the validation\n",
    "7. Repeat steps 3 – 6 k times. Each time use the remaining  fold as the test set. In the end, you should have validated the model on every fold that you have.\n",
    "8. To get the final score average the results that you got on step 6.\n",
    "\n",
    "Change the value of k in the cell below to see how it affects the validation score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "23VPfA1UKZcm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a233b13e7dec9bb5b95fbd3ca7ee0db",
     "grade": false,
     "grade_id": "cell-3657d480624c8782",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "bfc32bef-d519-4993-803b-964a98cf6d85"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Set X and y variables\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Define number of folds for cross-validation\n",
    "k = 5\n",
    "\n",
    "# Initialize KFold object\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "# Initialize Logistic Regression object\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Initialize empty list to store accuracy scores\n",
    "scores = []\n",
    "\n",
    "# Loop through each fold and train the model\n",
    "for train_idx, val_idx in kf.split(X):\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_val, y_val = X[val_idx], y[val_idx]\n",
    "\n",
    "    # Fit the model on the training set\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels of validation set\n",
    "    y_pred = logreg.predict(X_val)\n",
    "\n",
    "    # Calculate the accuracy score and append to scores list\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    scores.append(acc)\n",
    "\n",
    "# Calculate the average accuracy score\n",
    "avg_score = sum(scores) / len(scores)\n",
    "\n",
    "print(\"Cross-validation average accuracy score:\", avg_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7NdHbDA8KZcm",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "03eb287435676d7d29f7c734ec949bfc",
     "grade": false,
     "grade_id": "cell-3528c43a7207eca6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the code above, we set k to 5 for 5-fold cross-validation. We then initialize a KFold object with n_splits parameter set to k and shuffle parameter set to True to shuffle the data before splitting it into folds.\n",
    "\n",
    "We looped through each fold, split the data into training and validation sets, fit the logistic regression model on the training set, and predict the labels of the validation set. We then calculate the accuracy score and append it to the scores list.\n",
    "\n",
    "After all the folds are processed, we calculate the average accuracy score by summing the scores list and dividing by the number of folds. Finally, we print the average accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "deletable": false,
    "editable": false,
    "id": "vqEe7BdSKZcm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c6d25851bbd34b7cf64b8765c9f401b6",
     "grade": false,
     "grade_id": "cell-fcdc77ff424318e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "b00a7def-0062-4378-c685-214896268fa6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(model, X, y, cv=10, n_jobs=-1)\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean, label='Training score')\n",
    "plt.plot(train_sizes, val_mean, label='Cross-validation score')\n",
    "\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1)\n",
    "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1)\n",
    "\n",
    "plt.xlabel('Number of training examples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Rs5IBGNAKZcm",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3d53facff4d7e36b6c9b671452b9fc25",
     "grade": false,
     "grade_id": "cell-281be1b038d13231",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The above code will plot the learning curves for the model. The learning curves plot the accuracy of the model on the training and validation sets as a function of the number of training examples. If the gap between the training and validation scores is large, it could indicate overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "deletable": false,
    "editable": false,
    "id": "Liq0ldrIKZcm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f1432a24df8aca8de7a8f76bd620281",
     "grade": false,
     "grade_id": "cell-ea698e3c7f8fab5b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "c96dde3d-8b66-402e-c39c-21a7225ff62d"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=10)\n",
    "plt.boxplot(scores)\n",
    "plt.title('Cross-validation scores')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "deletable": false,
    "editable": false,
    "id": "P6ZlX3HWKZcm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc8f85c08fbebd30840df8dafa3ed0cf",
     "grade": false,
     "grade_id": "cell-2a33759c31e953c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "1e5f0f39-ac74-4b96-b155-a3d278169926"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    model, X, y, cv=kf, scoring='neg_mean_squared_error', train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "\n",
    "train_scores_mean = -np.mean(train_scores, axis=1)\n",
    "test_scores_mean = -np.mean(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', label='Training score')\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', label='Cross-validation score')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Training examples')\n",
    "plt.ylabel('Negative mean squared error')\n",
    "plt.title('Learning curves')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "qoq_Yyy1KZcm",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "04da3c3744445f42a0f8418f63580271",
     "grade": false,
     "grade_id": "cell-668c888b58423069",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Learning curves: Learning curves show the training and validation scores for a model as a function of the size of the training set. By plotting learning curves for each fold of the cross-validation, you can get an idea of how the model's performance changes as the amount of training data increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8143987bc912eb8b0f8c1210af39c1ff",
     "grade": false,
     "grade_id": "question-5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"exercise\"><b>Question 5: Evaluating Cross-Validation and Learning Curves</b> The plots above from section 3. Cross Validation illustrate different aspects of cross-validation and learning curves for a logistic regression model trained on the Iris dataset.\n",
    "\n",
    "Which of the following statements best describes insights gained from these visualizations?</div>\n",
    "\n",
    "1. Cross-validation accuracy improves indefinitely as the number of folds increases, indicating that using the maximum number of folds always results in the best model.\n",
    "2. The learning curves indicate a high bias model since the training and validation scores remain consistently low across all training set sizes.\n",
    "3. The learning curves suggest that as more training data is added, the validation accuracy improves while the training accuracy slightly decreases, reducing overfitting.\n",
    "4. The cross-validation boxplot indicates that model performance varies significantly across different folds, suggesting instability in the learning process.\n",
    "\n",
    "**Store your answer to a variable called `answer` in below code cell:**\n",
    "\n",
    "Example code:\n",
    "```python\n",
    "answer = 4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3604ad95bebf36d6922268ac5ba87947",
     "grade": false,
     "grade_id": "question-5-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0480fe0d337add5969169a866eed40fd",
     "grade": true,
     "grade_id": "quesion-5-tests",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "deletable": false,
    "editable": false,
    "id": "NSjWtogoKZcm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60702b47b714a42f8fb8bfdbfee9c5f5",
     "grade": false,
     "grade_id": "cell-f869289e4fa59144",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "3368f803-ecf8-4c7e-a820-39078f182bbd"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 5, figsize=(20, 8))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    axs[i].scatter(y_test, y_pred - y_test)\n",
    "    axs[i].axhline(y=0, color='black', linestyle='--')\n",
    "    axs[i].set_title(f'Fold {i+1}')\n",
    "\n",
    "plt.suptitle('Residual plots')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "RENIkmgcKZcm",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27f833fd4966390a8bf45adb9b06cd6c",
     "grade": false,
     "grade_id": "cell-14bd77a4e3744328",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Residual plots: Residual plots show the difference between the predicted and actual values as a function of the actual values. By plotting residual plots for each fold of the cross-validation, you can get an idea of how well the model is fitting the data and whether there are any patterns in the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "deletable": false,
    "editable": false,
    "id": "GYS0a8RwKZcm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e02644e970638892e9301e4321bf85d5",
     "grade": false,
     "grade_id": "cell-8eecde32bb320094",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "407621ee-bfb0-4d09-d4b1-ac1a9df7322a"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(model, X_train, y_train, cv=5)\n",
    "    \n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    ax.plot(train_sizes, train_mean, label=f'Train Fold {i+1}')\n",
    "    ax.plot(train_sizes, test_mean, label=f'Test Fold {i+1}')\n",
    "    \n",
    "ax.set_xlabel('Training examples')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ukTmVFIqKZcm",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "85aa4d9fd4151918683b4bbb012a2974",
     "grade": false,
     "grade_id": "cell-4234cb9a674065c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Above code creates learning curves for each fold of the k-fold cross-validation. The learning curves can help to identify if the model is overfitting or underfitting for any particular fold.\n",
    "\n",
    "These visualizations can help to diagnose issues with the model or the data and improve the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "wCwQswPYKZcn",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "17be0ae1aff37b98fa897c92fb76271b",
     "grade": false,
     "grade_id": "cell-9dd915cc54a47fb8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.2 Leave-One-Out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "EmNlJ4f4KZcn",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25209ef9e6a25e3374a98da17730f812",
     "grade": false,
     "grade_id": "cell-6e2d8f7768f65710",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "4af29461-03fb-4ef1-930f-f96f5ea67cf9"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(f'Mean accuracy: {np.mean(accuracy_scores):.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "j-6VNPN_KZcn",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47f9665bffc097f1ce8d0a4daafa40f4",
     "grade": false,
     "grade_id": "note-3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Notes:\n",
    "In this example, we use the LeaveOneOut class to split the data into training and testing sets for each sample in the dataset. We then fit the logistic regression model on the training data and compute the accuracy score on the testing data. Finally, we calculate the mean accuracy score across all the samples in the dataset.\n",
    "\n",
    "Note that LOOCV can be very computationally expensive, especially for larger datasets, since it involves fitting the model n times (where n is the number of samples in the dataset). Therefore, it is generally recommended to use k-fold cross-validation instead, unless the dataset is very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "deletable": false,
    "editable": false,
    "id": "w7U65JJPKZcn",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61a98395c242ee9ef9e19357f4ac01e9",
     "grade": false,
     "grade_id": "cell-8300dfc6da498843",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "9ce2a504-d1d2-4739-88e0-d2171486f551"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Plot accuracy scores for each sample\n",
    "plt.plot(np.arange(len(accuracy_scores)), accuracy_scores)\n",
    "plt.axhline(np.mean(accuracy_scores), color='r', linestyle='--', label='Mean accuracy')\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Leave-One-Out Cross Validation for Iris Dataset')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "32npZZ-bKZcn",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "17a650da1c67bfb8a5dad5541a3dd146",
     "grade": false,
     "grade_id": "cell-d93d4bf38d306b24",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the above example, we plot the accuracy score for each individual sample in the dataset, as well as a horizontal line representing the mean accuracy score across all the samples. This can be a useful way to visualize the performance of the model on each individual sample, and to detect any outliers or unusual patterns in the accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "deletable": false,
    "editable": false,
    "id": "v_VO1aXRKZcn",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c6f8c6ceb0e975a736ed0754569dee0",
     "grade": false,
     "grade_id": "cell-c1940436925097d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "e17ed2e1-22d5-4852-ed70-d3e4790937c5"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_true.append(y_test[0])\n",
    "    y_pred.append(model.predict(X_test)[0])\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "ax.set(xticks=np.arange(cm.shape[1]),\n",
    "       yticks=np.arange(cm.shape[0]),\n",
    "       xticklabels=iris.target_names, yticklabels=iris.target_names,\n",
    "       xlabel='Predicted label', ylabel='True label',\n",
    "       title='Confusion matrix for Iris dataset (LOOCV)')\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "fmt = 'd'\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm[i, j], fmt),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "L03xiY7iKZcn",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "83dccfb8d20eb7772f2f71d55f1a8882",
     "grade": false,
     "grade_id": "cell-2c9eab40e5a0ea1e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the above example, we computed a confusion matrix for the model's predictions on the Iris dataset, using LOOCV to evaluate the performance. We then plot the confusion matrix as a heatmap, with the true labels on the y-axis and the predicted labels on the x-axis. This can be a useful way to visualize the model's performance across different classes, and to identify any patterns of misclassification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "deletable": false,
    "editable": false,
    "id": "uuxTsXzNKZcn",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0fc57f477ef0b8e58699873d14eb7610",
     "grade": false,
     "grade_id": "cell-6b6935ee9c1376ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "804117b2-5f32-49ee-c9ca-29e2e3f50e59"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "X, y = make_classification(n_samples=100, n_features=5, n_informative=3, random_state=42)\n",
    "\n",
    "# Define the model and the Leave-One-Out Cross Validation object\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Initialize the confusion matrix\n",
    "cm = np.zeros((2, 2))\n",
    "\n",
    "# Loop over the LOO splits and train/test the model\n",
    "for train_idx, test_idx in loo.split(X):\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Update the confusion matrix\n",
    "    cm[y_test, y_pred] += 1\n",
    "\n",
    "# Compute the accuracy and display the confusion matrix\n",
    "accuracy = np.sum(np.diag(cm)) / np.sum(cm)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "plt.title('Confusion matrix for Logistic Regression (LOOCV)')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.xticks([0, 1], ['Negative', 'Positive'])\n",
    "plt.yticks([0, 1], ['Negative', 'Positive'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Yob8b2SCKZcn",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "64fb45368d65e56485bb506fa7e08dd6",
     "grade": false,
     "grade_id": "cell-d497834a198f5bdf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the above example, we generated a synthetic dataset and train a logistic regression model on it, using LOOCV to evaluate the performance. For each split, we compute the confusion matrix (the number of true positives, true negatives, false positives, and false negatives), and we accumulate the results over all splits. We then display the overall accuracy and the confusion matrix as a heatmap. This can be a useful way to visualize the model's performance and to identify any patterns in the errors that the model is making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f0098e4660a94b172e9d9a8609264f16",
     "grade": false,
     "grade_id": "question-6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"exercise\"><b>Question 6: Evaluating LOOCV Performance</b> The visualizations above show accuracy trends and confusion matrices for models trained using Leave-One-Out Cross-Validation (LOOCV) on the Iris dataset and a synthetic dataset.\n",
    "\n",
    "Which of the following statements best describes insights gained from these visualizations?</div>\n",
    "\n",
    "1. LOOCV produces high variance in accuracy scores due to training on nearly all data except one sample at a time, leading to occasional misclassifications.\n",
    "2. The confusion matrices indicate that LOOCV is not suitable for small datasets, as it fails to produce meaningful classification results.\n",
    "3. The LOOCV accuracy is significantly lower than k-fold cross-validation, suggesting it is not a reliable evaluation method.\n",
    "4. The confusion matrices show that LOOCV guarantees perfect classification, as every sample is used for training except one at each iteration.\n",
    "\n",
    "**Store your answer to a variable called `answer` in below code cell:**\n",
    "\n",
    "Example code:\n",
    "```python\n",
    "answer = 4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e5481219cb2323bc2757c8983ff5b9fe",
     "grade": false,
     "grade_id": "question-6-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da7b08280e62ee847dde60ccd64ed1cb",
     "grade": true,
     "grade_id": "question-6-tests",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "728b55fcbf6d3208654ec24b63f2d20b",
     "grade": false,
     "grade_id": "end",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "interpreter": {
   "hash": "57990f1ad2ea89c67ddae7f31d40c478205c5912da0fccfb7c5cfbb2b8bf17ad"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
