{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73504a8e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4fb825f2d0c7d0e9370f6a3de07e8822",
     "grade": false,
     "grade_id": "cell-30c623fb2066bfc0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class='heading'>\n",
    "    <div style='float:left;'><h1>CPSC 4300/6300: Applied Data Science</h1></div>\n",
    "    <img style=\"float: right; padding-right: 10px; width: 65px\" src=\"https://bsethwalker.github.io/assets/img/clemson_paw.png\"> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b89b435",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e2a724552a4d714ca462488310089a7d",
     "grade": false,
     "grade_id": "cell-66f83eaea1905a54",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Week 6 | Lab 2: Outlier Detection, Model Selection and Cross Validation\n",
    "\n",
    "**Clemson University**<br>\n",
    "**Instructor(s):** Tim Ransom<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this lab, you should be able to:\n",
    "* Feel comfortable with splitting the training and validation sets\n",
    "* Feel comfortable with model selection\n",
    "* Feel comfortable with selecting the best model out of selected ones\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdc84b0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2a44f9707417d278808718e62a6c9b2",
     "grade": false,
     "grade_id": "cell-4161298b865af7e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" RUN THIS CELL TO GET THE RIGHT FORMATTING \"\"\"\n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "css_file = 'https://raw.githubusercontent.com/bsethwalker/clemson-cs4300/main/css/cpsc6300.css'\n",
    "styles = requests.get(css_file).text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61398718",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c25c9cbdc7f814e72947c4d3a7a76b4a",
     "grade": false,
     "grade_id": "cell-56747a90e4f063f0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Outlier Detection, Model Selection, and Cross Validation\n",
    "\n",
    "Outline of the topics in this notebook:\n",
    "\n",
    "1.  **Outlier Detection**\n",
    "    -   Interquartile Range (IQR) method\n",
    "    -   z-score detection\n",
    "2.  **Model Selection**\n",
    "    -   Using `scikit-learn` pipelines\n",
    "    -   Linear Regression\n",
    "    -   k-Nearest Neighbors (kNN)\n",
    "3.  **Cross Validation**\n",
    "    -   k-fold validation\n",
    "    -   Leave-One-Out validation\n",
    "\n",
    "In this lab, you will:\n",
    "\n",
    "1.  Understand why outliers can be problematic and learn common\n",
    "    techniques to detect them.\n",
    "2.  Explore different model selection procedures and how to set up\n",
    "    pipelines.\n",
    "3.  Implement cross validation methods to evaluate model performance.\n",
    "\n",
    "**Why is this important to data scientists?**\n",
    "\n",
    "-   Outlier detection ensures that models are not misled by extreme or\n",
    "    unusual values, improving robustness.\n",
    "-   Proper model selection and hyperparameter tuning can drastically\n",
    "    improve predictive performance and efficiency.\n",
    "-   Cross validation provides reliable estimates of model performance\n",
    "    and helps prevent overfitting.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4310fc93",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dbf79ddce3599ec7848941ecd369a42d",
     "grade": false,
     "grade_id": "cell-d8a1fb13696c905c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "We'll be using synthetic data for this lab. With authentic data, you'll\n",
    "find a large number of reasons outliers exist. Swapping out sensors,\n",
    "mixed up data migrations, user input error - the list could go on.\n",
    "Removing these data points with some statistical techniques can help us\n",
    "make accurate, useful models. Validating the cleaned up data helps us\n",
    "reach an even higher level of accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8b9a50",
   "metadata": {
    "deletable": false,
    "editable": false,
    "executionInfo": {},
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5748a24a6ae68be338bc4ca6371023f1",
     "grade": false,
     "grade_id": "cell-92d16aeb37cf1919",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, LeaveOneOut, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic data with a less obvious linear relationship and more noise\n",
    "num_points = 500\n",
    "X = np.linspace(0, 10, num_points)\n",
    "# Add a base linear trend with an offset and significantly more random noise\n",
    "y = 23 * X + 10 + np.random.randn(num_points) * 8\n",
    "\n",
    "# Introduce outliers: 12% of the data\n",
    "num_outliers = int(0.12 * num_points)  # 12% of 500 points\n",
    "outlier_indices = np.random.choice(range(num_points), size=num_outliers, replace=False)\n",
    "y[outlier_indices] += 200 * np.random.randn(num_outliers)\n",
    "y += np.random.randn(num_points) * 75\n",
    "\n",
    "# Convert to a Pandas DataFrame for convenience\n",
    "df = pd.DataFrame({'X': X, 'y': y})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b6183f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b2c0d03b0072f09344d68ed3467a98c5",
     "grade": false,
     "grade_id": "cell-5acf4db9ee97e67e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's visualize our data to get a sense of the distribution and\n",
    "potential outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dd01f7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "executionInfo": {},
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8e34ea8451cc044f7a027ae88c1a9cc",
     "grade": false,
     "grade_id": "cell-41f072691d0417d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(df['X'], df['y'], color='blue', alpha=0.7)\n",
    "plt.title('Synthetic Data')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab05c0a1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "14121997a451f73af466c17aee615ba9",
     "grade": false,
     "grade_id": "cell-4daffe00e506b2ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 1. Outlier Detection\n",
    "\n",
    "Outliers are data points that deviate significantly from the rest of the\n",
    "dataset. They may occur due to measurement errors, data processing\n",
    "issues, or naturally be part of the phenomenon you are studying.\n",
    "\n",
    "Data scientists must identify and handle outliers carefully because:\n",
    "\n",
    "-   They can skew statistical measures like mean and variance.\n",
    "-   They may lead to poor model performance if not handled correctly.\n",
    "-   They can break assumptions of certain algorithms (e.g., linear\n",
    "    regression's assumption of homoscedasticity).\n",
    "\n",
    "We will explore two common methods:\n",
    "\n",
    "1.  **IQR (Interquartile Range)**\n",
    "2.  **z-score**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b43aa9e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "41931e7f7a7115877563d6d8851c10e7",
     "grade": false,
     "grade_id": "cell-3bb483d4477297eb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.1 IQR Detection\n",
    "\n",
    "### Interquartile Range Definition\n",
    "\n",
    "The Interquartile Range (IQR) is defined as the difference between the\n",
    "75th percentile ($Q3$) and the 25th percentile ($Q1$) of the data:\n",
    "\n",
    "$$ \\text{IQR} = Q3 - Q1 $$\n",
    "\n",
    "Typically, points that lie outside the following bounds are considered\n",
    "outliers:\n",
    "\n",
    "$$ \\text{Lower bound} = Q1 - 1.5 \\times \\text{IQR} $$\n",
    "$$ \\text{Upper bound} = Q3 + 1.5 \\times \\text{IQR} $$\n",
    "\n",
    "IQR detection is useful for data scientists because it is relatively\n",
    "robust to extreme values and is easy to interpret. Let's apply this to\n",
    "our `y` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0148cd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5cdbe06d80d0226990cf7db4f459b1a",
     "grade": false,
     "grade_id": "cell-b9fb63fdfb3c739c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute Q1, Q3, and IQR\n",
    "Q1 = df['y'].quantile(0.25)\n",
    "Q3 = df['y'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "print(f\"Q1: {Q1:.2f}, Q3: {Q3:.2f}, IQR: {IQR:.2f}\")\n",
    "print(f\"Lower bound: {lower_bound:.2f}, Upper bound: {upper_bound:.2f}\")\n",
    "\n",
    "# Filter outliers\n",
    "df['IQR_Outlier'] = ((df['y'] < lower_bound) | (df['y'] > upper_bound))\n",
    "df_outliers_iqr = df[df['IQR_Outlier']]\n",
    "print(f\"Number of outliers detected by IQR: {len(df_outliers_iqr)}\")\n",
    "df_outliers_iqr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaf2aa5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "71addecb79af343f87c600e1cd3d4c6e",
     "grade": false,
     "grade_id": "cell-a8b73b9a528bfd64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Visualizing IQR Outliers\n",
    "\n",
    "We'll mark the outliers detected by IQR in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d5d59a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a90ff7f7ee814c152ef35aeb129e9ab3",
     "grade": false,
     "grade_id": "cell-6c8a12e71dff3b5c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "inliers = df[~df['IQR_Outlier']]\n",
    "outliers = df[df['IQR_Outlier']]\n",
    "\n",
    "plt.scatter(inliers['X'], inliers['y'], color='blue', alpha=0.7, label='Inliers')\n",
    "plt.scatter(outliers['X'], outliers['y'], color='red', alpha=0.7, label='Outliers')\n",
    "plt.title('IQR Outlier Detection')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c6101d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0449828ed4a67b9e771887320d038a12",
     "grade": false,
     "grade_id": "cell-e4440c8e9bddd1ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.2 z-score Detection\n",
    "\n",
    "### z-score Definition\n",
    "\n",
    "The z-score of a data point measures how many standard deviations away\n",
    "it is from the mean:\n",
    "\n",
    "$$ z = \\frac{x - \\mu}{\\sigma} $$\n",
    "\n",
    "where $x$ is the data point, $\\mu$ is the mean, and $\\sigma$ is the\n",
    "standard deviation. A common rule of thumb is to consider points with\n",
    "$|z| > 3$ as outliers.\n",
    "\n",
    "z-score detection is a common technique for data scientists working with\n",
    "data that is (or is assumed to be) approximately normally distributed.\n",
    "It helps highlight points far from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1266cf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84e3858fa018caf7a7b05dbf352e802e",
     "grade": false,
     "grade_id": "cell-02993c8b6d1623cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "y_mean = np.mean(df['y'])\n",
    "y_std = np.std(df['y'])\n",
    "\n",
    "df['z_score'] = (df['y'] - y_mean) / y_std\n",
    "threshold = 3\n",
    "\n",
    "df['Z_Outlier'] = df['z_score'].abs() > threshold\n",
    "\n",
    "df_outliers_z = df[df['Z_Outlier']]\n",
    "print(f\"Number of outliers detected by Z-score: {len(df_outliers_z)}\")\n",
    "df_outliers_z.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7a4840",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dc13b2ea472d6b99ff55c2a70134ff4d",
     "grade": false,
     "grade_id": "cell-3b195eb692141e95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Visualizing z-score Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0cfe09",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc2297dfc4c09a300794500460e0d81e",
     "grade": false,
     "grade_id": "cell-91fe34623871201d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "inliers_z = df[~df['Z_Outlier']]\n",
    "outliers_z = df[df['Z_Outlier']]\n",
    "\n",
    "plt.scatter(inliers_z['X'], inliers_z['y'], color='blue', alpha=0.7, label='Inliers')\n",
    "plt.scatter(outliers_z['X'], outliers_z['y'], color='red', alpha=0.7, label='Outliers')\n",
    "plt.title('z-score Outlier Detection')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e469d9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7c0155abce0807a49319d5307e48817",
     "grade": false,
     "grade_id": "cell-4c535bcbddaba19c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Observations\n",
    "\n",
    "1.  **IQR vs z-score**: Notice that the two methods may flag slightly\n",
    "    different points as outliers.\n",
    "2.  **Domain knowledge**: In practice, combine statistical methods with\n",
    "    domain expertise to decide if an outlier is truly erroneous or a\n",
    "    genuine data point.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "# 2. Model Selection\n",
    "\n",
    "Once we have understood and potentially handled outliers (either by\n",
    "removing them or adjusting them), we often need to choose a model. We'll\n",
    "explore how to use `scikit-learn` pipelines, then train two simple\n",
    "models:\n",
    "\n",
    "1.  **Linear Regression**\n",
    "2.  **k-Nearest Neighbors (kNN)**\n",
    "\n",
    "We'll then compare them using cross validation.\n",
    "\n",
    "**Why is this important to data scientists?**\n",
    "\n",
    "-   Choosing the right model can have a huge impact on accuracy and\n",
    "    generalization.\n",
    "-   Pipelines help maintain clean and reproducible workflows.\n",
    "-   Trying multiple models is a core practice to find the best approach\n",
    "    for a given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253bbe4e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc10221a563ab1f2134027a139be44d0",
     "grade": false,
     "grade_id": "cell-3131b31951875a9d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.1 scikit-learn Pipeline\n",
    "\n",
    "A `Pipeline` in `scikit-learn` lets you sequence multiple steps, such as\n",
    "transformations (scaling, encoding, etc.) and an estimator (like a\n",
    "regression model), into one object. This has several advantages:\n",
    "\n",
    "1.  **Convenience and encapsulation**: All steps can be contained in one\n",
    "    pipeline.\n",
    "2.  **Consistency**: Ensures the same transformations apply to both\n",
    "    training and test sets.\n",
    "3.  **Optimization**: Hyperparameter tuning can be done across the\n",
    "    entire pipeline in an automated way.\n",
    "\n",
    "For data scientists, pipelines save time, reduce the risk of data\n",
    "leakage, and make code more organized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2004b81a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "feb0b13ac38f8671b3f614749865de8a",
     "grade": false,
     "grade_id": "cell-12bd67d81c36291c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.2 Linear Regression\n",
    "\n",
    "Linear Regression assumes:\n",
    "\n",
    "$$ y = w_0 + w_1 X_1 + \\cdots + w_n X_n + \\epsilon $$\n",
    "\n",
    "where $\\epsilon$ is the error term. It tries to find weights $w_i$ that\n",
    "minimize the residual sum of squares between the observed targets and\n",
    "predicted targets.\n",
    "\n",
    "Data scientists often start with linear regression as a baseline model\n",
    "because it's simple, fast, and easily interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce12d40",
   "metadata": {
    "deletable": false,
    "editable": false,
    "executionInfo": {},
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4add03de9303552cb52dacab77ff7ec",
     "grade": false,
     "grade_id": "cell-42d9d1767758602e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_data = df[['X']]  # features\n",
    "y_data = df['y']    # target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Create a pipeline with a scaler and linear regression\n",
    "pipeline_lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lr', LinearRegression())\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "pipeline_lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_lr = pipeline_lr.predict(X_test)\n",
    "\n",
    "# Evaluate performance (e.g., using mean squared error)\n",
    "mse_lr = np.mean((y_test - y_pred_lr)**2)\n",
    "print(f\"Linear Regression MSE: {mse_lr:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2602b45b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c24cdc5d7e95c9ef0e04d728e646859b",
     "grade": false,
     "grade_id": "cell-8edfc82cd01b90de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.3 k-Nearest Neighbors (kNN)\n",
    "\n",
    "kNN is a non-parametric method that predicts the target by looking at\n",
    "the $k$ nearest training examples in the feature space. For regression,\n",
    "it takes the average of these neighbors as the prediction.\n",
    "\n",
    "This model is often useful for data scientists who want a simple,\n",
    "instance-based approach that can adapt to complex data distributions\n",
    "without a strict functional form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8bb96c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "executionInfo": {},
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b942316d15f24a19cde06ce593c34b76",
     "grade": false,
     "grade_id": "cell-5a0ec26d5277edce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Question: Is k=5 the appropriate number of neighbors?\n",
    "# We'll start by using k=5 as a default and then test a few different k values.\n",
    "\n",
    "# Create a pipeline with a scaler and kNN (for regression)\n",
    "pipeline_knn_5 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsRegressor(n_neighbors=5))  # default k=5\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "pipeline_knn_5.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_knn_5 = pipeline_knn_5.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "mse_knn_5 = np.mean((y_test - y_pred_knn_5)**2)\n",
    "print(f\"kNN Regression (k=5) MSE: {mse_knn_5:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082d256a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f699a3391bdda0fa526ed089e097f95c",
     "grade": false,
     "grade_id": "cell-193f80593dcfa0f9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing Different Values of k\n",
    "\n",
    "Now, let's see how changing the number of neighbors ($k$) affects the\n",
    "performance of kNN. We'll train multiple kNN regressors with different\n",
    "$k$ values and compare their mean squared errors on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18375cc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "executionInfo": {},
    "nbgrader": {
     "cell_type": "code",
     "checksum": "764fee0034821eadc53f7854c9042d38",
     "grade": false,
     "grade_id": "cell-3d75a46e886be73d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "k_values_to_test = list(range(1, 400, 10))\n",
    "mse_scores = []\n",
    "\n",
    "for k_val in k_values_to_test:\n",
    "    pipeline_knn_var = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('knn', KNeighborsRegressor(n_neighbors=k_val))\n",
    "    ])\n",
    "    # Fit the model\n",
    "    pipeline_knn_var.fit(X_train, y_train)\n",
    "    # Predict\n",
    "    y_pred = pipeline_knn_var.predict(X_test)\n",
    "    # Calculate MSE\n",
    "    mse = np.mean((y_test - y_pred)**2)\n",
    "    mse_scores.append(mse)\n",
    "\n",
    "# Let's visualize the impact of adjusting k on the error\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(k_values_to_test, mse_scores, marker='o', linestyle='--', color='blue')\n",
    "plt.title('Impact of k on kNN MSE')\n",
    "plt.xlabel('Number of Neighbors (k)')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e863c553",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5ef4ef34a046b49c36cf57ce001c2a37",
     "grade": false,
     "grade_id": "cell-c2b2804d12ace5e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Observations about k\n",
    "\n",
    "-   Smaller $k$ values (e.g., $k=1$ or $k=3$) often capture more local\n",
    "    patterns but can be noisy.\n",
    "-   Larger $k$ values (e.g., $k=15$) provide smoother predictions but\n",
    "    might underfit.\n",
    "-   Choosing an optimal $k$ usually involves balancing variance (too\n",
    "    small $k$) and bias (too large $k$), and often requires empirical\n",
    "    testing or cross validation.\n",
    "\n",
    "So, is $k=5$ the best choice? It depends on the data. In this example,\n",
    "you can see from the plot which $k$ gives the lowest MSE on the test\n",
    "set. In practice, you might also use cross validation to find the best\n",
    "$k$ in a more robust manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d163494b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6041954e4fc9847b479048f1bc20a464",
     "grade": false,
     "grade_id": "cell-e22faecb4aa4389a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Observations\n",
    "\n",
    "-   We have two models with potentially different performance.\n",
    "-   We evaluated them on a single train-test split.\n",
    "-   To get a more reliable estimate of model performance, we use **cross\n",
    "    validation**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e530f344",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bc6599d8a621b9a062ce0ef7019f971b",
     "grade": false,
     "grade_id": "cell-dc0a8d2762aed9d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 3. Cross Validation\n",
    "\n",
    "Cross validation is a technique to evaluate models by splitting the data\n",
    "multiple times and aggregating results. This helps provide a more robust\n",
    "measure of how well the model generalizes to unseen data.\n",
    "\n",
    "In practice, data scientists rely on cross validation to:\n",
    "\n",
    "-   Get a more stable performance metric.\n",
    "-   Make better model selection decisions.\n",
    "-   Mitigate overfitting by not relying on a single train-test split.\n",
    "\n",
    "Common methods:\n",
    "\n",
    "1.  **k-fold Cross Validation**\n",
    "2.  **Leave-One-Out (LOO) Cross Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b5ad7f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "86e233aa7fc6cb22ef229de91c96bab0",
     "grade": false,
     "grade_id": "cell-a5ef69818062acfb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.1 k-fold Validation\n",
    "\n",
    "The dataset is split into $k$ folds (subsets). The model is trained on\n",
    "$k-1$ folds and validated on the remaining fold. This process is\n",
    "repeated $k$ times, with each fold used exactly once as the validation\n",
    "set.\n",
    "\n",
    "Let's first use 5-fold cross validation for both our Linear Regression\n",
    "and kNN models and compare their performance.\n",
    "\n",
    "This approach provides a balance between computational cost and robust\n",
    "performance estimation, making it a favorite for many data scientists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e8c594",
   "metadata": {
    "deletable": false,
    "editable": false,
    "executionInfo": {},
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d34a77b2585758fa571bc2a4ee178e6",
     "grade": false,
     "grade_id": "cell-26e0fba75297db19",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "pipeline_lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lr', LinearRegression())\n",
    "])\n",
    "\n",
    "pipeline_knn_cv = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsRegressor(n_neighbors=5))\n",
    "])\n",
    "\n",
    "# Cross validation scores\n",
    "scores_lr = cross_val_score(pipeline_lr, X_data, y_data, cv=kf, scoring='neg_mean_squared_error')\n",
    "scores_knn = cross_val_score(pipeline_knn_cv, X_data, y_data, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert scores from negative MSE to positive MSE\n",
    "mse_lr_cv = -scores_lr\n",
    "mse_knn_cv = -scores_knn\n",
    "\n",
    "print(f\"Linear Regression Mean MSE (5-fold): {np.mean(mse_lr_cv):.2f} ± {np.std(mse_lr_cv):.2f}\")\n",
    "print(f\"kNN Regression Mean MSE (5-fold): {np.mean(mse_knn_cv):.2f} ± {np.std(mse_knn_cv):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931bfbb1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c06204b6714e1104d252f87add39d6f",
     "grade": false,
     "grade_id": "cell-33940635e6922f74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Visualizing 5-fold Validation Results\n",
    "\n",
    "We can visualize the MSE for each fold to get a sense of the model\n",
    "performance distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab8a7e4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "executionInfo": {},
    "nbgrader": {
     "cell_type": "code",
     "checksum": "826d6cd3ff2b8162f47941c1d3538f9c",
     "grade": false,
     "grade_id": "cell-661fdeede3aeeeeb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataframe for visualization\n",
    "cv_results = pd.DataFrame({\n",
    "    'Fold': list(range(1, k+1)) + list(range(1, k+1)),\n",
    "    'MSE': np.concatenate([mse_lr_cv, mse_knn_cv]),\n",
    "    'Model': ['LinearReg'] * k + ['kNN'] * k\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x='Fold', y='MSE', hue='Model', data=cv_results)\n",
    "plt.title('MSE for Each Fold by Model (5-Fold)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80583ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "585e850ef572bd832d5bddf5878bf244",
     "grade": false,
     "grade_id": "cell-597a62646d2f8fe8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Demonstrating Different k Values for Cross Validation\n",
    "\n",
    "While 5-fold cross validation is quite common, the choice of $k$ can\n",
    "affect:\n",
    "\n",
    "1.  **Bias-Variance trade-off** in the performance estimate.\n",
    "2.  **Computational cost** (larger $k$ can be more expensive).\n",
    "3.  **Stability** of the results.\n",
    "\n",
    "Let's see how different values of $k$ (from 2 to 19) affect the cross\n",
    "validation results for both Linear Regression and kNN (with $k=5$\n",
    "neighbors). We'll visualize and compare the performance across these\n",
    "different $k$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91d6c8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "executionInfo": {},
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e4a6fc41cee2ad68e652b403973752b",
     "grade": false,
     "grade_id": "cell-3ca1efabf9283b24",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "k_values = list(range(2, 20))\n",
    "\n",
    "results_dict = {'k': [], 'Model': [], 'Mean MSE': []}\n",
    "\n",
    "for k_val in k_values:\n",
    "    kf_var = KFold(n_splits=k_val, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Linear Regression\n",
    "    scores_lr_var = cross_val_score(pipeline_lr, X_data, y_data, cv=kf_var, scoring='neg_mean_squared_error')\n",
    "    mse_lr_var = -scores_lr_var\n",
    "    mean_mse_lr = np.mean(mse_lr_var)\n",
    "    results_dict['k'].append(k_val)\n",
    "    results_dict['Model'].append('Linear Regression')\n",
    "    results_dict['Mean MSE'].append(mean_mse_lr)\n",
    "    \n",
    "    # kNN with k=5 neighbors\n",
    "    scores_knn_var = cross_val_score(pipeline_knn_cv, X_data, y_data, cv=kf_var, scoring='neg_mean_squared_error')\n",
    "    mse_knn_var = -scores_knn_var\n",
    "    mean_mse_knn = np.mean(mse_knn_var)\n",
    "    results_dict['k'].append(k_val)\n",
    "    results_dict['Model'].append('kNN')\n",
    "    results_dict['Mean MSE'].append(mean_mse_knn)\n",
    "\n",
    "kfold_comparison_df = pd.DataFrame(results_dict)\n",
    "kfold_comparison_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f65f7c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4bab449a94148c32af30e2523b6f56d9",
     "grade": false,
     "grade_id": "cell-7ad5a43de2ebb8e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Visualizing the Effect of Different k Values (CV)\n",
    "\n",
    "Let's create a bar plot to compare the mean MSE for each $k$ (folds) and\n",
    "each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b4221e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "executionInfo": {},
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7237b0d35b35b016ef4f5772de8a3839",
     "grade": false,
     "grade_id": "cell-d490b2446a18b0d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x='k', y='Mean MSE', hue='Model', data=kfold_comparison_df)\n",
    "plt.title('Comparison of Mean MSE for Different Cross-Validation k Values')\n",
    "plt.xlabel('k (number of folds)')\n",
    "plt.ylabel('Mean MSE')\n",
    "plt.legend(loc='lower center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bd6d5c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d3f663ef79c8d8e715a2e4aa1541447a",
     "grade": false,
     "grade_id": "cell-2f4e930b397f2490",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Observations on Different k Values\n",
    "\n",
    "-   For large $k$ (close to the dataset size), you're nearing\n",
    "    Leave-One-Out Cross Validation.\n",
    "-   For smaller $k$, the training set in each fold is larger, and the\n",
    "    validation set is smaller.\n",
    "-   Typically, 5-fold or 10-fold are common defaults in many scenarios.\n",
    "\n",
    "### Quick Question\n",
    "\n",
    "Now that we've seen the error's that these two models are working with\n",
    "on the data - which is the more appropriate choice for the data?\n",
    "\n",
    "1.  KNN\n",
    "2.  Linear Regression\n",
    "\n",
    "Put your answer in a variable called `answer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48c1979-d98f-4ac3-bd9c-3d8cc61459d3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e5f66871481eb5faedca07dabcb2a518",
     "grade": false,
     "grade_id": "cell-25aef7c2e76a5fd4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee62dd3-791d-4cea-90a6-ffed32d135b5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f85c2bf1925f04cfd683fa296e9d51a",
     "grade": true,
     "grade_id": "cell-c1a878e646111450",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04e810ed",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d2c417d64aac57591272ec0c99bf6fc",
     "grade": false,
     "grade_id": "cell-d44fe779b4c80c7a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.2 Leave-One-Out Validation\n",
    "\n",
    "Leave-One-Out Cross Validation (LOOCV) is a special case of k-fold cross\n",
    "validation where $k$ is equal to the number of data points. Each time,\n",
    "we train on all the points except one, and use that one point for\n",
    "validation. This can be computationally expensive but provides an almost\n",
    "unbiased estimate of model performance.\n",
    "\n",
    "For data scientists, LOOCV can be appealing for smaller datasets where\n",
    "maximizing training data usage is critical, but it becomes expensive for\n",
    "larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a7eda3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "executionInfo": {},
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d18d2c72c65c2bd5ff1d6251a246375d",
     "grade": false,
     "grade_id": "cell-ab485f56eda0d876",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "loo = LeaveOneOut()\n",
    "pipeline_lr_loo = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lr', LinearRegression())\n",
    "])\n",
    "\n",
    "pipeline_knn_loo = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsRegressor(n_neighbors=5))\n",
    "])\n",
    "\n",
    "scores_lr_loo = cross_val_score(pipeline_lr_loo, X_data, y_data, cv=loo, scoring='neg_mean_squared_error')\n",
    "scores_knn_loo = cross_val_score(pipeline_knn_loo, X_data, y_data, cv=loo, scoring='neg_mean_squared_error')\n",
    "\n",
    "mse_lr_loo = -scores_lr_loo\n",
    "mse_knn_loo = -scores_knn_loo\n",
    "\n",
    "print(f\"Linear Regression Mean MSE (LOOCV): {np.mean(mse_lr_loo):.2f}\")\n",
    "print(f\"kNN Regression Mean MSE (LOOCV): {np.mean(mse_knn_loo):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e31c0d3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e8e34f7fe9dbf145293c6d7646a0179e",
     "grade": false,
     "grade_id": "cell-0747f094ed47de93",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Summary (of the demos)\n",
    "\n",
    "We've covered a lot of ground in this notebook:\n",
    "\n",
    "1.  Detecting outliers using **IQR** and **z-score** methods.\n",
    "2.  Setting up and using a **scikit-learn Pipeline** for data scaling\n",
    "    and model fitting.\n",
    "3.  Training and comparing **Linear Regression** and **k-Nearest\n",
    "    Neighbors**.\n",
    "4.  Evaluating model performance using **k-fold** (with different $k$\n",
    "    values) and **Leave-One-Out Cross Validation**.\n",
    "5.  Seeing if different values of $k$ are appropriate choices for kNN by\n",
    "    testing different neighbor counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9db3ca",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c1452418687b8f681df7cb0d4e8702ad",
     "grade": false,
     "grade_id": "cell-ae0ae6dc7bbf1264",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercises\n",
    "\n",
    "Below are some exercises for you to practice the techniques covered in\n",
    "this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2464352f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b3c6cd118544b5465fdc809012fe49d7",
     "grade": false,
     "grade_id": "cell-9b33f841708d5f7e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Exercise 1: Outlier Handling and Impact on Model Performance**\n",
    "### **Instructions**\n",
    "In this exercise, you will investigate how removing outliers affects model performance by following these steps:\n",
    "\n",
    "1. **Choose an outlier detection method**:\n",
    "   - Use either the **Interquartile Range (IQR) method** or **z-score method** to detect and remove outliers from the dataset.\n",
    "   - Store the cleaned dataset as a new DataFrame, **`df_clean`**, to allow for easy comparison with the original dataset.\n",
    "\n",
    "2. **Split the cleaned dataset**:\n",
    "   - Separate `X_clean` (features) and `y_clean` (target variable).\n",
    "   - Perform an 80-20 train-test split on the cleaned dataset using `train_test_split()` with `random_state=42`.\n",
    "\n",
    "3. **Train and evaluate models on the cleaned dataset**:\n",
    "   - Train **Linear Regression** on the cleaned data using a scikit-learn **Pipeline**.\n",
    "   - Train **k-Nearest Neighbors (kNN)** with `n_neighbors=5` on the cleaned data.\n",
    "   - Compute the **Mean Squared Error (MSE)** for both models and store them in variables:\n",
    "     - `mse_lr_clean` → MSE for Linear Regression on cleaned data.\n",
    "     - `mse_knn_clean` → MSE for kNN on cleaned data.\n",
    "\n",
    "4. **Compare results**:\n",
    "   - Print the dataset sizes before and after outlier removal.\n",
    "   - Print and compare MSE values for both models on **cleaned vs. original data**.\n",
    "\n",
    "### **Key Considerations**\n",
    "- Ensure `df_clean` has fewer rows than `df` (i.e., outliers are actually removed).\n",
    "- Expect **MSE to decrease** after removing outliers.\n",
    "- Store the computed MSE values in **`mse_lr_clean`** and **`mse_knn_clean`** to pass the test cases.\n",
    "- The test cases will check:\n",
    "  - If `df_clean` exists and is smaller than `df`.\n",
    "  - If `mse_lr_clean` and `mse_knn_clean` are correctly computed and stored.\n",
    "  - If MSE values on cleaned data are lower than on the original data.\n",
    "\n",
    "### **Hints**\n",
    "- You can use **IQR detection**:\n",
    "  ```python\n",
    "  Q1 = df['y'].quantile(0.25)\n",
    "  Q3 = df['y'].quantile(0.75)\n",
    "  IQR = Q3 - Q1\n",
    "  lower_bound = Q1 - 1.5 * IQR\n",
    "  upper_bound = Q3 + 1.5 * IQR\n",
    "  df_clean = df[(df['y'] >= lower_bound) & (df['y'] <= upper_bound)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954c092c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75471b057daa1e220c7be7f71d8b2cc1",
     "grade": false,
     "grade_id": "cell-4bd215715b586e75",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8073fee",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ee3a6900b5ce583d4ae88e3dfe70f97",
     "grade": true,
     "grade_id": "cell-a28a197ca98c6c86",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# === EXERCISE 1 DEEPER CHECKS (HIDDEN) ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01a9442",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5ec7ad5a8d2b4f79fedee50b98f20f7",
     "grade": false,
     "grade_id": "cell-efd07235d0c87d1d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# === EXERCISE 1 SHALLOW CHECKS ===\n",
    "assert 'df_clean' in globals(), \"df_clean is not defined. Make sure you created a cleaned DataFrame.\"\n",
    "assert df_clean.shape[0] <= df.shape[0], \"Cleaned dataset should not be larger than the original.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfde5b6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "52c4890290c01f5469ba66ced0fc152a",
     "grade": false,
     "grade_id": "cell-523d54abafb087ba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Which of the following are potential reasons removing outliers might\n",
    "improve model performance?\n",
    "\n",
    "1.  It reduces the variance caused by extreme data points.\n",
    "2.  It can simplify the learning task for models sensitive to outliers.\n",
    "3.  It always increases the accuracy of every possible model.\n",
    "4.  It can help certain models meet their statistical assumptions.\n",
    "5.  It guarantees we will never overfit.\n",
    "\n",
    "Put your choices into an array of integers called `answer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2722198f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02f5b5622349d8f5293d2274d7587716",
     "grade": false,
     "grade_id": "cell-ecb13782b1f7c14f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Provide the correct choices as a list of integers. For instance, answer = [1, 2, 4]\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1d22a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec782e03e7353ddbab44b2600f160e2e",
     "grade": true,
     "grade_id": "cell-d7054452cb78da53",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e01dcb73",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a30821955cd0b36111d997831e6ea923",
     "grade": false,
     "grade_id": "cell-e3187d43f772d202",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Exercise 2: Trying a New Transformer or Model in the Pipeline**\n",
    "### **Instructions**\n",
    "In this exercise, you will experiment with adding **polynomial features** to the pipeline and evaluate whether they improve model performance.\n",
    "\n",
    "Follow these steps:\n",
    "\n",
    "1. **Create a new pipeline**:\n",
    "   - Add **PolynomialFeatures(degree=2)** from `sklearn.preprocessing` as a transformation step.\n",
    "   - Normalize the data using `StandardScaler()`.\n",
    "   - Train a **Linear Regression** model using the transformed features.\n",
    "\n",
    "2. **Train and evaluate the model**:\n",
    "   - Use the original training dataset (`X_train`, `y_train`).\n",
    "   - Fit the polynomial regression pipeline.\n",
    "   - Predict on the test dataset (`X_test`).\n",
    "   - Compute the **Mean Squared Error (MSE)** of the polynomial regression model.\n",
    "   - Store the result in the variable **`mse_poly`**.\n",
    "\n",
    "3. **Compare results**:\n",
    "   - Print the **MSE of the polynomial regression model**.\n",
    "   - Compare it with the **MSE of the original Linear Regression (`mse_lr`)**.\n",
    "   - Analyze whether polynomial regression improves or worsens performance.\n",
    "\n",
    "### **Key Considerations**\n",
    "- Ensure **`pipeline_poly_lr`** exists and includes `PolynomialFeatures(degree=2)`, `StandardScaler()`, and `LinearRegression()`.\n",
    "- Store the computed **MSE in `mse_poly`** to pass the test cases.\n",
    "- The test cases will check:\n",
    "  - If **`pipeline_poly_lr`** is defined correctly.\n",
    "  - If **`mse_poly`** is computed and stored.\n",
    "  - If `mse_poly` is **not exactly equal to `mse_lr`**, ensuring that polynomial features were used.\n",
    "\n",
    "### **Questions for Analysis**\n",
    "- **Does polynomial regression improve or worsen the performance on this dataset?**\n",
    "- **Why might polynomial features be helpful or harmful?**\n",
    "  - Polynomial features can capture **non-linear relationships** in data, potentially reducing bias.\n",
    "  - However, they can also lead to **overfitting**, increasing variance and reducing generalizability.\n",
    "  - Watch for overfitting if the **polynomial degree is too high**.\n",
    "\n",
    "### **Hints**\n",
    "- Your pipeline should look like this:\n",
    "  ```python\n",
    "  pipeline_poly_lr = Pipeline([\n",
    "      ('poly', PolynomialFeatures(degree=2)),\n",
    "      ('scaler', StandardScaler()),\n",
    "      ('lr', LinearRegression())\n",
    "  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef15c2b8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e661395e78983eda156951f34dede773",
     "grade": false,
     "grade_id": "cell-9698fd4b5432d8e7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a29878b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db740d9d8cee9e1f3ab6cf409d93a21f",
     "grade": true,
     "grade_id": "cell-aee13e5f3365a9e4",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# === EXERCISE 2 DEEPER CHECKS (HIDDEN) ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b867c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e571979af676363f4727b307268f7005",
     "grade": false,
     "grade_id": "cell-654e5a18b4b3a00d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# === EXERCISE 2 SHALLOW CHECKS ===\n",
    "assert 'pipeline_poly_lr' in globals(), \"pipeline_poly_lr is not defined. Make sure to create a pipeline with PolynomialFeatures.\"\n",
    "assert 'mse_poly' in globals(), \"mse_poly is not defined. Make sure you stored the polynomial regression MSE.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6e950a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "675dc2af1f99055ec309e400804466df",
     "grade": false,
     "grade_id": "cell-8cec63db04f6c681",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Which statements about adding polynomial features to a linear regression\n",
    "are correct?\n",
    "\n",
    "1.  It can model non-linear relationships.\n",
    "2.  It never changes training time.\n",
    "3.  It can lead to overfitting if the polynomial degree is too high.\n",
    "4.  It's guaranteed to reduce MSE on every dataset.\n",
    "5.  It can increase model complexity.\n",
    "\n",
    "Put your choices into an array of integers called `answer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc94e2a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a95a90fc4ff0771d78c067f108633e7",
     "grade": false,
     "grade_id": "cell-0e46e08403a8bf07",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060c199b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad09219dfc178e8e0160c55e5b3e08bf",
     "grade": true,
     "grade_id": "cell-2729a9d608795852",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31c24149",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4a2f1da9bb05ecc560a1a7a117765352",
     "grade": false,
     "grade_id": "cell-b08376b3b5eb57d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Exercise 3: Exploring Different Metrics in Cross Validation**\n",
    "### **Instructions**\n",
    "In this exercise, you will evaluate models using different performance metrics in **k-fold cross-validation (5-fold)** and analyze how the choice of metric affects model ranking.\n",
    "\n",
    "Follow these steps:\n",
    "\n",
    "1. **Perform 5-fold cross-validation** on both models (**Linear Regression and kNN**) using:\n",
    "   - **Mean Absolute Error (MAE)** as the scoring metric (`scoring='neg_mean_absolute_error'`).\n",
    "   - **R² Score** as the scoring metric (`scoring='r2'`).\n",
    "   - Store the results for each fold.\n",
    "\n",
    "2. **Compute and store the results**:\n",
    "   - Convert the **negative MAE scores** to positive values.\n",
    "   - Compute the **mean and standard deviation** for both MAE and R² metrics.\n",
    "   - Print the results to compare performance.\n",
    "\n",
    "3. **Compare results**:\n",
    "   - Analyze if **Linear Regression or kNN performs better under different metrics**.\n",
    "   - Observe if the \"best\" model changes based on **MAE vs. R² score**.\n",
    "\n",
    "### **Key Considerations**\n",
    "- Ensure **5-fold cross-validation** is used.\n",
    "- Store the computed **MAE and R² values** correctly:\n",
    "  - `scores_lr_mae` and `scores_knn_mae` should contain **negative values** (due to `cross_val_score`).\n",
    "  - Convert these to positive values before comparing.\n",
    "  - `scores_lr_r2` and `scores_knn_r2` should contain **R² values**.\n",
    "- The test cases will check:\n",
    "  - If **5-fold cross-validation** is applied correctly.\n",
    "  - If the correct metrics (`MAE` and `R²`) are used.\n",
    "  - If MAE values are **negative** before conversion.\n",
    "\n",
    "### **Questions for Analysis**\n",
    "- **Which metric shows the greatest difference between the two models?**\n",
    "- **Why might one model outperform the other on a specific metric?**\n",
    "  - MAE focuses on **absolute errors**, penalizing large errors equally.\n",
    "  - R² measures how well the model explains variance in the data.\n",
    "  - kNN may perform better in cases with **non-linear patterns**, while Linear Regression might do better if the data is **linearly structured**.\n",
    "\n",
    "### **Hints**\n",
    "- Use the following scoring methods in `cross_val_score()`:\n",
    "  ```python\n",
    "  cross_val_score(pipeline_lr, X_data, y_data, cv=5, scoring='neg_mean_absolute_error')\n",
    "  cross_val_score(pipeline_lr, X_data, y_data, cv=5, scoring='r2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64f30c0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d59239dc073ca54520494b0f6865802",
     "grade": false,
     "grade_id": "cell-76f14a9d5ba95bf4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2cd289",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d45e890bed06b5a31d45f8efea28cfb",
     "grade": true,
     "grade_id": "cell-6af530f78e93a928",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# === EXERCISE 3 DEEPER CHECKS (HIDDEN) ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97fcd28",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4b08e584498b964a9b37f063d4cade8",
     "grade": false,
     "grade_id": "cell-fd81289bc4e27275",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# === EXERCISE 3 SHALLOW CHECKS ===\n",
    "# We'll just check if the cross-validation arrays exist.\n",
    "assert 'scores_lr_mae' in globals(), \"scores_lr_mae not found. Make sure you're doing cross_val_score with MAE for LR.\"\n",
    "assert 'scores_knn_mae' in globals(), \"scores_knn_mae not found. Make sure you're doing cross_val_score with MAE for kNN.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0dddcd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e49ac89fca5ae52454c15fccf1da8b2",
     "grade": false,
     "grade_id": "cell-80dea78478092eb9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Which of the following metrics can be used to evaluate regression\n",
    "models?\n",
    "\n",
    "1.  Mean Squared Error (MSE)\n",
    "2.  Accuracy\n",
    "3.  Mean Absolute Error (MAE)\n",
    "4.  R^2 Score\n",
    "5.  F1-Score\n",
    "\n",
    "Put your choices into an array of integers called `answer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef3c7cc",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d5bb4e05cb2c42b4473757ab6e54433",
     "grade": false,
     "grade_id": "cell-f1bfb5c5c29ac164",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Provide the correct choices as a list of integers. For instance, [1, 3, 4].\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc361621",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6f15d033b884f7bd6642ae137d2f71f",
     "grade": true,
     "grade_id": "cell-eee93def412d8411",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "706f724a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1bd509891c5688d5621177bd797f5bde",
     "grade": false,
     "grade_id": "cell-b42cb849734c05f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Exercise 4: Manual Hyperparameter Search for k in kNN Using Cross Validation**\n",
    "### **Instructions**\n",
    "In this exercise, you will **experiment with different values of k** in k-Nearest Neighbors (kNN) and determine the best choice using **5-fold cross-validation**.\n",
    "\n",
    "Follow these steps:\n",
    "\n",
    "1. **Test different values of k**:\n",
    "   - Use `k_values_search = range(1, 31)`, testing values of **k from 1 to 30**.\n",
    "   - For each **k**, train a kNN model and evaluate its **Mean Squared Error (MSE)** using **5-fold cross-validation**.\n",
    "   - Store the **average MSE for each k** in a list called `mse_means`.\n",
    "\n",
    "2. **Plot the results**:\n",
    "   - Create a **line plot** of **k (number of neighbors) vs. MSE**.\n",
    "   - Label the x-axis as **\"k (number of neighbors)\"** and the y-axis as **\"Mean MSE\"**.\n",
    "   - Identify the **k value that yields the lowest MSE**.\n",
    "\n",
    "3. **Determine the best k**:\n",
    "   - Find and print the **optimal k** (the one with the lowest MSE).\n",
    "   - Print the **minimum MSE** observed.\n",
    "\n",
    "### **Key Considerations**\n",
    "- Ensure **5-fold cross-validation** is used to compute MSE.\n",
    "- Store the computed values in:\n",
    "  - `k_values_search` → The range of **k** values tested.\n",
    "  - `mse_means` → The list of corresponding **MSE values**.\n",
    "  - `best_k` → The optimal **k** value (minimizing MSE).\n",
    "- The test cases will check:\n",
    "  - If `k_values_search` contains **values from 1 to 30**.\n",
    "  - If `mse_means` has **the same length as `k_values_search`**.\n",
    "  - If the **minimum MSE is non-negative**.\n",
    "\n",
    "### **Questions for Analysis**\n",
    "- **Which k provides the best balance of bias vs. variance?**\n",
    "- **Does this optimal k differ from what you found using a single train-test split?**\n",
    "  - Small k (e.g., 1-5) captures **local patterns** but may lead to **high variance**.\n",
    "  - Large k (e.g., 20-30) smooths predictions but may lead to **high bias**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf709ec",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73ab3ad2e90bd5217b4d3c216edef277",
     "grade": false,
     "grade_id": "cell-57ea47b79bb71e34",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0811cd6d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0fa1c7f573e47d4cb59d13fb5cbe28cb",
     "grade": true,
     "grade_id": "cell-ec3b44e137e515ce",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# === EXERCISE 4 DEEPER CHECKS (HIDDEN) ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4adb91c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "026ebd41ab485dcbc052e536a19f16d3",
     "grade": false,
     "grade_id": "cell-9886c810f6f39651",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# === EXERCISE 4 SHALLOW CHECKS ===\n",
    "# We'll confirm the array of k_values_search and mse_means exist.\n",
    "assert 'k_values_search' in globals(), \"k_values_search not found.\"\n",
    "assert 'mse_means' in globals(), \"mse_means not found.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40fc78e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd24a87244ec3df23ec5cc8cdc59bfac",
     "grade": false,
     "grade_id": "cell-4fa040bb42c2ce08",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### EXERCISE 4 SELECT ALL THAT APPLY\n",
    "\n",
    "Which statements about k in kNN regression are correct?\n",
    "\n",
    "1.  Smaller k often reduces bias but increases variance.\n",
    "2.  Larger k always yields perfect predictions.\n",
    "3.  k=1 typically yields a very high-variance model.\n",
    "4.  Choosing k with cross validation can help avoid overfitting.\n",
    "5.  k must always be an even number.\n",
    "\n",
    "Put your choices into an array of integers called `answer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fd5b3e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8067eae5cacbc579bf07edaa38a1e58a",
     "grade": false,
     "grade_id": "cell-728bca43d65b7396",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a7bd8b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4b82af7a69006459ed1e61f84f40387",
     "grade": true,
     "grade_id": "cell-ea33daaba95eee42",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "057b5626",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ab16e4cc14b7d33715091a36a4ecada8",
     "grade": false,
     "grade_id": "cell-2547a341ab27c0ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Exercise 5: Using GridSearchCV for Hyperparameter Tuning**\n",
    "### **Instructions**\n",
    "In this exercise, you will use **GridSearchCV** to systematically search for the best **k** in **k-Nearest Neighbors (kNN)** by evaluating different values of **k** using cross-validation.\n",
    "\n",
    "Follow these steps:\n",
    "\n",
    "1. **Define a parameter grid**:\n",
    "   - Create a dictionary `param_grid` that specifies different **k values** to test:  \n",
    "     \\[\n",
    "     k = [1, 3, 5, 10, 15, 20, 25, 30]\n",
    "     \\]\n",
    "   - The key should be **'knn__n_neighbors'**, which refers to the kNN hyperparameter.\n",
    "\n",
    "2. **Set up the GridSearchCV pipeline**:\n",
    "   - Create a **Pipeline** with:\n",
    "     - `StandardScaler()` for scaling.\n",
    "     - `KNeighborsRegressor()` for kNN regression.\n",
    "   - Use `GridSearchCV()` to perform **5-fold cross-validation**:\n",
    "     - Set `scoring='neg_mean_squared_error'` to evaluate performance.\n",
    "     - Use `cv=5` for 5-fold cross-validation.\n",
    "     - Set `n_jobs=-1` to utilize all CPU cores for faster computation.\n",
    "\n",
    "3. **Fit the model and extract results**:\n",
    "   - Train the `GridSearchCV` model on `X_data` and `y_data`.\n",
    "   - Retrieve and print:\n",
    "     - **Best k** (`grid_search.best_params_`).\n",
    "     - **Best negative MSE score** (`grid_search.best_score_`).\n",
    "     - **Best MSE (converted from negative score)**.\n",
    "\n",
    "### **Key Considerations**\n",
    "- Ensure the **parameter grid** includes the correct k values.\n",
    "- Store the trained GridSearchCV model in **`grid_search`**.\n",
    "- The test cases will check:\n",
    "  - If `grid_search.best_params_` is **not None**.\n",
    "  - If `grid_search.best_params_` contains the **'knn__n_neighbors'** key.\n",
    "  - If the best **k value** is within the tested range.\n",
    "\n",
    "### **Questions for Analysis**\n",
    "- **Does the GridSearchCV approach find the same best k as in Exercise 4?**\n",
    "- **How does cross-validation in GridSearchCV help prevent overfitting?**\n",
    "  - **Prevents bias from a single train-test split.**\n",
    "  - **Ensures the model generalizes better by averaging results across multiple splits.**\n",
    "\n",
    "### **Hints**\n",
    "- Define the parameter grid:\n",
    "  ```python\n",
    "  param_grid = {\n",
    "      'knn__n_neighbors': [1, 3, 5, 10, 15, 20, 25, 30]\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90042c00",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de11739b6a960c2224d4079aafc01087",
     "grade": false,
     "grade_id": "cell-da229b74cf1e04fb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d31aecf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad2d39644e2fbd001a618874eb8efbcc",
     "grade": true,
     "grade_id": "cell-d55029d864bcc1d2",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# === EXERCISE 5 DEEPER CHECKS (HIDDEN) ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b100b156",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3129ec92ff003ca7ef63c0a2354bfe67",
     "grade": false,
     "grade_id": "cell-aae7c5c3a6623916",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# === EXERCISE 5 SHALLOW CHECKS ===\n",
    "assert 'grid_search' in globals(), \"grid_search not found. Make sure you created a GridSearchCV object.\"\n",
    "assert hasattr(grid_search, 'best_params_'), \"grid_search should have best_params_ after fitting.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335c5bbf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dbe6e61c396a99d1211a92d8892a5c8e",
     "grade": false,
     "grade_id": "cell-d449968d5ec2c95a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Which statements about GridSearchCV are correct?\n",
    "\n",
    "1.  It uses cross-validation to evaluate different hyperparameter\n",
    "    combinations.\n",
    "2.  It automatically cleans the data for you.\n",
    "3.  It helps find the best hyperparameters by trying each combination.\n",
    "4.  It guarantees your model will never overfit.\n",
    "5.  It can use multiple scoring metrics simultaneously if configured.\n",
    "\n",
    "Put your choices into an array of integers called `answer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43a50d1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69a17067a2beb08d99963fd742e488da",
     "grade": false,
     "grade_id": "cell-c81b8d9b70eceaa9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef553110",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "28d77df7a8feb43af2484f158a35588f",
     "grade": true,
     "grade_id": "cell-085353d85d141d42",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b42a8e1a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d57a830fd6745eec930ef9bae4b82b66",
     "grade": false,
     "grade_id": "cell-e066e2ad2723c0c1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Exercise 6: See how much error is gained by removing outliers**\n",
    "### **Instructions**\n",
    "In this exercise, you will see how removing outliers is a way to reduce error. Keep in mind that when working with real data, you should know why outliers are being removed (faulty sensor, mis-entered data, etc.).\n",
    "\n",
    "Follow these steps:\n",
    "\n",
    "1. **Remove outliers from the data before the pipeline**:\n",
    "   - Use a typical function to remove data ponts outside of the IQR\n",
    "\n",
    "2. **Set up a pipeline with automatic outlier removal**:\n",
    "   - Chain the following steps in a `Pipeline`:\n",
    "     - `StandardScaler()` → Scales the data.\n",
    "     - `LinearRegression()` → Fits a regression model.\n",
    "\n",
    "3. **Compare performance**:\n",
    "   - Train and evaluate this pipeline using **train-test split**.\n",
    "   - Compute **Mean Squared Error (MSE)** for this pipeline.\n",
    "   - Compare it to the MSE of **Linear Regression without outlier removal** (`mse_lr`).\n",
    "\n",
    "### **Questions for Analysis**\n",
    "- **How does removing outliers inside the pipeline affect your final MSE?**\n",
    "- **Is the effect as large as you thought it would be?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ec5f08",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "364d62c7321cc38909d4760dfb237aa6",
     "grade": false,
     "grade_id": "cell-239abf7290dfd224",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e95a611",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30a95fb3a66932dc096e477a7619a512",
     "grade": true,
     "grade_id": "cell-78d583ce882cd94e",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# === EXERCISE 6 DEEPER CHECKS (HIDDEN) ==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e743389a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b080cf35fa62fa970c5b8c9244524c35",
     "grade": false,
     "grade_id": "cell-0555f87f91270334",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Which statements about removing outliers in a pipeline are correct?\n",
    "\n",
    "1.  It can help avoid data leakage by only removing outliers from the\n",
    "    training set.\n",
    "2.  It is impossible to remove outliers within a scikit-learn pipeline.\n",
    "3.  You need a custom transformer or a function transformer to do it\n",
    "    properly.\n",
    "4.  Removing outliers in the pipeline is always guaranteed to improve\n",
    "    MSE.\n",
    "5.  The approach may differ from removing outliers prior to splitting\n",
    "    the data.\n",
    "\n",
    "Put your choices into an array of integers called `answer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c1a184",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97a72c687d71682d07781bea19737ded",
     "grade": false,
     "grade_id": "cell-e50a0e2573932b8a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Provide the correct choices as a list of integers. For example, [1, 3, 5].\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f01b5d0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ebd6f2e6933eb54729d9aff9ec808796",
     "grade": true,
     "grade_id": "cell-134e98e4ddec951b",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2324d1b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "629e9d2d529d6dd9ca836aa48cbc5a72",
     "grade": false,
     "grade_id": "cell-5ee1800ff67f6947",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
