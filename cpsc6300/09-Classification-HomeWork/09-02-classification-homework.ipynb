{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1673221d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "67d3cb62c956904e515960567c430672",
     "grade": false,
     "grade_id": "ads",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class='heading'>\n",
    "    <div style='float:left;'><h1>CPSC 4300/6300: Applied Data Science</h1></div>\n",
    "    <img style=\"float: right; padding-right: 10px; width: 65px\" src=\"https://raw.githubusercontent.com/bsethwalker/clemson-cs4300/main/images/clemson_paw.png\"> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a639ea64-b71c-4bfc-8ed7-811cf567a565",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5019d58ae0532abc410014235cbdd43b",
     "grade": false,
     "grade_id": "week-9-homework",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Week 9 | HomeWork: Classification | Logistic Regression\n",
    "\n",
    "**Clemson University** </br>\n",
    "**Instructor(s):** Tim Ransom </br>\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "## Learning objectives\n",
    "\n",
    "- Differentiate between supervised and unsupervised classification methods.\n",
    "- Implement a logistic regression model for classification.\n",
    "- Evaluate the performance of a classification model using metrics like accuracy.\n",
    "- Compare the performance of different classification algorithms.\n",
    "- Preprocess data for classification tasks, including normalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33da1c24-4319-4c4a-a437-a56e53f4ab70",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a95feea5b475a0848b369e71d639468c",
     "grade": false,
     "grade_id": "instructions",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### INSTRUCTIONS\n",
    "\n",
    "-   To submit your assignment, follow the instructions provided by Coursera Labs.\n",
    "-   Restart the kernel and run the whole notebook again before you\n",
    "    submit.\n",
    "-   As much as possible, try and stick to the hints and functions we\n",
    "    import at the top of the homework, as those are the ideas and tools\n",
    "    the class supports and are aiming to teach. And if a problem\n",
    "    specifies a particular library, you're required to use that library,\n",
    "    and possibly others from the import list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35695532-4795-46ef-b0ed-1db4ee280297",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9ca8221b1f4242dc04a39989a909956",
     "grade": false,
     "grade_id": "formatting",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" RUN THIS CELL TO GET THE RIGHT FORMATTING \"\"\"\n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "css_file = 'https://raw.githubusercontent.com/bsethwalker/clemson-cs4300/main/css/cpsc6300.css'\n",
    "styles = requests.get(css_file).text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f598221b-682f-43fc-96de-34487e8c7ede",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c783b72f1c9ef0c7cdb5ad67e2611cbc",
     "grade": false,
     "grade_id": "required-libs",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotcheck.base import PlotTester\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from scipy.stats import ttest_ind\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5007d4c0-6859-42ee-a5a2-27b47103bcce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "82e9c7e82a6c2f254efc5d0d95ef184f",
     "grade": false,
     "grade_id": "about",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class='theme'> Cancer Classification from Gene Expressions </div>\n",
    "\n",
    "- In this problem, we will build a classification model to distinguish between two related classes of cancer, `acute lymphoblastic leukemia (ALL)` and `acute myeloid leukemia (AML)`, using gene expression measurements. \n",
    "- The dataset is provided in the file `hw6_enhance.csv`.\n",
    "- Each row in this file corresponds to a tumor tissue sample from a patient with one of the two forms of Leukemia. \n",
    "    - The first column contains the cancer type, with **0 indicating the ALL** class and **1 indicating the AML** class. \n",
    "    - Columns 2-7130 contain expression levels of 7129 genes recorded from each tissue sample.\n",
    "\n",
    "- In the following questions, we will use linear and logistic regression to build classification models for this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe81119",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2fb3bd99b99037be2c31022709400f5f",
     "grade": false,
     "grade_id": "exercise-1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class='exercise'><b> Exercise 1</b></div>\n",
    "\n",
    "## Data Exploration\n",
    "\n",
    "1. Load the dataset `data/hw6_enhance.csv` into a pandas DataFrame named `df`. (Given csv file is located in `/data/hw6_enhance.csv` path)\n",
    "2. Split the observations into an approximate **80-20 train-test split**:\n",
    "   - Store the feature matrix in `X` (excluding the `Unnamed: 0` index column and `Cancer_type`).\n",
    "   - Store the target variable (`Cancer_type`) in `y`.\n",
    "3. Use `train_test_split()` from `sklearn.model_selection` to split the data into `X_train`, `X_test`, `y_train`, and `y_test` with:\n",
    "   - `test_size=0.2`\n",
    "   - `random_state=72` (for reproducibility)\n",
    "   - `stratify=y` (to maintain the class distribution)\n",
    "4. Print the dataset shape **before** and **after** splitting.\n",
    "5. Verify class distribution in both training and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6463fd8-aa17-43a0-b5a5-e91601d419ec",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e16f8ec2391fe54962cf5dbee46f5a3f",
     "grade": false,
     "grade_id": "exercise-1-implementation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Write your code for exercise-1 here:\"\"\"\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353babfe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "215feed273f0de46456dbf23ad9734d7",
     "grade": true,
     "grade_id": "exercise-1-tests",
     "locked": true,
     "points": 9,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "401376be",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2c94748b16d1c309fb25cab9f37dd13b",
     "grade": false,
     "grade_id": "cell-337a451d7cd23415",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bcdd04",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "79f39308b8d2d741e5105dc631efc47f",
     "grade": false,
     "grade_id": "cell-a2106e84f3d91844",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- Let's take a peek at your training set (Using the describe()method): you should notice the severe differences in the measurementsfrom one gene to the next (some are negative, some hover around zero,and some are well into the thousands)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f8e50",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ff4669e458844867f8214b790015c53",
     "grade": false,
     "grade_id": "cell-7d14fffd487e0785",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# original data statistics before normalization\n",
    "print(\"Original Training Set Description:\")\n",
    "print(X_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688f8e5a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7bb3caa12000f513aca0dcafc1fd3f33",
     "grade": false,
     "grade_id": "cell-2b7d8144aec412b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Checking for missing values in X_train before normalization:\")\n",
    "print(X_test.isnull().sum().sum())\n",
    "\n",
    "# Check for non-numeric data (shouldn't happen if all columns are numeric)\n",
    "print(\"Checking for non-numeric columns in X_train:\")\n",
    "print(X_train.dtypes)\n",
    "\n",
    "print(\"Min and Max values in X_test before scaling:\")\n",
    "print(f\"Min: {X_train.min().min()}, Max: {X_train.max().max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5a7228",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "88a296de87fc9da4b5e93fe6502366e0",
     "grade": false,
     "grade_id": "cell-fe3b37cdbf7a402f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# original data statistics before normalization\n",
    "print(\"Original Test Set Description:\")\n",
    "print(X_test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cf8d1d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91c33169e38b762846791af4f7d749ed",
     "grade": false,
     "grade_id": "cell-f2ba007d397bb08a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Checking for missing values in X_test before normalization:\")\n",
    "print(X_test.isnull().sum().sum())\n",
    "\n",
    "# Check for non-numeric data (shouldn't happen if all columns are numeric)\n",
    "print(\"Checking for non-numeric columns in X_test:\")\n",
    "print(X_test.dtypes)\n",
    "\n",
    "print(\"Min and Max values in X_test before scaling:\")\n",
    "print(f\"Min: {X_test.min().min()}, Max: {X_test.max().max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd78f62-06d4-42a8-9140-d57047888ded",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "baf93400f3fda3494c27ce1956605ddc",
     "grade": false,
     "grade_id": "exercise-2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class='exercise'><b> Exercise 2</b></div>\n",
    "\n",
    "## Normalization\n",
    "\n",
    "In this exercise, you will normalize the dataset to ensure that all predictors vary between **0 and 1**. This helps in handling differences in scale and variability across different gene expression levels.\n",
    "\n",
    "1. Use `MinMaxScaler()` from `sklearn.preprocessing` to scale **X_train** and **X_test**.\n",
    "2. Fit the scaler on the **training data** and transform both **X_train** and **X_test**.\n",
    "3. Store the transformed data back into the same DataFrames, keeping the original structure.\n",
    "4. Ensure that all feature values are now between **0 and 1**.\n",
    "\n",
    "**Note:**  \n",
    "For the remainder of this homework, you **must** use these normalized values instead of the original raw values.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fe5e29-2901-41c4-a37b-e967c0b5b605",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed4cf0d9e1f452510162220f1c728f6c",
     "grade": false,
     "grade_id": "exercise-2-implementation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Write your code for exercise-2 here:\"\"\"\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049ef233",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "616527a139f8c88d964ce71307b52022",
     "grade": true,
     "grade_id": "exercise-2-tests",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d28860c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2bb9e323fcf2f341d2acaed783cbbf64",
     "grade": false,
     "grade_id": "cell-fc8c147e42a90ec0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# normalized data statistics\n",
    "print(\"\\nNormalized Training Set (first 5 rows):\")\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8894ebb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e2061ea473e18e879ed0d83fcd69f72",
     "grade": false,
     "grade_id": "exercise-3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"theme\"> Question 1:</div>\n",
    "\n",
    "The training set contains more predictors than observations. What problem(s) can this lead to when fitting a classification model? (Select the most appropriate answer)\n",
    "\n",
    "1. The model will generalize well to new data because it has a large number of predictors.\n",
    "2. The model will perform faster because more features improve efficiency.\n",
    "3. The model may overfit due to the high dimensionality, leading to poor generalization.\n",
    "4. Having more predictors than observations is beneficial and does not cause any issues.\n",
    "\n",
    "**Store your answer in an integer variable named 'answer' in the below code cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbf943c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f55ccfe91ad1c3935b692ecdc3419ca7",
     "grade": false,
     "grade_id": "ex3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0cf760",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ce2607decc78881a7e3c2891d04e109",
     "grade": true,
     "grade_id": "exercise-3-answer",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b6c6b88-e09b-46ac-8e79-39699a98e590",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4311d79c8d1e64e4d639f4476126c828",
     "grade": false,
     "grade_id": "cell-2d7c183ed9563eee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Next we want to determine which 10 genes individually discriminate between the two cancer classes the best (consider every gene in the dataset). Code has been provided to do this for you. Make sure you understand what the code is doing. Note that it makes use of [t-testing](https://en.wikipedia.org/wiki/Welch%27s_t-test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7feac0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7a1b4d214df70dac5fbbd59bc6dbb85",
     "grade": false,
     "grade_id": "cell-7ac065f16bbb8ffa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.columns)\n",
    "# Drop the column 'Unnamed: 0' if it exists in the DataFrame\n",
    "X_train = X_train.loc[:, ~X_train.columns.str.contains('^Unnamed')]\n",
    "X_test = X_test.loc[:, ~X_test.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa8431",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b03f2d2b52420fee77559c59b2ee261",
     "grade": false,
     "grade_id": "cell-8506408528a04f58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Drop the 'Unnamed: 0' column from df and X_train, X_test \n",
    "df = df.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "X_train = X_train.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "X_test = X_test.drop(columns=['Unnamed: 0'], errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df79156e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ba8440cceb3970640690acb4040f55a",
     "grade": false,
     "grade_id": "cell-0f42545d6a4af9a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Below code uses t-values to determine which genes discriminate between the two cancer classes the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fba4797-3ad3-4893-937a-c8540981a4e9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e6f6b0dd775c944914b4624d2b35d7d",
     "grade": false,
     "grade_id": "cell-8ddfc74119460af3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code uses t-values to determine which genes discriminate between the two\n",
    "cancer classes the best. \n",
    "\"\"\"\n",
    "predictors = df.columns\n",
    "predictors = predictors.drop('Cancer_type');\n",
    "print(predictors.shape) \n",
    "\n",
    "means_0 = X_train[y_train==0][predictors].mean()\n",
    "means_1 = X_train[y_train==1][predictors].mean()\n",
    "stds_0 = X_train[y_train==0][predictors].std()\n",
    "stds_1 = X_train[y_train==1][predictors].std()\n",
    "n1 = X_train[y_train==0].shape[0]\n",
    "n2 = X_train[y_train==1].shape[0]\n",
    "\n",
    "t_tests = np.abs(means_0-means_1)/np.sqrt( stds_0**2/n1 + stds_1**2/n2)\n",
    "\n",
    "best_preds_idx = np.argsort(-t_tests.values)\n",
    "best_preds = t_tests.index[best_preds_idx]\n",
    "\n",
    "print(t_tests[best_preds_idx[0:10]])\n",
    "print(t_tests.index[best_preds_idx[0:10]])\n",
    "\n",
    "best_pred = t_tests.index[best_preds_idx[0]]\n",
    "print(best_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d91aea5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e31082ccc6bbcdb62df681c194008015",
     "grade": false,
     "grade_id": "exercise-4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class='exercise'><b> Exercise 3</b></div>\n",
    "\n",
    "## Visualizing the Best Gene for Cancer Classification \n",
    "\n",
    "In this exercise, you will create a histogram to visualize how the most discriminative gene (identified using the t-test from above code cell) varies between the two cancer types.\n",
    "\n",
    "### **Instructions**\n",
    "1. Write a function `plot_histograms()` that takes the following parameters:\n",
    "   - `best_pred`: The gene name identified as the best predictor.\n",
    "   - `X`: The feature matrix (gene expression data).\n",
    "   - `y`: The target variable (cancer type labels).\n",
    "   - `dataset_name`: A string indicating whether the data is from the **training** or **test** set.\n",
    "   \n",
    "2. The function should:\n",
    "   - Plot histograms for the gene expression levels for **Cancer Type 0** and **Cancer Type 1**.\n",
    "   - Use **different colors** to differentiate between the two cancer types.\n",
    "   - Include a **title** to indicate which dataset is being visualized.\n",
    "   - Label the **x-axis (gene expression levels)** and **y-axis (frequency count)**.\n",
    "   - Add a **legend** for clarity.\n",
    "\n",
    "\n",
    "**Example code:**\n",
    "```python\n",
    "    def plot_histograms(best_pred, X, y, dataset_name):\n",
    "        ....\n",
    "        ....\n",
    "```\n",
    "**Code usage:**\n",
    "```python\n",
    "# Plot histograms for the training set\n",
    "plot_histograms(best_pred, X_train, y_train, 'Training')\n",
    "\n",
    "# Plot histograms for the test set\n",
    "plot_histograms(best_pred, X_test, y_test, 'Testing')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4353dd31-e760-4150-aa4a-d1c5bc658d93",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd14a555604d0cb0c345b9d9cc7c3fe1",
     "grade": false,
     "grade_id": "exercise-4-implementation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Write your code for exercise-3 here:\"\"\"\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7179d548",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0aaf14429b4b9f747f5dbf5f32adc6db",
     "grade": true,
     "grade_id": "exercise-4-tests",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19474382-0ed6-4d65-a672-e6b76d6f2d72",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4812bce5463fe6d9508b75f335924623",
     "grade": false,
     "grade_id": "exercise-5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class='exercise'><b> Exercise 4</b></div>\n",
    "\n",
    "## Creating a Manual Classification Model  \n",
    "\n",
    "In this exercise, you will create a simple **manual classification model** using the best gene identified in Exercise 3. Rather than using a machine learning algorithm, you will classify cancer types based on a **manually chosen threshold** from the histogram.\n",
    "\n",
    "1. **Choose a threshold value** based on the histogram from Exercise 3.  \n",
    "   - Manually **eye-ball** the distribution and choose a threshold value that best **separates the two cancer types** (**ALL vs. AML**).\n",
    "   - Assign the threshold value to a variable named **`threshold`**.\n",
    "   \n",
    "2. **Implement a classification rule** using the threshold:\n",
    "    - If the **gene expression value** is **greater** than the threshold, classify it as **1 (AML)**.\n",
    "    - Otherwise, classify it as **0 (ALL)**.\n",
    "    - Store the predicted values in a variable **`y_pred_test`**.\n",
    "\n",
    "3. **Evaluate your model**:\n",
    "   - Compute the **accuracy** on the test set and store it in a variable named `accuracy`.\n",
    "   - Print the chosen threshold and the computed accuracy.\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be8546b-e8ff-41ac-a5b7-3d81ec244b71",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3639e46f42e59d9d24b4a8347d4d4ebb",
     "grade": false,
     "grade_id": "exercise-5-implementation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Write your code for exercise-4 here:\"\"\"\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb4871a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "900b07669b845189662367e28f26725d",
     "grade": true,
     "grade_id": "exercise-5-tests",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e57f8a1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "84dd4328477d0e1d32f6d68c19eab72e",
     "grade": false,
     "grade_id": "cell-af90efb63a741b7c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- **In class, we discussed how to use both `linear regression` and `logistic regression` for classification.**\n",
    "- **Now we will explore these two models by working with the single gene that you identified above as being the best predictor.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5233d7e8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "189740aec3384a770efb134d372f7216",
     "grade": false,
     "grade_id": "exercise-6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class='exercise'><b> Exercise 5</b></div>\n",
    "\n",
    "## Linear and Logistic Regression for Cancer Classification\n",
    "\n",
    "In this exercise, you will fit a **simple linear regression model** using the single **best gene predictor** identified previously. You will analyze whether **linear regression** is suitable for classifying AML vs ALL.\n",
    "\n",
    "#### **Linear Regression Model**\n",
    "1. Fit a **simple linear regression model** to predict cancer type (AML vs ALL) based on the best gene predictor.\n",
    "   - Use the **normalized values** of the best predictor.\n",
    "   - Create an instance of `LinearRegression()` named **`linear_model`**.\n",
    "   - Train this model using **X_train_best** (the single best predictor) and **y_train**.\n",
    "\n",
    "2. Predict the **cancer type** (`y_train_pred`) using the linear model.\n",
    "\n",
    "3. **Plot the results**:\n",
    "   - **Scatter plot**: True binary labels (0 for ALL, 1 for AML).\n",
    "   - **Line plot**: Predicted values from the linear regression model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae689c6e-18ba-433f-b6af-41c985c0aca0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c0f5a7eada9e21fa866fc80555845d7",
     "grade": false,
     "grade_id": "exercise-6-implementation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Write your code for exercise-5 here:\"\"\"\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4086746b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "683646758cf8040ffd5094c77dac9749",
     "grade": true,
     "grade_id": "exercise-6-tests",
     "locked": true,
     "points": 13,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76236218",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "45d9ed85c4065c43efd450193e8b6aa6",
     "grade": false,
     "grade_id": "exercise-7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class='exercise'><b> Exercise 6: Linear and Logistic Regression  </b></div>\n",
    "\n",
    "## Linear Regression as a Classifier  \n",
    "\n",
    "In this exercise, you will use your **trained linear regression model** from Exercise 5 to classify cancer types into **0 (ALL)** and **1 (AML)**. Since linear regression produces **continuous values**, you will apply a **Bayes classifier** by using a **threshold of 0.5** for classification.\n",
    "\n",
    "1. Apply the Classification Rule\n",
    "- If the **predicted value** is **greater than 0.5**, classify the sample as **1 (AML)**.\n",
    "- Otherwise, classify the sample as **0 (ALL)**.\n",
    "\n",
    "2. Compute Classification Accuracy\n",
    "- **Training Set:**\n",
    "  - Convert the predicted values `y_train_pred` into binary classifications.\n",
    "  - Store the classified predictions in a variable named **`y_train_classified`**.\n",
    "  - Compute the **training accuracy** and store it in **`train_accuracy`**.\n",
    "\n",
    "- **Test Set:**\n",
    "  - Predict values for **`X_test_best`** using the trained linear regression model.\n",
    "  - Convert predictions into binary classifications and store them in **`y_test_classified`**.\n",
    "  - Compute the **test accuracy** and store it in **`test_accuracy`**.\n",
    "\n",
    "3. Print the accuracy values for both sets.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f8f541-f66a-4091-aea4-3a5498863631",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb992589a1f0d95e4ff1d05112977889",
     "grade": false,
     "grade_id": "exercise-7-implementation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Write your code for exercise-6 here:\"\"\"\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9a8035",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35f9eee9bbe31c45020e8caef4350db5",
     "grade": true,
     "grade_id": "exercise-7-tests",
     "locked": true,
     "points": 9,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9de99764-62f6-4192-b66f-111718566004",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "df99f144adae4b9b3701e45e6bb9afda",
     "grade": false,
     "grade_id": "exercise-8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"exercise\"><b>Exercise 7</b> </div>\n",
    "\n",
    "## Logistic Regression for Cancer Classification  \n",
    "\n",
    "In this exercise, you will fit a **simple logistic regression model** to classify AML vs ALL based on the best predictor gene identified earlier. Unlike linear regression, logistic regression is a more appropriate method for **binary classification**.\n",
    "\n",
    "1. **Create a logistic regression model**:\n",
    "   - Use `LogisticRegression()` from `sklearn.linear_model`.\n",
    "   - Set **C=10000** to minimize regularization.\n",
    "   - Set **random_state=4300** for reproducibility.\n",
    "   - Name the model **`logistic_model`**.\n",
    "\n",
    "2. **Fit the model** using:\n",
    "   - **X_train_best** (the single best predictor).\n",
    "   - **y_train** (cancer type labels).\n",
    "\n",
    "3. **Make predictions**:\n",
    "   - Predict **training set labels** and store in `y_train_pred_logistic`.\n",
    "   - Predict **test set labels** and store in `y_test_pred_logistic`.\n",
    "\n",
    "4. **Compute accuracy**:\n",
    "   - Compute **training accuracy** and store in `train_accuracy_logistic`.\n",
    "   - Compute **test accuracy** and store in `test_accuracy_logistic`.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a79f0-c432-477b-b4f2-ec1619c8d4ae",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "deec29a1116fdb97b26f708324d282d3",
     "grade": false,
     "grade_id": "exercise-8-implementation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Write your code for exercise-7 here:\"\"\"\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f548704",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "37dbc40d115816cc7f667c53a8a3dcb3",
     "grade": true,
     "grade_id": "exercise-8-tests",
     "locked": true,
     "points": 13,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "772713d9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bcf30b99b9b6185b1da731f62c958617",
     "grade": false,
     "grade_id": "cell-d3fe70a536a145ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"theme\"> Question 2:</div>\n",
    "\n",
    "How does the classification accuracy of **logistic regression** compare to **linear regression** in this problem? (Select the most appropriate answer)\n",
    "\n",
    "1. Logistic regression performs **worse** than linear regression because it overfits the training data.\n",
    "2. Logistic regression performs **similarly** to linear regression because both methods are linear models.\n",
    "3. Logistic regression performs **better** than linear regression because it is specifically designed for binary classification.\n",
    "4. Linear regression performs **better** than logistic regression because it can handle continuous predictions.\n",
    "\n",
    "**Store your answer in an integer variable named `answer` in the below code cell.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143a9770",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ecad5915a9043a84ed6e902b1e9a9c8e",
     "grade": false,
     "grade_id": "cell-8be03ebd59208eb5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2965658a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7998d21b3b0c841145c3056a32ec929c",
     "grade": true,
     "grade_id": "cell-c49fac7195cc94b3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50c2505b-be2b-440b-88db-cd95a0b5ec21",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd00d5d47d808df90e2a09d212a700aa",
     "grade": false,
     "grade_id": "exercise-9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class='exercise'><b> Exercise 8: Linear and Logistic Regression  </b></div>\n",
    "\n",
    "## Comparing Linear and Logistic Regression Predictions\n",
    "\n",
    "In this exercise, you will visualize and compare the predictions from **linear regression** and **logistic regression** to evaluate their suitability for binary classification.\n",
    "\n",
    "1. **Create two subplots** (side by side) for:\n",
    "   - **Training data**\n",
    "   - **Test data**\n",
    "\n",
    "2. **Each plot should contain the following:**\n",
    "   - **Linear regression predictions** (continuous values).\n",
    "   - **Logistic regression predicted probabilities**.\n",
    "   - **True binary response** (actual labels).\n",
    "   - **A horizontal line at y=0.5** (classification threshold).\n",
    "\n",
    "3. **Customize the plot:**\n",
    "   - Use `plt.subplots(1, 2, figsize=(12, 6))` to create the figure.\n",
    "   - Set appropriate **titles, labels, and legends**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7343f948",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52d2510b78e6fbb7e46c88a0f3a06315",
     "grade": false,
     "grade_id": "exercise-9-implementation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Write your code for exercise-8 here:\"\"\"\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c5b957",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5fbeeea2302978115d546153b9891b78",
     "grade": true,
     "grade_id": "exercise-9-tests",
     "locked": true,
     "points": 14,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9082208",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7c5eb9033305fc6046ee8591186c8fd5",
     "grade": false,
     "grade_id": "cell-d36a9f7a4d525753",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"theme\"> Question 3:</div>\n",
    "\n",
    "Based on the plots comparing **linear regression** and **logistic regression**, which model is better suited for binary classification? (Select the most appropriate answer)\n",
    "\n",
    "- 1. **Linear regression** is better because it provides continuous predictions that can be thresholded.\n",
    "- 2. **Logistic regression** is better because it models probabilities and naturally handles binary classification.\n",
    "- 3. **Both models are equally effective** for classification tasks.\n",
    "- 4. **Linear regression is better than logistic regression** for probability estimation.\n",
    "\n",
    "**Store your answer in an integer variable named `answer` in the below code cell.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8566c37f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6230f1a01c50011d54fb3aef5c4e9198",
     "grade": false,
     "grade_id": "cell-70b8e21e205ccce0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e39018d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02bbd96b19d3234b799f1a2daaf20d66",
     "grade": true,
     "grade_id": "cell-d25ea9d45cf374d8",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29bb464b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc0940d37726fa680bc93f35f6b02027",
     "grade": false,
     "grade_id": "exercise-10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class='exercise'> <b> Exercise 9: Multiple Logistic Regression </b> </div>\n",
    "\n",
    "## Multiple Logistic Regression\n",
    "\n",
    "In this exercise, you will fit a **multiple logistic regression model** using **all gene predictors** in the dataset. Unlike the previous exercises, where classification was based on a single gene, this model will use all available gene expressions as features.\n",
    "\n",
    "1. **Fit a logistic regression model** using all genes:\n",
    "   - Use `LogisticRegression()` from `sklearn.linear_model`.\n",
    "   - Set **C=10000**, **max_iter=10000**, and **random_state=4300**.\n",
    "   - Name the model **`multi_logistic_model`**.\n",
    "\n",
    "2. **Make predictions**:\n",
    "   - Predict **training set labels** and store in `y_train_pred_multi`.\n",
    "   - Predict **test set labels** and store in `y_test_pred_multi`.\n",
    "\n",
    "3. **Compute accuracy**:\n",
    "   - Store **training accuracy** in `train_accuracy_multi`.\n",
    "   - Store **test accuracy** in `test_accuracy_multi`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe41bb7-7d09-466d-9d0a-6805c4eee514",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ced775cead1b7d7f232d168f72e88aa",
     "grade": false,
     "grade_id": "exercise-10-implementation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Write your code for exercise-9 here:\"\"\"\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62333d43",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a6b54efb4519ce0287e387105ee7020a",
     "grade": true,
     "grade_id": "exercise-10-tests",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bae8cc34",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "586820649577449e1a133495f80b991f",
     "grade": false,
     "grade_id": "cell-450ba39aa54bd2d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"theme\"> Question 4:</div>\n",
    "\n",
    "How does **multiple logistic regression** compare to the **single-gene models** in terms of accuracy? (Select the most appropriate answer)\n",
    "\n",
    "- 1. **Multiple logistic regression performs worse** because using all genes increases overfitting.\n",
    "- 2. **Multiple logistic regression performs similarly** to single-gene models because adding more predictors does not always improve classification.\n",
    "- 3. **Multiple logistic regression performs better** because it considers multiple genes, leading to more informed predictions.\n",
    "- 4. **Single-gene logistic regression is superior** because it is simpler and avoids overfitting.\n",
    "\n",
    "**Store your answer in an integer variable named `answer` in the below code cell.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2279d7d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d185c5abc8b444291127cb05629e0d5",
     "grade": false,
     "grade_id": "cell-5caf0fecb598682d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787cdbec",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a2c5824274a77d54ff6f3d9202af778",
     "grade": true,
     "grade_id": "cell-1bb2864c6b85ac13",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "649e8cd2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "77567f31d5820e8688374fd9ea1318a1",
     "grade": false,
     "grade_id": "exercise-11",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"theme\"> Question 5:</div>\n",
    "\n",
    "Based on the classification accuracy observed in **Exercise 9**, how would you assess the generalization capacity of your trained multiple logistic regression model? (Select the most appropriate answer)\n",
    "\n",
    "- 1. The model generalizes well if **training accuracy â‰ˆ test accuracy**, meaning it is not overfitting.\n",
    "- 2. The model overfits if **training accuracy >> test accuracy**, meaning it memorizes the training data but performs poorly on new data.\n",
    "- 3. The model underfits if **training accuracy and test accuracy are both low**, meaning it fails to capture patterns in the data.\n",
    "- 4. Generalization capacity cannot be assessed using accuracy alone; more evaluation metrics are needed.\n",
    "\n",
    "**Store your answer in an integer variable named `answer` in the below code cell.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e0aaca",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3962602edf6bde2d701c875a379f645e",
     "grade": false,
     "grade_id": "cell-2c058490b2a7f1d5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacafca4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0279cf89ce0eaced2361db710413cd6f",
     "grade": true,
     "grade_id": "cell-9b3ece12ce842e97",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e68a5c96",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ef72f9f1e004ff19f13dfe7759a5264",
     "grade": false,
     "grade_id": "exercise-12",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class='exercise'> <b> Exercise 10 </b> </div>\n",
    "\n",
    "## Regularization with L1 Penalty (LASSO)\n",
    "\n",
    "In this exercise, you will apply **LASSO-like regularization** (L1 penalty) using **5-fold cross-validation** to train a **logistic regression model**. Regularization helps to improve **generalization** by reducing overfitting.\n",
    "\n",
    "1. **Create and train a logistic regression model** with **L1 penalty (LASSO)**:\n",
    "   - Use `LogisticRegressionCV()` from `sklearn.linear_model`.\n",
    "   - Set **Cs = 10** (searches across 10 regularization strengths).\n",
    "   - Use **5-fold cross-validation (cv = 5)**.\n",
    "   - Set **penalty = 'l1'** for LASSO.\n",
    "   - Use **solver = 'saga'** (needed for L1 penalty).\n",
    "   - Set **max_iter = 50** and **random_state = 4300**.\n",
    "\n",
    "2. **Make predictions**:\n",
    "   - Predict **training set labels** and store in `y_train_pred_lasso`.\n",
    "   - Predict **test set labels** and store in `y_test_pred_lasso`.\n",
    "\n",
    "3. **Compute accuracy**:\n",
    "   - Store **training accuracy** in `train_accuracy_lasso`.\n",
    "   - Store **test accuracy** in `test_accuracy_lasso`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18765709-83dd-453c-8c37-803c13e20f23",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35f4edf52b999f1c048980212956b819",
     "grade": false,
     "grade_id": "exercise-12-implementation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Write your code for exercise-10 here:\"\"\"\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abadbbc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "90a67394b5d7733421161c89631ae963",
     "grade": true,
     "grade_id": "exercise-12-tests",
     "locked": true,
     "points": 13,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "845cab13",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b578227197e069a24105a66cc6a63aa7",
     "grade": false,
     "grade_id": "exercise-13-answer",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# **Conclusion: Model Comparison and Generalization**\n",
    "\n",
    "In this homework, we implemented and evaluated different **Logistic Regression models** for classifying leukemia types based on gene expression data. Below is a summary of the results:\n",
    "\n",
    "| Model | Training Accuracy | Test Accuracy | Analysis |\n",
    "|--------|-----------------|--------------|-----------|\n",
    "| **Logistic Regression (No Regularization)** | **0.7205** | **0.6821** | The gap between training and test accuracy is small, but the overall performance is lower than other models. This simple model lacks regularization, which may limit its generalization. |\n",
    "| **Multiple Logistic Regression (All Features)** | **1.0000** | **0.8278** | The model overfits the training data (100% accuracy), meaning it memorized the training set rather than generalizing well. The large gap between training and test accuracy suggests poor generalization. |\n",
    "| **Lasso Logistic Regression (L1 Regularization)** | **0.9035** | **0.8808** | This model balances bias and variance, showing a high test accuracy with a small gap from the training accuracy. The use of **L1 regularization (Lasso)** prevents overfitting by selecting only the most relevant genes. |\n",
    "\n",
    "## **Final Conclusion**\n",
    "The **Lasso Logistic Regression model** provides the best **generalization** across all models. \n",
    "\n",
    "- It achieves a **high test accuracy (88.08%)** while avoiding **overfitting**.\n",
    "- **L1 regularization** helps **select important features** and **ignore noise** in the data.\n",
    "- Unlike **Multiple Logistic Regression**, which memorizes the training set, the **Lasso model** learns a more **generalizable decision boundary**.\n",
    "\n",
    "### **Key Takeaways**\n",
    "âœ… Regularization techniques (such as **L1 penalty**) help **prevent overfitting**.  \n",
    "âœ… A **high training accuracy with a large test accuracy gap** is a sign of **overfitting**.  \n",
    "âœ… **Feature selection** via Lasso improves **interpretability and generalization**.  \n",
    "âœ… **Cross-validation** and **regularization** should be part of every **classification pipeline**.\n",
    "\n",
    "**Lasso Logistic Regression is the recommended model for this task!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9dd175",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d68f10b06228019547afbd47e63b6163",
     "grade": false,
     "grade_id": "cell-98f3572a841efd34",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
