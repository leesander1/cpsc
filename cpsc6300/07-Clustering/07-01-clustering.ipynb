{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af05d4d0-6bb6-41dd-858f-8ffc52c5e1af",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "06704e9a4c0622b1896d873967ab402a",
     "grade": false,
     "grade_id": "ads",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class='heading'>\n",
    "    <div style='float:left;'><h1>CPSC 4300/6300: Applied Data Science</h1></div>\n",
    "     <img style=\"float: right; padding-right: 10px\" width=\"100\" src=\"https://raw.githubusercontent.com/bsethwalker/clemson-cs4300/main/images/clemson_paw.png\"> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8858d0ae",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1d0d2e7219bd9931322ec5525075cd79",
     "grade": false,
     "grade_id": "week-7-lab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "\n",
    "# Week 7| Lab: Clustering\n",
    "\n",
    "**Clemson University** </br>\n",
    "**Instructor(s):** Tim Ransom </br>\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "## Learning objectives\n",
    "\n",
    "- List different types of clustering algorithms.\n",
    "- Apply k-means clustering to a dataset.\n",
    "- Interpret the results of a k-means clustering analysis.\n",
    "- Compare and contrast k-means and hierarchical clustering.\n",
    "- Visualize clusters using scatter plots.\n",
    "\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dca4171-9926-4112-b9a1-ca5cd2c488ba",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1adecbbc9168b4555d45f19966a14c83",
     "grade": false,
     "grade_id": "formatting",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" RUN THIS CELL TO GET THE RIGHT FORMATTING \"\"\"\n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "css_file = 'https://raw.githubusercontent.com/bsethwalker/clemson-cs4300/main/css/cpsc6300.css'\n",
    "styles = requests.get(css_file).text\n",
    "HTML(styles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543ca90d-5f99-4d59-9f44-bf12a47a6898",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c87d41ac5b8905c954d8303ef7d65001",
     "grade": false,
     "grade_id": "required-libs",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from matplotcheck.base import PlotTester\n",
    "from matplotlib.patches import PathPatch\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2a5d79-6d5a-4a90-bcb0-e88b9e85add1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e6f3f6a9046476565883fe60f90615a9",
     "grade": false,
     "grade_id": "question-1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"exercise\"><b>Question 1:</b> </div>\n",
    "Why is clustering important in data analysis and machine learning? (Select the most appropriate answer)\n",
    "\n",
    "- 1. It is a supervised learning technique used for classification tasks.\n",
    "- 2. It helps in discovering hidden patterns and segmenting data without prior labels.\n",
    "- 3. Clustering is only useful for preprocessing and does not have real-world applications.\n",
    "- 4. It is used solely for feature selection in deep learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2049e585",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52df3a5fb4bad32dbd2213a017e97d2a",
     "grade": false,
     "grade_id": "question-1-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a0068d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a6455a21ecbed73d4526eb2970f3e6f",
     "grade": true,
     "grade_id": "cell-c36f24c8791effc8",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a1aaffb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c374dcea54e6db3df68b5186890eb449",
     "grade": false,
     "grade_id": "clustering-algorithm",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Clustering Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6ee695",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cfaeb7952e4205fcde6544d1a1d82906",
     "grade": false,
     "grade_id": "cell-8ce1dfe3128d4240",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We will now walk through three clustering algorithms, first discussing\n",
    "them at a high-level, then showing how to implement them with Python\n",
    "libraries. Let's first load and scale our data, so that particular\n",
    "dimensions don't naturally dominate in their contributions in the\n",
    "distant calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7d514e-10dd-489b-bd8c-f53154508aeb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5513288926a63e4b5b282e25c081fdda",
     "grade": false,
     "grade_id": "cell-ef0d40e564187f0f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# loads and displays our summary statistics of our data\n",
    "multishapes = pd.read_csv(\"data/multishapes.csv\")\n",
    "multishapes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bf480c-b0a7-4cc6-acf6-c9dbc77cb3fa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c9391fbc0f4db54715e8ade435702744",
     "grade": false,
     "grade_id": "cell-6d9ba859943f2a91",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ms_df = multishapes[['x','y']]\n",
    "ms_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b9214-25e8-42da-aa73-a21e2dcefb8e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7187fe52054e393d3629a94d618a5f43",
     "grade": false,
     "grade_id": "cell-1376ef71fa37b77b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# scale our data\n",
    "scaled_df = pd.DataFrame(preprocessing.scale(ms_df), \n",
    "                         index=multishapes['shape'], \n",
    "                         columns=ms_df.columns)\n",
    "scaled_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7e99b5-ddb6-47ad-b99c-2a62232dd53e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0825f5f7554b13bb41e15471ab77b3c4",
     "grade": false,
     "grade_id": "cell-7e8078b97ad776d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# plots our data\n",
    "msplot = scaled_df.plot.scatter(x='x',y='y',c='Black',title=\"Multishapes data\",figsize=(11,8.5))\n",
    "msplot.set_xlabel(\"X\")\n",
    "msplot.set_ylabel(\"Y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a1e955-2849-466c-bcd2-fb6f4787610d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ccaaa0b3ab003ed18e963b36553bff66",
     "grade": false,
     "grade_id": "k-means-clustering",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1. k-Means clustering:\n",
    "\n",
    "### Code (via `sklearn`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465ef7b0-c34a-48c0-8341-7bfca0547165",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58a79bc2d8fdc14d8afac4126dd82492",
     "grade": false,
     "grade_id": "cell-3817049d8dd81776",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34edd21-6c93-496c-93e6-0e4fede54c7f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bffcf7d3a9ee69346c99acf5981e355a",
     "grade": false,
     "grade_id": "exercise-1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"exercise\"><b>Exercise 1</b>:     </div>\n",
    "\n",
    "-   Create a KMeans object named `ms_kmeans` using 3 clusters and a random<sub>state</sub>\n",
    "    of 109.\n",
    "-   Fit the `ms_kmeans` object to the `scaled_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aa0c38-d46b-411b-860e-68034f48596d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26bd2a5bdbd06c3ea711ee89a9eebf6c",
     "grade": false,
     "grade_id": "exercise-1-implementation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Write your code for Exercise-1 here:\"\"\"\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afb7d7f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02f8e36c7af2c21e977588794ea6b721",
     "grade": true,
     "grade_id": "exercise-1-grader",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc335566-a161-4677-a705-31218c8226f5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b63727350dc4a148bcd5d4bd432b728",
     "grade": false,
     "grade_id": "cell-319e03257ea52672",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that we've run k-Means, we can look at various attributes of our\n",
    "clusters. Full documenation is\n",
    "[here](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db90a8c-efed-4769-8ce2-1d2011abf510",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f0e53c20d63df598f1ce548dffdb5b4",
     "grade": false,
     "grade_id": "cell-77ed2479eb596946",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "display(ms_kmeans.cluster_centers_)\n",
    "display(ms_kmeans.labels_[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbb4413-dfdc-490e-9ea6-a44adfdb3a1a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d588abfa2ba7736a7a3c493c975f13cc",
     "grade": false,
     "grade_id": "cell-919cbf7cc3291e36",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Plotting\n",
    "\n",
    "Take note of matplotlib's `c=` argument to color items in the plot,\n",
    "along with our stacking two different plotting functions in the same\n",
    "plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100961ca-943c-4381-a99d-ee1853be737b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02fad629fc5c2e1fd11035696a54a53b",
     "grade": false,
     "grade_id": "cell-309a5ad071c28c66",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Scatter plot of the data points\n",
    "scatter = ax.scatter(scaled_df['x'], scaled_df['y'], c=ms_kmeans.labels_)\n",
    "\n",
    "# Highlight cluster centers\n",
    "ax.scatter(ms_kmeans.cluster_centers_[:, 0],\n",
    "           ms_kmeans.cluster_centers_[:, 1], \n",
    "           c='r', marker='h', s=100)\n",
    "\n",
    "# add titles and labels\n",
    "ax.set_title('Clustered Data with KMeans')\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_ylabel('Y-axis')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dadbdd-39ab-4af8-820e-0c2c2f97c400",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a76b7ed17b055c15f902ded170d87596",
     "grade": false,
     "grade_id": "question-2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"exercise\"><b>Question 2:</b></div>\n",
    "\n",
    "### **Importance of Feature Scaling in Clustering**  \n",
    "\n",
    "Clustering algorithms like **k-Means** rely on **distance metrics** (e.g., Euclidean distance) to assign points to clusters. If features have **different scales** (e.g., age in years vs. income in dollars), clustering results may be **skewed**.  \n",
    "\n",
    "**Question:**  \n",
    "Should we always scale our data before applying clustering algorithms like k-Means?  \n",
    "\n",
    "**Select the most appropriate answer:**  \n",
    "\n",
    "- 1. No, clustering algorithms are not affected by feature scaling.  \n",
    "- 2. Yes, because clustering methods like k-Means rely on distance metrics, and unscaled features with larger ranges can dominate the clustering process.  \n",
    "- 3. Scaling is only required when dealing with categorical data.  \n",
    "- 4. Scaling should be avoided as it distorts the natural relationships in the data.  \n",
    "\n",
    "**Store your answer in an integer variable named `answer` in the code cell below.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86651778",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b504676900e3d9c8bd08a6a755d5ed6",
     "grade": false,
     "grade_id": "question-2-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcf08f8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7faa55c97e312e9d7095e20d7c22a54f",
     "grade": true,
     "grade_id": "cell-a079e1f69bdc647b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72741ec5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d81a00d301af1a0a63424831a8c13e30",
     "grade": false,
     "grade_id": "inertia",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.1 Quality of Clusters: Inertia\n",
    "\n",
    "Inertia measures the total squared distance from points to their\n",
    "cluster's centroid. We obviously want this distance to be relatively\n",
    "small. If we increase the number of clusters, it will naturally make the\n",
    "average distance smaller. If every point has its own cluster, then our\n",
    "distance would be 0. That's obviously not an ideal way to cluster. One\n",
    "way to determine a reasonable number of clusters to simply try many\n",
    "different clusterings as we vary **k**, and each time, measure the\n",
    "overall inertia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3660a8e-12d8-470e-87dd-8a8c32e443c7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a4f4adce597f5d0cf3cdebc67978e5b",
     "grade": false,
     "grade_id": "cell-a5151397a7b84597",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "wss = []\n",
    "for i in range(1,11):\n",
    "    fitx = KMeans(n_clusters=i, init='random', n_init=5, random_state=109).fit(scaled_df)\n",
    "    wss.append(fitx.inertia_)\n",
    "\n",
    "plt.figure(figsize=(11,8.5))\n",
    "plt.plot(range(1,11), wss, 'bx-')\n",
    "plt.xlabel('Number of clusters $k$')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('The Elbow Method showing the optimal $k$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462b6bbd-5b6c-4154-b749-ccd380070eec",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "df2bb3436597b4fa922f3f747491e44f",
     "grade": false,
     "grade_id": "cell-1b54846328e4e4dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Look for the place(s) where distance stops decreasing as much (i.e., the\n",
    "'elbow' of the curve). It seems that 4 would be a good number of\n",
    "clusters, as a higher *k* yields diminishing returns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd097cb1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f706ea845b466a9d3079ec2e3dffddac",
     "grade": false,
     "grade_id": "Silhouette",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.2 Quality of Clusters: Silhouette\n",
    "\n",
    "Let's say we have a data point $i$, and the cluster it belongs to is\n",
    "referred to as $C(i)$. One way to measure the quality of a cluster\n",
    "$C(i)$ is to measure how close its data points are to each other\n",
    "(within-cluster) compared to nearby, other clusters $C(j)$. This is what\n",
    "`Silhouette Scores` provide for us. The range is \\[-1,1\\]; 0 indicates a\n",
    "point on the decision boundary (equal average closeness to points\n",
    "intra-cluster and out-of-cluster), and negative values mean that datum\n",
    "might be better in a different cluster.\n",
    "\n",
    "Specifically, let $a(i)$ denote the average distance data point $i$ is\n",
    "to the other points in the same cluster:</br>\n",
    "</br>\n",
    "<center>\n",
    "$a(i) = \\frac{1}{|C_i| - 1} \\sum_{j \\in C_i, i \\neq j} d(i, j)$\n",
    "</center>\n",
    "</br>\n",
    "</br>\n",
    "Similarly, we can also compute the average distance that data point $i$\n",
    "is to all **other** clusters. The cluster that yields the minimum\n",
    "distance is denoted by $b(i)$:</br>\n",
    "</br>\n",
    "<center>\n",
    "$b(i) = \\min_{k \\neq i} \\frac{1}{|C_k|} \\sum_{j \\in C_k} d(i, j)$\n",
    "</center>\n",
    "</br>\n",
    "</br>\n",
    "Hopefully our data point $i$ is much closer, on average, to points\n",
    "within its own cluster (i.e., $a(i)$ than it is to its closest\n",
    "neighboring cluster $b(i)$). The silhouette score quantifies this as\n",
    "$s(i)$:</br>\n",
    "</br>\n",
    "<center>\n",
    "$s(i) = \\frac{b(i) - a(i)}{\\max \\{ a(i), b(i) \\}}, \\text{ if } |C_i| > 1$\n",
    "</center>\n",
    "</br>\n",
    "**NOTE:** If data point $i$ belongs to its own cluster (no other\n",
    "points), then the silhouette score is set to 0 (otherwise, $a(i)$ would\n",
    "be undefined).\n",
    "\n",
    "The silhouette score plotted below is the **overall average** across all\n",
    "points in our dataset.\n",
    "\n",
    "The `silhouette_score()` function is available in `sklearn`. We can\n",
    "manually loop over values of K (for applying k-Means algorithm), then\n",
    "plot its silhouette score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af0d3e8-9412-4ebd-bac3-0a671a6d8575",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4edf60096f6e091b2b446ac0b10b34da",
     "grade": false,
     "grade_id": "cell-d5cf73e063cbbb71",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "scores = [0]\n",
    "for i in range(2,11):\n",
    "    fitx = KMeans(n_clusters=i, init='random', n_init=5, random_state=109).fit(scaled_df)\n",
    "    score = silhouette_score(scaled_df, fitx.labels_)\n",
    "    scores.append(score)\n",
    "\n",
    "plt.figure(figsize=(11,8.5))\n",
    "plt.plot(range(1,11), np.array(scores), 'bx-')\n",
    "plt.xlabel('Number of clusters $k$')\n",
    "plt.ylabel('Average Silhouette')\n",
    "plt.title('The Elbow Method showing the optimal $k$')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e291ab28-4607-40d4-af50-31f2ce01b4b4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2172780c4c71d42801f776e61fbeeeae",
     "grade": false,
     "grade_id": "cell-0acb6cfb878ef6b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.3.1 Visualizing all Silhoutte scores for a particular clustering\n",
    "\n",
    "Below, we borrow from an `sklearn` example. The second plot may be\n",
    "overkill.\n",
    "\n",
    "-   The second plot is just the scaled data.\n",
    "-   If you only need the raw silhouette scores, use the\n",
    "    `silhouette_samples()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad96045-397c-4bea-ab8d-f0cd02394289",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5cc0d639dc3191605693e199c07705a",
     "grade": false,
     "grade_id": "cell-4261bc6ca87edd16",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.cm as cm\n",
    "#modified code from http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html\n",
    "\n",
    "def silplot(X, clusterer, pointlabels=None):\n",
    "    cluster_labels = clusterer.labels_\n",
    "    n_clusters = clusterer.n_clusters\n",
    "\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(11,8.5)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters = \", n_clusters,\n",
    "          \", the average silhouette_score is \", silhouette_avg,\".\",sep=\"\")\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(0,n_clusters+1):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    ax2.scatter(X[:, 0], X[:, 1], marker='.', s=200, lw=0, alpha=0.7,\n",
    "                c=colors, edgecolor='k')\n",
    "    xs = X[:, 0]\n",
    "    ys = X[:, 1]\n",
    "\n",
    "    if pointlabels is not None:\n",
    "        for i in range(len(xs)):\n",
    "            plt.text(xs[i],ys[i],pointlabels[i])\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = clusterer.cluster_centers_\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker='$%d$' % int(i), alpha=1,\n",
    "                    s=50, edgecolor='k')\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f5842e-c9b8-4bd3-bf09-e985cb3f84c2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a2d435309c0cad02e19816c2096170d",
     "grade": false,
     "grade_id": "cell-ab07b3bdba58b728",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# run k-means with 3 clusters\n",
    "ms_kmeans = KMeans(n_clusters=3, init='random', n_init=3, random_state=109).fit(scaled_df)\n",
    "\n",
    "# plot a fancy silhouette plot\n",
    "silplot(scaled_df.values, ms_kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a386612b-1fa7-47fa-ab89-b7279e9e7c06",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b62c0a5e74193983a0e396a22aa7510b",
     "grade": false,
     "grade_id": "exercise-2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"exercise\"><b>Exercise 2:</b></div>\n",
    "\n",
    "### **Optimizing k-Means Clustering using Silhouette Scores**\n",
    "\n",
    "Using the **optimal number of clusters** from the silhouette scores (as determined by the elbow plot above):\n",
    "\n",
    "1. **Fit a new k-Means model** named `ms_kmeans_optimal` using the **optimal number of clusters**.\n",
    "2. **Plot the clusters** as we originally did with k-Means.\n",
    "3. **Plot the silhouette scores** just like in the previous cells.\n",
    "4. Compare the clustering results for **3 clusters** versus the **optimal number of clusters** found using silhouette scores.\n",
    "\n",
    "**Instructions:**\n",
    "- Create a new `KMeans` object named `ms_kmeans_optimal` using the **optimal number of clusters**.\n",
    "- Fit `ms_kmeans_optimal` to `scaled_df`.\n",
    "- Generate a **scatter plot** of the clusters.\n",
    "- Generate a **silhouette plot** to visualize the quality of the clustering.\n",
    "\n",
    "**Write your code in the cell below.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b2e240-0e49-45e8-9a7d-26f73f586e48",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15291a80276031c7e2e5bb98e04ac7e9",
     "grade": false,
     "grade_id": "exercise-2-implementation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Write your code for Exercise-2 here:\"\"\"\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f738389a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84d7b04971ae8e68755c4177e8cd89bc",
     "grade": true,
     "grade_id": "exercise-2-grader",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e751e0e-3b6b-4cf1-a7ac-999310b06838",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b69726495619ce35099695857e1a1e2",
     "grade": false,
     "grade_id": "gap-stats",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.3 Quality of Clusters: Gap Statistic\n",
    "\n",
    "The gap statistic compares within-cluster distances (like in\n",
    "silhouette), but instead of comparing against the second-best existing\n",
    "cluster for that point, it compares our clustering's overall average to\n",
    "the average we'd see if the data were generated at random (we'd expect\n",
    "randomly generated data to not necessarily have any inherit patterns\n",
    "that can be easily clustered).\n",
    "\n",
    "In essence, the within-cluster distances (in the elbow plot) will go\n",
    "down just becuse we have more clusters. We additionally calculate how\n",
    "much they'd go down on non-clustered data with the same spread as our\n",
    "data and subtract that trend out to produce the plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0698ed-20dd-4e0c-afbc-5a2c7b018687",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e58fb9b7bdbb57b14c29dcf773e5f90a",
     "grade": false,
     "grade_id": "cell-153378bd68dd7f72",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# If you need to install the gap_statistic package, run following code on you local machine\n",
    "!pip install --upgrade pip\n",
    "!pip install gap-stat --only-binary :all:\n",
    "!pip install git+git://github.com/milesgranger/gap_statistic.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9f2917-2a53-45bb-abb2-153cc29a6f5b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8230753df91a0425e82dcbc9a17d6c3f",
     "grade": false,
     "grade_id": "cell-a071b366e62cd31d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from gap_statistic import OptimalK\n",
    "\n",
    "gs_obj = OptimalK()\n",
    "\n",
    "n_clusters = gs_obj(scaled_df.values, n_refs=50, cluster_array=np.arange(1, 15))\n",
    "print('Optimal clusters: ', n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7682434b-f21e-4492-825a-aa3995f2b104",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dae5f681407f9b7b2a69f76ed649abd9",
     "grade": false,
     "grade_id": "cell-b7edb54a20d710d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "gs_obj.gap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2e3fb0-ca2a-452e-90e6-d860fd812fe2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f7e6997b27b49ec35877cac4a55f476",
     "grade": false,
     "grade_id": "cell-658f08ece70d424b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "gs_obj.plot_results() # makes nice plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d355057-81c1-48eb-8844-d91a962bd56a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f61d4551f2773430044b0273e9be56d1",
     "grade": false,
     "grade_id": "cell-486f041d1eb02095",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If we wish to add error bars to help us decide how many clusters to use,\n",
    "the following code displays such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822eb62d-d3b8-425a-b8e7-62539473a3d4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c01247ba954cf0f42c729d39867ce626",
     "grade": false,
     "grade_id": "cell-97da4b141797c9e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def display_gapstat_with_errbars(gap_df):\n",
    "    gaps = gap_df[\"gap_value\"].values\n",
    "    diffs = gap_df[\"diff\"]\n",
    "\n",
    "    err_bars = np.zeros(len(gap_df))\n",
    "    err_bars[1:] = diffs[:-1] - gaps[:-1] + gaps[1:]\n",
    "\n",
    "    plt.scatter(gap_df[\"n_clusters\"], gap_df[\"gap_value\"])\n",
    "    plt.errorbar(gap_df[\"n_clusters\"], gap_df[\"gap_value\"], yerr=err_bars, capsize=6)\n",
    "    plt.xlabel(\"Number of Clusters\")\n",
    "    plt.ylabel(\"Gap Statistic\")\n",
    "    plt.show()\n",
    "\n",
    "display_gapstat_with_errbars(gs_obj.gap_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24bcf88-0a8d-488c-9de2-0463f332804a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "64b3091db600992fc8cda1240aa5d44c",
     "grade": false,
     "grade_id": "cell-25ee8702610e7166",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For more information about the `gap_stat` package, please see [the full\n",
    "documentation here](https://github.com/milesgranger/gap_statistic)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f215b3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4110e0ea53a5a4a90b27e7f27c038a2",
     "grade": false,
     "grade_id": "agglomerative-clustering",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2. Agglomerative Clustering\n",
    "### Code (via `scipy`):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee39e66e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d1c5d7f3801b19dcd702585d8ac4b41",
     "grade": false,
     "grade_id": "cell-23043dd22fe802ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "There are many different cluster-merging criteria, one of which is\n",
    "Ward's criteria. Ward's optimizes having the lowest total within-cluster\n",
    "distances, so it merges the two clusters that will harm this objective\n",
    "least. `scipy`'s agglomerative clustering function implements Ward's\n",
    "method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afd825b-b7ec-40ed-8ddd-c1c8534b4297",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3217c513baedb28fbed4de6d4536e047",
     "grade": false,
     "grade_id": "cell-a435fb682ed5abe2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as hac\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "plt.figure(figsize=(11,8.5))\n",
    "dist_mat = pdist(scaled_df, metric=\"euclidean\")\n",
    "ward_data = hac.ward(dist_mat)\n",
    "\n",
    "hac.dendrogram(ward_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352cb2c6-068b-4127-8890-2824dbc4c0fc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a5d1d28e7b758890ab0bdb8525e7fcab",
     "grade": false,
     "grade_id": "cell-9af7028312379fc5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "How do you read a plot like the above? What are valid options for number\n",
    "of clusters, and how can you tell? Are some more valid than others? Does\n",
    "it make sense to compute silhouette scores for an agglomerative\n",
    "clustering? If we wanted to compute silhouette scores, what would we\n",
    "need for this to be possible?\n",
    "\n",
    "## Lessons:\n",
    "\n",
    "-   It's expensive: O(n<sup>3</sup>) time complexity and\n",
    "    O(n<sup>2</sup>) space complexity.\n",
    "-   Many choices for linkage criteria\n",
    "-   Every node gets clustered (no child left behind)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f498d2b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ade79b7b688bcd4ca23fe7cba8bb62f7",
     "grade": false,
     "grade_id": "dbscan-clustering",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3. DBscan Clustering\n",
    "\n",
    "### Code (via `sklearn`):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fee85c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "339b8d2521bffabb27d4de48ae774782",
     "grade": false,
     "grade_id": "cell-98d91bdcf588f66c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "`DBscan` uses an intuitive notion of denseness to define clusters, rather than defining clusters by a central point as in k-means.\n",
    "\n",
    "DBscan is implemented in good 'ol sklearn, but there aren't great\n",
    "automated tools for searching for the optimal `epsilon` parameter. For\n",
    "full documentation, please [visit this\n",
    "page](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4d3d8f-8b15-48af-9f05-9bdf3afa31bd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08239fe901de00f9f110fad49c3bdcb4",
     "grade": false,
     "grade_id": "cell-4640af455f0b89cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "plt.figure(figsize=(11,8.5))\n",
    "\n",
    "fitted_dbscan = DBSCAN(eps=0.2).fit(scaled_df)\n",
    "\n",
    "plt.scatter(scaled_df['x'], scaled_df['y'], c=fitted_dbscan.labels_);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b9e55a-5e19-405b-8e27-9759560a94fb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3fe9c612577bacb714b066a2d1f31c01",
     "grade": false,
     "grade_id": "cell-ad7b9d2bc6d23664",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Note:** the dark purple dots are not clustered with anything else.\n",
    "They are lone singletons. You can validate such by setting epsilon to a\n",
    "very small value, and increase the min<sub>samples</sub> to a high\n",
    "value. Under these conditions, nothing would cluster, and yet all dots\n",
    "become dark purple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25527bd1-f0f9-49cd-ae73-b2b77eb7aac4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c9d21f9c5dab9f6bddd7e6ba860132f",
     "grade": false,
     "grade_id": "cell-c31d930d2d6ca96b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# x-axis is each individual data point, numbered by an artificial index\n",
    "# y-axis is the distance to its 2nd closest neighbor\n",
    "def plot_epsilon(df, min_samples):\n",
    "    fitted_neigbors = NearestNeighbors(n_neighbors=min_samples).fit(df)\n",
    "    distances, indices = fitted_neigbors.kneighbors(df)\n",
    "    dist_to_nth_nearest_neighbor = distances[:,-1]\n",
    "    plt.plot(np.sort(dist_to_nth_nearest_neighbor))\n",
    "    plt.xlabel(\"Index\\n(sorted by increasing distances)\")\n",
    "    plt.ylabel(\"{}-NN Distance (epsilon)\".format(min_samples-1))\n",
    "    plt.tick_params(right=True, labelright=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd15b3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0cec2379ef6fe32fd6df06370d6e9726",
     "grade": false,
     "grade_id": "exercise-3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"exercise\"><b>Exercise 3:</b></div>\n",
    "\n",
    "### **Experimenting with DBSCAN Parameters**\n",
    "DBSCAN clustering uses the **epsilon (eps)** parameter to define the neighborhood size and **min_samples** to determine the minimum number of points required to form a dense cluster.  \n",
    "\n",
    "#### **Tasks:**\n",
    "1. Experiment with the **DBSCAN** clustering algorithm by **changing the epsilon (`eps`)** value and the **min_samples** parameter.\n",
    "2. Identify the **default value** for `min_samples` (since the code above does not explicitly set it).\n",
    "3. Use the `plot_epsilon()` function to **inspect how far each data point is from its nearest neighbor**.\n",
    "4. Compute the **Nth nearest neighbor distance** for `min_samples` values **ranging from 1 to 10** and store the results in variables:\n",
    "   - `value_a = f(1)`\n",
    "   - `value_b = f(2)`\n",
    "\n",
    "**This exercise is for experimental practice and will not be graded.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1c20da-11f7-47f9-a504-e7a38cce6448",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c152ace6e30bfbf5fff615a29adb67c7",
     "grade": false,
     "grade_id": "cell-06e1efdbb78b4ae2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plot_epsilon(scaled_df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cd2f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56e1da18-38bf-4206-a5e5-a3e90280542f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "803a149173188bc2014a73a335038a9c",
     "grade": false,
     "grade_id": "cell-8f373c4246223e36",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Lessons:\n",
    "\n",
    "-   Can cluster non-linear relationships very well; potential for more\n",
    "    natural, arbritrarily shaped groupings\n",
    "-   Does not require specifying the \\# of clusters (i.e., **k**); the\n",
    "    algorithm determines such\n",
    "-   Robust to outliers\n",
    "-   Very sensitive to the parameters (requires strong knowledge of the\n",
    "    data)\n",
    "-   Doesn't guarantee that every (or ANY) item will be clustered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6a2ad1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "728b55fcbf6d3208654ec24b63f2d20b",
     "grade": false,
     "grade_id": "end",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
